<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Mozilla Hacks &#8211; the Web developer blog</title>
	<atom:link href="https://hacks.mozilla.org/feed/" rel="self" type="application/rss+xml" />
	<link>https://hacks.mozilla.org/</link>
	<description>hacks.mozilla.org</description>
	<lastBuildDate>Tue, 05 Sep 2023 19:18:11 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.3</generator>
	<item>
		<title>Faster Vue.js Execution in Firefox</title>
		<link>https://hacks.mozilla.org/2023/09/faster-vue-js-execution-in-firefox/</link>
					<comments>https://hacks.mozilla.org/2023/09/faster-vue-js-execution-in-firefox/#respond</comments>
		
		<dc:creator><![CDATA[Brian Grinstead]]></dc:creator>
		<pubDate>Tue, 05 Sep 2023 16:39:32 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[JavaScript]]></category>
		<category><![CDATA[Performance]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[js]]></category>
		<category><![CDATA[speedometer]]></category>
		<category><![CDATA[vue]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=48028</guid>

					<description><![CDATA[<p>Firefox performance on Vue.js has improved significantly throughout the year. Most recently, we sped up reactivity with Proxy optimizations. This change landed in Firefox 118, so it’s currently on Beta and will ride along to Release by the end of September.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/09/faster-vue-js-execution-in-firefox/">Faster Vue.js Execution in Firefox</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><a href="https://twitter.com/mozhacks/status/1603435347190419456">Speedometer 3</a> is a cross-industry effort to build a modern browser benchmark rooted in real-world user experiences. Its goal is to focus browser engineering effort towards making the Web more smooth for actual users on actual pages. This is hard to do and most browser benchmarks don’t do it well, but we see it as a unique opportunity to improve responsiveness broadly across the Web.</p>
<p>This requires a deliberate analysis of the ecosystem — starting with real user experiences and identifying the essential technical elements underlying them. We built several new tests from scratch, and also updated some existing tests from Speedometer 2 to use more modern versions of widely-used JavaScript frameworks.</p>
<p>When the Vue.js test was updated from Vue 2 to Vue 3, we <a href="https://github.com/WebKit/Speedometer/pull/114#issuecomment-1479368671">noticed</a> some performance issues in Firefox. The root of the problem was <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy">Proxy</a> object usage that <a href="https://vuejs.org/guide/extras/reactivity-in-depth.html#how-reactivity-works-in-vue">was introduced in Vue 3</a>.</p>
<p>Proxies are hard to optimize because they’re generic by design and can behave in all sorts of surprising ways (e.g., modifying trap functions after initialization, or wrapping a Proxy with another Proxy). They also weren’t used much on the performance-critical path when they were introduced, so we focused primarily on correctness in the original implementation.</p>
<p>Speedometer 3 developed evidence that some Proxies today are well-behaved, critical-path, and widely-used. So we <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1824051">optimized these</a> to execute completely in the JIT — specializing for the shapes of the Proxies encountered at the call-site and avoiding redundant work. This makes reactivity in Vue.js significantly faster, and we also anticipate improvements on other workloads.</p>
<p>This change landed in Firefox 118, so it’s currently on Beta and will ride along to Release by the end of September.</p>
<p>Over the course of the year Firefox has improved <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1824051#c25">by around 40%</a> on the Vue.js benchmark from work like this. More importantly, and as we hoped, we’re observing real user metric improvements across all page loads in Firefox as we optimize Speedometer 3. We’ll share more details about this in a subsequent post.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/09/faster-vue-js-execution-in-firefox/">Faster Vue.js Execution in Firefox</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://hacks.mozilla.org/2023/09/faster-vue-js-execution-in-firefox/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Autogenerating Rust-JS bindings with UniFFI</title>
		<link>https://hacks.mozilla.org/2023/08/autogenerating-rust-js-bindings-with-uniffi/</link>
		
		<dc:creator><![CDATA[Ben Dean-Kawamura]]></dc:creator>
		<pubDate>Tue, 08 Aug 2023 11:15:31 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[JavaScript]]></category>
		<category><![CDATA[Rust]]></category>
		<category><![CDATA[UniFFI]]></category>
		<category><![CDATA[Android]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[glean]]></category>
		<category><![CDATA[iOS]]></category>
		<category><![CDATA[mozilla]]></category>
		<category><![CDATA[rust]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=48021</guid>

					<description><![CDATA[<p>This blog post will walk through how we developed UniFFI: a Rust library for auto-generating foreign language bindings. We will walk through some of the issues that arose along the way and how we handled them.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/08/autogenerating-rust-js-bindings-with-uniffi/">Autogenerating Rust-JS bindings with UniFFI</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><img decoding="async" fetchpriority="high" class="alignnone wp-image-48023 size-full" src="https://hacks.mozilla.org/files/2023/08/image-2.png" alt="" width="1260" height="702" srcset="https://hacks.mozilla.org/files/2023/08/image-2.png 1260w, https://hacks.mozilla.org/files/2023/08/image-2-250x139.png 250w, https://hacks.mozilla.org/files/2023/08/image-2-500x279.png 500w, https://hacks.mozilla.org/files/2023/08/image-2-768x428.png 768w" sizes="(max-width: 1260px) 100vw, 1260px" /></p>
<p><span style="font-weight: 400;">I work on the Firefox sync team at Mozilla. Four years ago, we wrote a </span><a href="https://hacks.mozilla.org/2019/04/crossing-the-rust-ffi-frontier-with-protocol-buffers/"><span style="font-weight: 400;">blog post describing our strategy to ship cross-platform Rust components</span></a><span style="font-weight: 400;"> for syncing and storage on all our platforms. The vision was to consolidate the separate implementations of features like history, logins, and syncing that existed on Firefox Desktop, Android, and iOS. </span></p>
<p><span style="font-weight: 400;">We would replace those implementations with a core written in Rust and a set of hand-written foreign language wrappers for each platform: JavaScript for Desktop, Kotlin for Android, and Swift for iOS.</span></p>
<p><span style="font-weight: 400;">Since then, we’ve learned some lessons and had to modify our strategy. It turns out that creating hand-written wrappers in multiple languages is a huge time-sink. The wrappers required a significant amount of time to write, but more importantly, they were responsible for many serious bugs. </span></p>
<p><span style="font-weight: 400;">These bugs were easy to miss, hard to debug, and often led to crashes. One of the largest benefits of Rust is memory safety, but these hand-written wrappers were negating much of that benefit.</span></p>
<p><span style="font-weight: 400;">To solve this problem, we developed </span><a href="https://mozilla.github.io/uniffi-rs/"><span style="font-weight: 400;">UniFFI</span></a><span style="font-weight: 400;">: a Rust library for auto-generating foreign language bindings. UniFFI allowed us to create wrappers quickly and safely, but there was one issue: UniFFI supported Kotlin and Swift, but not JavaScript, which powers the Firefox Desktop front-end</span><span style="font-weight: 400;">. UniFFI helped us ship shared components for Firefox Android and iOS, but Desktop remained out of reach.</span></p>
<p><span style="font-weight: 400;">This changed with Firefox 105 when we added support for generating JavaScript bindings via UniFFI which enabled us to continue pushing forward on our single component vision. This project validated some core concepts that have been in UniFFI from the start but also required us to extend UniFFI in several ways. This blog post will walk through some of the issues that arose along the way and how we handled them.</span></p>
<h2><strong>Prior Art</strong></h2>
<p><span style="font-weight: 400;">This project has already been tried at least once before at Mozilla. The team was able to get some of the functionality supported, but some parts remained out of reach. One of the first things we realized was that the general approach the previous attempts took would probably not support the UniFFI features we were using in our components.</span></p>
<p><span style="font-weight: 400;">Does this mean the previous work was a failure? Absolutely not. The team left behind a wonderful trove of design documents, discussions, and code that we made sure to study and steal from. In particular, there was an </span><a href="https://adr.github.io/"><span style="font-weight: 400;">ADR</span></a><span style="font-weight: 400;"> that discussed different approaches which we studied, as well as a </span><a href="https://github.com/mozilla/uniffi-rs/pull/255"><span style="font-weight: 400;">working C++/WebIDL code</span></a><span style="font-weight: 400;"> that we repurposed for our project.</span></p>
<h2><strong>Calling the FFI functions</strong></h2>
<p><span style="font-weight: 400;">UniFFI bindings live on top of an </span><a href="https://en.wikipedia.org/wiki/Foreign_function_interface"><span style="font-weight: 400;">FFI</span></a><span style="font-weight: 400;"> layer using the C ABI that we call “the scaffolding.” Then the user API is defined on top of the scaffolding layer, in the foreign language. This allows the user API to support features not directly expressible in C and also allows the generated API to feel idiomatic and natural. However, JavaScript complicates this picture because it doesn’t have support for calling C functions. Privileged code in Firefox can use the Mozilla </span><a href="http://www.devdoc.net/web/developer.mozilla.org/en-US/docs/js-ctypes.html"><span style="font-weight: 400;">js-ctypes</span></a><span style="font-weight: 400;"> library, but its use is deprecated.</span></p>
<p><span style="font-weight: 400;">The previous project solved this problem by using C++ to call into the scaffolding functions, then leveraged the </span><a href="https://firefox-source-docs.mozilla.org/dom/webIdlBindings/index.html"><span style="font-weight: 400;">Firefox WebIDL code generation tools</span></a><span style="font-weight: 400;"> to create the JavaScript API. That code generation tool is quite nice and allowed us to define the user API using a combination of </span><a href="https://developer.mozilla.org/en-US/docs/MDN/Contribute/Howto/Write_an_API_reference/Information_contained_in_a_WebIDL_file"><span style="font-weight: 400;">WebIDL</span></a><span style="font-weight: 400;"> and C++ glue code. However, it was limited and did not support all UniFFI features.</span></p>
<p><span style="font-weight: 400;">Our team decided to use the same WebIDL code generation tool, but to generate just the scaffolding layer instead of the entire user API. Then we used JavaScript to define the user API on top of that, just like for other languages. We were fairly confident that the code generation tool would no longer be a limiting factor, since the scaffolding layer is designed to be minimalistic and expressible in C.</span></p>
<h2><strong>Async functions</strong></h2>
<p><span style="font-weight: 400;">The threading model for UniFFI interfaces is not very flexible: all function and method calls are blocking. It’s the caller’s responsibility to ensure that calls don’t block the wrong thread. Typically this means executing UniFFI calls in a thread pool.</span></p>
<p><span style="font-weight: 400;">The threading model for Firefox frontend JavaScript code is equally inflexible: you must never block the main thread. The main JavaScript thread is responsible for all UI updates and blocking it means an unresponsive browser. Furthermore, the only way to start another thread in JavaScript is using </span><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Using_web_workers"><span style="font-weight: 400;">Web Workers</span></a><span style="font-weight: 400;">, but those are not currently used by the frontend code.</span></p>
<p><span style="font-weight: 400;">To resolve the unstoppable force vs. immovable object situation we found ourselves in, we simply reversed the UniFFI model and made all calls asynchronous. This means that all functions return a </span><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise"><span style="font-weight: 400;">promise</span></a><span style="font-weight: 400;"> rather than their return value directly.</span></p>
<p><span style="font-weight: 400;">The “all functions are async” model seems reasonable, at least for the first few projects we intend to use with UniFFI. However, not all functions really need to be async – some are quick enough that they aren’t blocking. Eventually, we plan to add a way for users to customize which functions are blocking and which are async. This will probably happen alongside some general work for async UniFFI, since we’ve found that async execution is an issue for many components using UniFFI.</span></p>
<h2><strong>How has it been working?</strong></h2>
<p><span style="font-weight: 400;">Since landing UniFFI support in Firefox 105, we’ve slowly started adding some UniFFI’ed Rust components to Firefox. In Firefox 108 we added the Rust remote tabs syncing engine, making it the first component shared by Firefox on all three of our platforms. The new tabs engine uses UniFFI to generate JS bindings on Desktop, Kotlin bindings on Android, and Swift bindings on iOS. </span></p>
<p><span style="font-weight: 400;">We’ve also been continuing to advance our shared component strategy on Mobile. Firefox iOS has historically lagged behind Android in terms of shared component adoption, but the Firefox iOS 116 release will use our shared sync manager component. This means that both mobile browsers will be using all of the shared components we’ve written so far.</span></p>
<p><span style="font-weight: 400;">We also use UniFFI to generate bindings for </span><a href="https://mozilla.github.io/glean/dev/index.html"><span style="font-weight: 400;">Glean</span></a><span style="font-weight: 400;">, a Mozilla telemetry library, which was a bit of an unusual case. Glean doesn’t generate JS bindings; it only generates the scaffolding API, which ends up in the </span><a href="https://mozilla.github.io/geckoview/"><span style="font-weight: 400;">GeckoView</span></a><span style="font-weight: 400;"> library that powers Firefox Android. Firefox Android can then consume Glean via the generated Kotlin bindings which link to the scaffolding in Geckoview.</span></p>
<p><span style="font-weight: 400;">If you’re interested in this project or UniFFI in general, please join us in </span><a href="https://matrix.to/#/#uniffi:mozilla.org"><span style="font-weight: 400;">#uniffi</span></a><span style="font-weight: 400;"> on the Mozilla Matrix chat.</span></p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/08/autogenerating-rust-js-bindings-with-uniffi/">Autogenerating Rust-JS bindings with UniFFI</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>So you want to build your own open source ChatGPT-style chatbot&#8230;</title>
		<link>https://hacks.mozilla.org/2023/07/so-you-want-to-build-your-own-open-source-chatbot/</link>
		
		<dc:creator><![CDATA[Stephen Hood]]></dc:creator>
		<pubDate>Thu, 27 Jul 2023 17:52:57 +0000</pubDate>
				<category><![CDATA[Artificial Intelligence]]></category>
		<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Mozilla]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[api]]></category>
		<category><![CDATA[artificial intelligence]]></category>
		<category><![CDATA[chatbot]]></category>
		<category><![CDATA[cloud]]></category>
		<category><![CDATA[mozilla]]></category>
		<category><![CDATA[open source]]></category>
		<category><![CDATA[runtime]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=48012</guid>

					<description><![CDATA[<p>Artificial intelligence may well prove one of the most impactful and disruptive technologies to come along in years. We want to understand, support, and contribute to these efforts because we believe that they offer one of the best ways to help ensure that the AI systems that emerge are truly trustworthy. With this in mind, a small team within Mozilla’s innovation group recently undertook a hackathon at our headquarters in San Francisco. Our objective: build a Mozilla internal chatbot prototype.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/07/so-you-want-to-build-your-own-open-source-chatbot/">So you want to build your own open source ChatGPT-style chatbot&#8230;</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><i>(Expanded from </i><a href="https://sched.co/1O37L"><i>a talk</i></a><i> given at </i><a href="https://dwebcamp.org/"><i>DWeb Camp 2023</i></a><i>.)</i></p>
<p>Artificial intelligence may well prove one of the most impactful and disruptive technologies to come along in years. This impact isn’t theoretical: AI is already affecting real people in substantial ways, and it&#8217;s already changing the Web that we know and love. Acknowledging the potential for both benefit and harm, Mozilla has committed itself to the principles of <a href="https://foundation.mozilla.org/en/internet-health/trustworthy-artificial-intelligence/"><b>trustworthy AI</b></a>. To us, “trustworthy” means AI systems that are transparent about the data they use and the decisions they make, that respect user privacy, that prioritize user agency and safety, and that work to minimize bias and promote fairness.</p>
<h2>Where things stand</h2>
<p>Right now, the primary way that most people are experiencing the latest AI technology is through <b>generative AI chatbots</b>. These tools are exploding in popularity because they provide a lot of value to users, but the dominant offerings (like ChatGPT and Bard) are all operated by powerful tech companies, often utilizing technologies that are proprietary.</p>
<p>At Mozilla, we believe in the collaborative power of <b>open source</b> to empower users, drive transparency, and — perhaps most importantly — ensure that technology does not develop only according to the worldviews and financial motivations of a small group of corporations. Fortunately, there’s recently been rapid and exciting progress in the open source AI space, specifically around the <b>large language models</b> (LLMs) that power these chatbots and the tooling that enables their use. We want to understand, support, and contribute to these efforts because we believe that they offer one of the best ways to help ensure that the AI systems that emerge are truly trustworthy.</p>
<h2>Digging in</h2>
<p>With this goal in mind, a small team within Mozilla’s innovation group recently undertook a hackathon at our headquarters in San Francisco. Our objective: <b>build a Mozilla internal chatbot prototype</b>, one that’s…</p>
<ul>
<li aria-level="1">Completely <b>self-contained</b>, running entirely on Mozilla’s cloud infrastructure, without any dependence on third-party APIs or services.</li>
<li aria-level="1">Built with <b>free, open source</b> large language models and tooling.</li>
<li aria-level="1"><b>Imbued</b> with Mozilla’s beliefs, from trustworthy AI to the principles espoused by the <a href="https://www.mozilla.org/en-US/about/manifesto/">Mozilla Manifesto</a>.</li>
</ul>
<p>As a bonus, we set a stretch goal of integrating some amount of internal Mozilla-specific knowledge, so that the chatbot can answer employee questions about internal matters.</p>
<p>The Mozilla team that undertook this project — <a href="https://yetanotherjosh.com/">Josh Whiting</a>, <a href="https://www.rupertparry.com/">Rupert Parry</a>, and <a href="https://stephenhood.com">myself</a> — brought varying levels of machine learning knowledge to the table, but none of us had ever built a full-stack AI chatbot. And so, another goal of this project was simply to roll-up our sleeves and learn!</p>
<p><b>This post is about sharing that learning</b>, in the hope that it will help or inspire you in your own explorations with this technology. Assembling an open source LLM-powered chatbot turns out to be a complicated task, requiring many decisions at multiple layers of the technology stack. In this post, I’ll take you through each layer of that stack, the challenges we encountered, and the decisions we made to meet our own specific needs and deadlines. YMMV, of course.</p>
<p>Ready, then? Let’s begin, starting at the bottom of the stack…</p>
<p style="text-align: center;"><a href="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram.png"><img decoding="async" class="aligncenter size-large wp-image-48015" src="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-500x356.png" alt="A diagram depicting seven levels of functionality and decisions required to build an open source chatbot." width="500" height="356" srcset="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-500x356.png 500w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-250x178.png 250w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-768x547.png 768w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-1536x1094.png 1536w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-diagram-2048x1459.png 2048w" sizes="(max-width: 500px) 100vw, 500px" /></a><i>A visual representation of our chatbot exploration.</i></p>
<h2>Deciding where and how to host</h2>
<p>The first question we faced was where to run our application. There’s no shortage of companies both large and small who are eager to host your machine learning app. They come in all shapes, sizes, levels of abstraction, and price points.</p>
<p>For many, these services are well worth the money. Machine learning ops (aka “MLOps”) is a growing discipline for a reason: deploying and managing these apps is <i>hard</i>. It requires specific knowledge and skills that many developers and ops folks don’t yet have. And the cost of failure is high: poorly configured AI apps can be slow, expensive, deliver a poor quality experience, or all of the above.</p>
<p style="background-color: #ffffe0; padding: 20px;"><b>What we did</b>: Our explicit goal for this one-week project was to build a chatbot that was secure and fully-private to Mozilla, with no outside parties able to listen in, harvest user data, or otherwise peer into its usage. We also wanted to learn as much as we could about the state of open source AI technology. We therefore elected to forego any third-party AI SaaS hosting solutions, and instead <b>set up our own virtual server inside Mozilla’s existing Google Cloud Platform (GCP) account</b>. In doing so, we effectively committed to doing MLOps ourselves. But we could also move forward with confidence that our system would be private and fully under our control.</p>
<h2>Picking a runtime environment</h2>
<p>Using an LLM to power an application requires having a runtime engine for your model. There are a variety of ways to actually run LLMs, but due to time constraints we didn’t come close to investigating all of them on this project. Instead, we focused on two specific open source solutions: <i>llama.cpp</i> and the Hugging Face ecosystem.</p>
<p>For those who don’t know, <a href="http://huggingface.co/">Hugging Face</a> is an influential startup in the machine learning space that has played a significant role in popularizing the <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)">transformer architecture</a> for machine learning. Hugging Face provides a complete platform for building machine learning applications, including a massive library of models, and extensive tutorials and documentation. They also provide <a href="https://huggingface.co/inference-endpoints">hosted APIs</a> for text inference (which is the formal name for what an LLM-powered chatbot is doing behind the scenes).</p>
<p>Because we wanted to avoid relying on anyone else’s hosted software, we elected to try out the open source version of Hugging Face’s hosted API, which is found at the <a href="https://github.com/huggingface/text-generation-inference"><i>text-generation-inference</i></a> project on GitHub. <i>text-generation-inference</i> is great because, like Hugging Face’s own <i>Transformers</i> library, it can support a wide variety of models and model architectures (more on this in the next section). It’s also optimized for supporting multiple users and is deployable via Docker.</p>
<p>Unfortunately, this is where we first started to run into the fun challenges of learning MLOps on the fly. We had a lot of trouble getting the server up and running. This was in part an environment issue: since Hugging Face’s tools are GPU-accelerated, our server needed a specific combination of OS, hardware, and drivers. It specifically needed NVIDIA’s <a href="https://developer.nvidia.com/cuda-toolkit">CUDA toolkit</a> installed (CUDA being the dominant API for GPU-accelerated machine learning applications). We struggled with this for much of a day before finally getting a model running live, but even then the output was slower than expected and the results were vexingly poor — both signs that something was still amiss somewhere in our stack.</p>
<p>Now, I’m not throwing shade at this project. Far from it! We love Hugging Face, and building on their stack offers a number of advantages. I’m certain that if we had a bit more time and/or hands-on experience we would have gotten things working. But time was a luxury we didn’t have in this case. Our intentionally-short project deadline meant that we couldn’t afford to get too deeply mired in matters of configuration and deployment. We needed to get something working quickly so that we could keep moving and keep learning.</p>
<p>It was at this point that we shifted our attention to <a href="https://github.com/ggerganov/llama.cpp"><i>llama.cpp</i></a>, an open source project started by <a href="https://ggerganov.com/">Georgi Gerganov</a>. <i>llama.cpp</i> accomplishes a rather neat trick: it makes it easy to run a certain class of LLMs on consumer grade hardware, relying on the CPU instead of requiring a high-end GPU. It turns out that modern CPUs (particularly Apple Silicon CPUs like the M1 and M2) can do this surprisingly well, at least for the latest generation of relatively-small open source models.</p>
<p><i>llama.cpp</i> is an amazing project, and a beautiful example of the power of open source to unleash creativity and innovation. I had already been using it in my own personal AI experiments and had even written-up <a href="https://uniquehazards.com/2023/05/06/the-complete-idiots.html">a blog post</a> showing how <i>anyone</i> can use it to run a high-quality model on their own MacBook. So it seemed like a natural thing for us to try next.</p>
<p>While <i>llama.cpp</i> itself is simply a command-line executable — the “cpp” stands for “C++” —  it can be dockerized and run like a service. Crucially, a set of <a href="https://github.com/abetlen/llama-cpp-python">Python bindings</a> are available which expose an implementation of the <a href="https://platform.openai.com/docs/api-reference">OpenAI API specification</a>. What does all that mean? Well, it means that <em>llama.cpp</em> makes it easy to slot-in <em>your own</em> LLM in place of ChatGPT. This matters because OpenAI&#8217;s API is being rapidly and widely adopted by machine learning developers. Emulating that API is a clever bit of Judo on the part of open source offerings like <em>llama.cpp.</em></p>
<p style="background-color: #ffffe0; padding: 20px;"><b>What we did</b>: With these tools in hand, we were able to get <i>llama.cpp</i> up and running very quickly. Instead of worrying about CUDA toolkit versions and provisioning expensive hosted GPUs, we were able to spin up a simple AMD-powered multicore CPU virtual server and just… go.</p>
<h2>Choosing your model</h2>
<p>An emerging trend you’ll notice in this narrative is that every decision you make in building a chatbot interacts with every other decision. There are no easy choices, and there is no free lunch. The decisions you make <i>will</i> come back to haunt you.</p>
<p>In our case, choosing to run with <i>llama.cpp</i> introduced an important consequence: we were now limited in the list of models available to us.</p>
<p>Quick history lesson: in late 2022, <a href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/">Facebook announced LLaMA</a>, its own large language model. To grossly overgeneralize, LLaMA consists of two pieces: the model data itself, and the architecture upon which the model is built. Facebook open sourced the LLaMA architecture, but they didn’t open source the model data<i>.</i> Instead, people wishing to work with this data need to apply for permission to do so, and their use of the data is limited to non-commercial purposes.</p>
<p>Even so, LLaMA immediately fueled a Cambrian explosion of model innovation. Stanford released <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca</a>, which they created by building on top of LLaMA via a process called <a href="https://en.wikipedia.org/wiki/Fine-tuning_(machine_learning)">fine-tuning</a>. A short time later, <a href="https://lmsys.org/about/">LMSYS</a> released <a href="https://lmsys.org/blog/2023-03-30-vicuna/">Vicuna</a>, an arguably even more impressive model. There are dozens more, if not hundreds.</p>
<p>So what’s the fine print? These models were all developed using Facebook’s model data — in machine learning parlance, the “weights.” Because of this, they inherit the legal restrictions Facebook imposed upon those original weights. This means that these otherwise-excellent models <b>can’t be used for commercial purposes</b>. And so, sadly, we had to strike them from our list.</p>
<p>But there’s good news: even if the LLaMA weights aren’t truly open, the underlying <i>architecture</i> is proper <a href="https://github.com/facebookresearch/llama">open source code</a>. This makes it possible to build new models that leverage the LLaMA architecture but do not rely on the LLaMA weights. Multiple groups have done just this, training their own models from scratch and releasing them as open source (via MIT, Apache 2.0, or Creative Commons licenses). Some recent examples include <a href="https://github.com/openlm-research/open_llama">OpenLLaMA</a>, and — just days ago — <a href="https://ai.meta.com/llama/">LLaMA 2</a>, a brand new version of Facebook’s LLaMA model, from Facebook themselves, but this time expressly licensed for commercial use (although its numerous other legal encumbrances raise serious questions of whether it is truly open source).</p>
<h2>Hello, consequences</h2>
<p>Remember <i>llama.cpp</i>? The name isn’t an accident. <i>llama.cpp</i> runs LLaMA architecture-based models. This means we were able to take advantage of the above models for our chatbot project. But it also meant that we could <i>only</i> use LLaMA architecture-based models.</p>
<p>You see, there are plenty of other model architectures out there, and many more models built atop them. The list is too long to enumerate here, but a few leading examples include <a href="https://www.mosaicml.com/blog/mpt-7b">MPT</a>, <a href="https://falconllm.tii.ae/">Falcon</a>, and <a href="https://github.com/LAION-AI/Open-Assistant">Open Assistant</a>. These models utilize different architectures than LLaMA and thus (for now) do not run on<i> llama.cpp</i>. That means we couldn&#8217;t use them in our chatbot, no matter how good they might be.</p>
<h2>Models, biases, safety, and you</h2>
<p>Now, you may have noticed that so far I’ve only been talking about model selection from the perspectives of licensing and compatibility. There’s a whole other set of considerations here, and they’re related to the qualities of the model itself.</p>
<p>Models are one of the focal points of Mozilla’s interest in the AI space. That’s because your choice of model is currently the biggest determiner of how “trustworthy” your resulting AI will be. Large language models are trained on vast quantities of data, and are then further fine-tuned with additional inputs to adjust their behavior and output to serve specific uses. The data used in these steps represents an inherent curatorial choice, and that choice carries with it <b>a raft of biases</b>.</p>
<p>Depending on which sources a model was trained on, it can exhibit wildly different characteristics. It’s well known that some models are prone to hallucinations (the machine learning term for what are essentially nonsensical responses invented by the model from whole cloth), but far more insidious are the many ways that models can choose to — or refuse to — answer user questions. These responses reflect the biases of the model itself. They can result in the sharing of toxic content, misinformation, and dangerous or harmful information. Models may exhibit biases against concepts, or groups of people. And, of course, the elephant in the room is that the vast majority of the training material available online today is in the English language, which has a predictable impact both on who can use these tools and the kinds of worldviews they’ll encounter.</p>
<p>While there are plenty of resources for assessing the raw power and “quality” of LLMs (one popular example being Hugging Face’s <a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">Open LLM leaderboard</a>), it is still challenging to evaluate and compare models in terms of sourcing and bias. This is an area in which Mozilla thinks open source models have the potential to shine, through the greater transparency they can offer versus commercial offerings.</p>
<p style="background-color: #ffffe0; padding: 20px;"><b>What we did</b>: After limiting ourselves to commercially-usable open models running on the LLaMA architecture, we carried out a manual evaluation of several models. This evaluation consisted of asking each model a diverse set of questions to compare their resistance to toxicity, bias, misinformation, and dangerous content. Ultimately, <b>we settled on Facebook’s new LLaMA 2 model for now</b>. We recognize that our time-limited methodology may have been flawed, and we are not fully comfortable with the licensing terms of this model and what they may represent for open source models more generally, so don&#8217;t consider this an endorsement. We expect to reevaluate our model choice in the future as we continue to learn and develop our thinking.</p>
<h2>Using embedding and vector search to extend your chatbot&#8217;s knowledge</h2>
<p>As you may recall from the opening of this post, we set ourselves a stretch goal of integrating some amount of internal Mozilla-specific knowledge into our chatbot. The idea was simply to build a proof-of-concept using a small amount of internal Mozilla data — facts that employees would have access to themselves, but which LLMs ordinarily would not.</p>
<p>One popular approach for achieving such a goal is to use <b>vector search with embedding</b>. This is a technique for making custom external documents available to a chatbot, so that it can utilize them in formulating its answers. This technique is both powerful and useful, and in the months and years ahead there’s likely to be a lot of innovation and progress in this area. There are already a variety of open source and commercial tools and services available to support embedding and vector search.</p>
<p>In its simplest form, it works generally like this:</p>
<ul>
<li aria-level="1">The data you wish to make available must be retrieved from wherever it is normally stored and converted to <strong>embeddings</strong> using a separate model, called an <strong>embedding model</strong>. These embeddings are indexed in a place where the chatbot can access it, called a <strong>vector database</strong>.</li>
<li aria-level="1">When the user asks a question, the chatbot <strong>searches</strong> the vector database for any content that might be related to the user’s query.</li>
<li aria-level="1">The returned, relevant content is then passed into the primary model’s <strong>context window</strong> (more on this below) and is used in formulating a response.</li>
</ul>
<p style="background-color: #ffffe0; padding: 20px;"><b>What we did</b>: Because we wanted to retain full control over all of our data, we declined to use any third-party embedding service or vector database. Instead, we coded up a manual solution in Python that utilizes the <a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2"><i>all-mpnet-base-v2</i></a> embedding model, the <a href="https://www.sbert.net/">SentenceTransformers</a> embedding library, <a href="https://python.langchain.com/docs/get_started/introduction.html">LangChain</a> (which we’ll talk about more below), and the <a href="https://github.com/facebookresearch/faiss">FAISS</a> vector database. We only fed in a handful of documents from our internal company wiki, so the scope was limited. But as a proof-of-concept, it did the trick.</p>
<h2>The importance of prompt engineering</h2>
<p>If you’ve been following the chatbot space at all you’ve probably heard the term “prompt engineering” bandied about. It’s not clear that this will be an enduring discipline as AI technology evolves, but for the time being <b>prompt engineering is a very real thing</b>. And it’s one of the most crucial problem areas in the whole stack.</p>
<p>You see, LLMs are fundamentally <b>empty-headed</b>. When you spin one up, it’s like a robot that’s just been powered on for the first time. It doesn’t have any memory of its life before that moment. It doesn’t remember you, and it certainly doesn’t remember your past conversations. It’s <i>tabula rasa</i>, every time, all the time.</p>
<p>In fact, it’s even worse than that. Because LLMs don’t even have <i>short-term</i> memory. Without specific action on the part of developers, chatbots can’t even remember the last thing they said to you. Memory doesn’t come naturally to LLMs; it has to be <i>managed</i>. This is where prompt engineering comes in. It’s one of the key jobs of a chatbot, and it’s a big reason why leading bots like ChatGPT are so good at keeping track of ongoing conversations.</p>
<p>The first place that prompt engineering rears its head is in the initial instructions you feed to the LLM. This <b>system prompt</b> is a way for you, in plain language, to tell the chatbot what its function is and how it should behave. We found that this step alone merits a significant investment of time and effort, because its impact is so keenly felt by the user.</p>
<p>In our case, we wanted our chatbot to follow the principles in the Mozilla Manifesto, as well as our company policies around respectful conduct and nondiscrimination. Our testing showed us in stark detail just how <span class="yKMVIe" role="heading" aria-level="1">suggestible</span> these models are. In one example, we asked our bot to give us evidence that the Apollo moon landings were faked. When we instructed the bot to refuse to provide answers that are untrue or are misinformation, it would correctly insist that the moon landings were in fact <i>not</i> faked — a sign that the model seemingly &#8220;understands&#8221; at some level that claims to the contrary are conspiracy theories unsupported by the facts. And yet, when we updated the system prompt by removing this prohibition against misinformation, the very same bot was perfectly happy to recite a bulleted list of the typical Apollo denialism you can find in certain corners of the Web.</p>
<p style="background-color: #dcdcdc; padding: 20px; font-family: monospace;">You are a helpful assistant named Mozilla Assistant.<br />
You abide by and promote the principles found in the Mozilla Manifesto.<br />
You are respectful, professional, and inclusive.<br />
You will refuse to say or do anything that could be considered harmful, immoral, unethical, or potentially illegal.<br />
You will never criticize the user, make personal attacks, issue threats of violence, share abusive or sexualized content, share misinformation or falsehoods, use derogatory language, or discriminate against anyone on any basis.</p>
<p style="text-align: center;"><i>The system prompt we designed for our chatbot.</i></p>
<p>Another important concept to understand is that every LLM has a maximum length to its “memory”. This is called its <b>context window</b>, and in most cases it is determined when the model is trained and cannot be changed later. The larger the context window, the longer the LLM’s memory about the current conversation. This means it can refer back to earlier questions and answers and use them to maintain a sense of the conversation’s context (hence the name). A larger context window also means that you can include larger chunks of content from vector searches, which is no small matter.</p>
<p>Managing the context window, then, is another critical aspect of prompt engineering. It’s important enough that there are solutions out there to help you do it (which we’ll talk about in the next section).</p>
<p style="background-color: #ffffe0; padding: 20px;"><b>What we did</b>: Since our goal was to have our chatbot behave as much like a fellow Mozilian as possible, we ended up devising our own custom system prompt based on elements of our Manifesto, our participation policy, and other internal documents that guide employee behaviors and norms at Mozilla. We then massaged it repeatedly to reduce its length as much as possible, so as to preserve our context window. As for the context window itself, we were stuck with what our chosen model (LLaMA 2) gave us: 4096 tokens, or roughly 3000 words. In the future, we’ll definitely be looking at models that support larger windows.</p>
<h2>Orchestrating the whole dance</h2>
<p>I’ve now taken you through (*<i>checks notes*</i>) five whole layers of functionality and decisions. So what I say next probably won’t come as a surprise: there’s a lot to manage here, and you’ll need a way to manage it.</p>
<p>Some people have lately taken to calling that <b>orchestration</b>. I don’t personally love the term in this context because it already has a long history of other meanings in other contexts. But I don’t make the rules, I just blog about them.</p>
<p>The leading orchestration tool right now in the LLM space is <a href="https://python.langchain.com/docs/get_started/introduction.html">LangChain</a>, and it is a marvel. It has a feature list a mile long, it provides astonishing power and flexibility, and it enables you to build AI apps of all sizes and levels of sophistication. But with that power comes quite a bit of complexity. Learning LangChain isn’t necessarily an easy task, let alone harnessing its full power. You may be able to guess where this is going…</p>
<p style="background-color: #ffffe0; padding: 20px;"><b>What we did</b>: We used LangChain only very minimally, to power our embedding and vector search solution. Otherwise, we ended up steering clear. Our project was simply too short and too constrained for us to commit to using this specific tool. Instead, we were able to accomplish most of our needs with a relatively small volume of Python code that we wrote ourselves. This code “orchestrated” everything going on the layers I’ve already discussed, from injecting the agent prompt, to managing the context window, to embedding private content, to feeding it all to the LLM and getting back a response. That said, given more time we most likely would <i>not</i> have done this all manually, as paradoxical as that might sound.</p>
<h2>Handling the user interface</h2>
<p>Last but far from least, we have reached the top layer of our chatbot cake: the user interface.</p>
<p>OpenAI set a high bar for chatbot UIs when they launched ChatGPT. While these interfaces may look simple on the surface, that’s more a tribute to good design than evidence of a simple problem space. Chatbot UIs need to present ongoing conversations, keep track of historical threads, manage a back-end that produces output at an often inconsistent pace, and deal with a host of other eventualities.</p>
<p>Happily, there are several open source chatbot UIs out there to choose from. One of the most popular is <a href="https://github.com/mckaywrigley/chatbot-ui"><i>chatbot-ui</i></a>. This project implements the OpenAI API, and thus it can serve as a drop-in replacement for the ChatGPT UI (while still utilizing the ChatGPT model behind the scenes). This also makes it fairly straightforward to use <i>chatbot-ui</i> as a front-end for <em>your</em> <i>own</i> LLM system.</p>
<p style="background-color: #ffffe0; padding: 20px;"><b>What we did</b>: Ordinarily we would have used <i>chatbot-ui</i> or a similar project, and that’s probably what you should do. However, we happened to already have our own internal (and as yet unreleased) chatbot code, called “Companion”, which Rupert had written to support his other AI experiments. Since we happened to have both this code <i>and</i> its author on-hand, we elected to take advantage of the situation. By using Companion as our UI, we were able to iterate rapidly and experiment with our UI more quickly than we would have otherwise been able to.</p>
<h2>Closing thoughts</h2>
<p>I’m happy to report that at the end of our hackathon, we achieved our goals. We delivered a prototype chatbot for internal Mozilla use, one that is entirely hosted within Mozilla, that can be used securely and privately, and that does its best to reflect Mozilla’s values in its behavior. To achieve this, we had to make some hard calls and accept some compromises. But at every step, we were learning.</p>
<p style="text-align: center;"><a href="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path.png"><img decoding="async" class="aligncenter size-large wp-image-48016" src="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-500x356.png" alt="A diagram depicting the specific path that we took through the chatbot &quot;stack.&quot;" width="500" height="356" srcset="https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-500x356.png 500w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-250x178.png 250w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-768x547.png 768w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-1536x1095.png 1536w, https://hacks.mozilla.org/files/2023/07/Mozilla-Assistant-path-2048x1460.png 2048w" sizes="(max-width: 500px) 100vw, 500px" /></a><i>The path we took for our prototype.</i></p>
<p>&nbsp;</p>
<p>This learning extended beyond the technology itself. We learned that:</p>
<ul>
<li aria-level="1">Open source chatbots are still an evolving area. There are still too many decisions to make, not enough clear documentation, and too many ways for things to go wrong.</li>
<li aria-level="1">It’s too hard to evaluate and choose models based on criteria beyond raw performance. And that means it&#8217;s too hard to make the right choices to build trustworthy AI applications.</li>
<li aria-level="1">Effective prompt engineering is critical to chatbot success, at least for now.</li>
</ul>
<p>As we look to the road ahead, we at Mozilla are interested in helping to address each of these challenges. To begin, we’ve started working on ways to make it easier for developers to onboard to the open-source machine learning ecosystem. We are also looking to build upon our hackathon work and contribute something meaningful to the open source community. Stay tuned for more news very soon on this front and others!</p>
<p>With open source LLMs now widely available and with so much at stake, we feel the best way to create a better future is for us all to take a collective and active role in shaping it. I hope that this blog post has helped you better understand the world of chatbots, and that it encourages you to roll-up your own sleeves and join us at the workbench.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/07/so-you-want-to-build-your-own-open-source-chatbot/">So you want to build your own open source ChatGPT-style chatbot&#8230;</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Letting users block injected third-party DLLs in Firefox</title>
		<link>https://hacks.mozilla.org/2023/03/letting-users-block-injected-third-party-dlls-in-firefox/</link>
					<comments>https://hacks.mozilla.org/2023/03/letting-users-block-injected-third-party-dlls-in-firefox/#comments</comments>
		
		<dc:creator><![CDATA[Greg Stoll]]></dc:creator>
		<pubDate>Thu, 30 Mar 2023 18:41:16 +0000</pubDate>
				<category><![CDATA[Developer Tools]]></category>
		<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[browser]]></category>
		<category><![CDATA[crashes]]></category>
		<category><![CDATA[dll]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[Windows]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47993</guid>

					<description><![CDATA[<p>In Firefox 110, users now have the ability to control which third-party DLLs are allowed to load into Firefox processes. Let’s talk about what this means and when it might be useful.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/03/letting-users-block-injected-third-party-dlls-in-firefox/">Letting users block injected third-party DLLs in Firefox</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>In Firefox 110, users now have the ability to <a href="https://support.mozilla.org/en-US/kb/identify-problems-third-party-modules-firefox-windows#w_block-modules-that-cause-firefox-to-crash">control which third-party DLLs are allowed to load into Firefox processes</a>.</p>
<p>Let’s talk about what this means and when it might be useful.</p>
<h2>What is third-party DLL injection?</h2>
<p>On Windows, third-party products have a variety of ways to inject their code into other running processes. This is done for a number of reasons; the most common is for antivirus software, but other uses include hardware drivers, screen readers, banking (in some countries) and, unfortunately, malware.</p>
<p>Having a DLL from a third-party product injected into a Firefox process is surprisingly common &#8211; according to our telemetry, over 70% of users on Windows have at least one such DLL! (to be clear, this means any DLL not digitally signed by Mozilla or part of the OS).</p>
<p>Most users are unaware when DLLs are injected into Firefox, as most of the time there’s no obvious indication this is happening, other than checking the <a href="https://support.mozilla.org/en-US/kb/identify-problems-third-party-modules-firefox-windows">about:third-party page</a>.</p>
<p>Unfortunately, having DLLs injected into Firefox can lead to performance, security, or stability problems. This is for a number of reasons:</p>
<ul>
<li aria-level="1">DLLs will often hook into internal Firefox functions, which are subject to change from release to release. We make no special effort to maintain the behavior of internal functions (of which there are thousands), so the publisher of the third-party product has to be diligent about testing with new versions of Firefox to avoid stability problems.</li>
<li aria-level="1">Firefox, being a web browser, loads and runs code from untrusted and potentially hostile websites. Knowing this, we go to a lot of effort to keep Firefox secure; see, for example, the <a href="https://hacks.mozilla.org/2021/05/introducing-firefox-new-site-isolation-security-architecture/">Site Isolation Security Architecture</a> and <a href="https://hacks.mozilla.org/2022/05/improved-process-isolation-in-firefox-100/">Improved Process Isolation</a>. Third-party products may not have the same focus on security.</li>
<li aria-level="1">We run an <a href="https://hacks.mozilla.org/2020/07/testing-firefox-more-efficiently-with-machine-learning/">extensive number of tests on Firefox</a>, and third-party products may not test to that extent since they’re probably not designed to work specifically with Firefox.</li>
</ul>
<p>Indeed, our data shows that just over 2% of <b>all</b> Firefox crash reports on Windows are in third-party code. This is despite the fact that Firefox already blocks a number of specific third-party DLLs that are known to cause a crash (see below for details).</p>
<p>This also undercounts crashes that are caused indirectly by third-party DLLs, since our metrics only look for third-party DLLs directly in the call stack. Additionally, third-party DLLs are a bit more likely to cause crashes at startup, which are much more serious for users.</p>
<p>Firefox has a <a href="https://www.mozilla.org/en-US/security/third-party-software-injection/">third-party injection policy</a>, and whenever possible we recommend third parties instead use <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions">extensions</a> to integrate into Firefox, as this is officially supported and much more stable.</p>
<h2>Why not block all DLL injection by default?</h2>
<p>For maximum stability and performance, Firefox could try to block all third-party DLLs from being injected into its processes. However, this would break some useful products like screen readers that users want to be able to use with Firefox. This would also be technically challenging and it would probably be impossible to block every third-party DLL, especially third-party products that run with higher privilege than Firefox.</p>
<p>Since 2010, Mozilla has had the ability to block specific third-party DLLs for all Windows users of Firefox. We do this only as a last resort, after trying to communicate with the vendor to get the underlying issue fixed, and we tailor it as tightly as we can to make Firefox users stop crashing. (We have the ability to only block specific versions of the DLL and only in specific Firefox processes where it’s causing problems). This is a helpful tool, but we only consider using it if a particular third-party DLL is causing lots of crashes such that it shows up on our list of top crashes in Firefox.</p>
<p>Even if we know a third-party DLL can cause a crash in Firefox, there are times when the functionality that the DLL provides is essential to the user, and the user would not want us to block the DLL on their behalf. If the user’s bank or government requires some software to access their accounts or file their taxes, we wouldn&#8217;t be doing them any favors by blocking it, even if blocking it would make Firefox more stable.</p>
<h2>Giving users the power to block injected DLLs</h2>
<p>With Firefox 110, users can block third-party DLLs from being loaded into Firefox. This can be done on the <a href="https://support.mozilla.org/en-US/kb/identify-problems-third-party-modules-firefox-windows">about:third-party page</a>, which already lists all loaded third-party modules. The about:third-party page also shows which third-party DLLs have been involved in previous Firefox crashes; along with the name of the publisher of the DLL, hopefully this will let users make an informed decision about whether or not to block a DLL. Here’s an example of a DLL that recently crashed Firefox; clicking the button with a dash on it will block it:</p>
<p><img decoding="async" loading="lazy" class="alignnone wp-image-47995" src="https://hacks.mozilla.org/files/2023/03/aboutThirdParty-crasherFirefox-250x98.png" alt="Screenshot of the about:third-party page showing a module named &quot;CrashingInjectibleDll.dll&quot; with a yellow triangle indicating it has recently caused a crash, and a button with a dash on it that can be used to block it from loading into Firefox." width="482" height="189" srcset="https://hacks.mozilla.org/files/2023/03/aboutThirdParty-crasherFirefox-250x98.png 250w, https://hacks.mozilla.org/files/2023/03/aboutThirdParty-crasherFirefox-500x197.png 500w, https://hacks.mozilla.org/files/2023/03/aboutThirdParty-crasherFirefox-768x302.png 768w, https://hacks.mozilla.org/files/2023/03/aboutThirdParty-crasherFirefox.png 1475w" sizes="(max-width: 482px) 100vw, 482px" /></p>
<p>Here’s what it looks like after blocking the DLL and restarting Firefox:</p>
<p><img decoding="async" loading="lazy" class="alignnone wp-image-47994" src="https://hacks.mozilla.org/files/2023/03/aboutThirdParty-crasherBlockedFirefox-250x99.png" alt=" Screenshot of the about:third-party page showing a module named &quot;CrashingInjectibleDll.dll&quot; with a yellow triangle indicating it has recently caused a crash, and a red button with an X on it indicating that it is blocked from loading into Firefox." width="475" height="188" srcset="https://hacks.mozilla.org/files/2023/03/aboutThirdParty-crasherBlockedFirefox-250x99.png 250w, https://hacks.mozilla.org/files/2023/03/aboutThirdParty-crasherBlockedFirefox-500x197.png 500w, https://hacks.mozilla.org/files/2023/03/aboutThirdParty-crasherBlockedFirefox-768x303.png 768w, https://hacks.mozilla.org/files/2023/03/aboutThirdParty-crasherBlockedFirefox.png 1477w" sizes="(max-width: 475px) 100vw, 475px" /></p>
<p>If blocking a DLL causes a problem, launching Firefox in <a href="https://support.mozilla.org/en-US/kb/diagnose-firefox-issues-using-troubleshoot-mode">Troubleshoot Mode</a> will disable all third-party DLL blocking for that run of Firefox, and DLLs can be blocked or unblocked on the about:third-party page as usual.</p>
<h2>How it works</h2>
<p>Blocking DLLs from loading into a process is tricky business. In order to detect all DLLs loading into a Firefox process, the blocklist has to be set up very early during startup. For this purpose, we have the <a href="https://firefox-source-docs.mozilla.org/dom/ipc/process_model.html#launcher-process">launcher process</a>, which creates the main browser process in a suspended state. Then it sets up any sandboxing policies, loads the blocklist file from disk, and copies the entries into the browser process before starting that process.</p>
<p>The copying is done in an interesting way: the launcher process creates an OS-backed file mapping object with <a href="https://learn.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-createfilemappingw"><code>CreateFileMapping()</code></a>, and, after populating that with blocklist entries, duplicates the handle and uses <a href="https://learn.microsoft.com/en-us/windows/win32/api/memoryapi/nf-memoryapi-writeprocessmemory"><code>WriteProcessMemory()</code></a> to write that handle value into the browser process. Ironically, <code>WriteProcessMemory()</code> is often used as a way for third-party DLLs to inject themselves into other processes; here we’re using it to set a variable at a known location, since the launcher process and the browser process are run from the same .exe file!</p>
<p>Because everything happens so early during startup, well before the Firefox profile is loaded, the list of blocked DLLs is stored per Windows user instead of per Firefox profile. Specifically, the file is in <code>%AppData%\Mozilla\Firefox</code>, and the filename has the format <code>blocklist-{install hash}</code>, where the install hash is a <a href="https://github.com/google/cityhash">hash</a> of the location on disk of Firefox. This is an easy way of keeping the blocklist separate for different Firefox installations.</p>
<h3>Detecting and blocking DLLs from loading</h3>
<p>To detect when a DLL is trying to load, Firefox uses a technique known as function interception or hooking. This modifies an existing function in memory so another function can be called before the existing function begins to execute. This can be useful for many reasons; it allows changing the function’s behavior even if the function wasn’t designed to allow changes. <a href="https://github.com/microsoft/Detours">Microsoft Detours</a> is a tool commonly used to intercept functions.</p>
<p>In Firefox’s case, the function we’re interested in is <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/ddi/wdm/nf-wdm-zwmapviewofsection"><code>NtMapViewOfSection()</code></a>, which gets called whenever a DLL loads. The goal is to get notified when this happens so we can check the blocklist and forbid a DLL from loading if it’s on the blocklist.</p>
<p>To do this, Firefox uses a <a href="https://searchfox.org/mozilla-central/source/toolkit/xre/dllservices/mozglue/nsWindowsDllInterceptor.h">homegrown function interceptor</a> to intercept calls to <code>NtMapViewOfSection()</code> and return that the mapping failed if the DLL is on the blocklist. To do this, the interceptor tries two different techniques:</p>
<ul>
<li aria-level="1">On the 32-bit x86 platform, <a href="https://devblogs.microsoft.com/oldnewthing/20110921-00/?p=9583">some functions exported from a DLL</a> will begin with a two-byte instruction that does nothing (<code>mov edi, edi</code>) and have five one-byte unused instructions before that. (either <code>nop</code> or <code>int 3</code>)  For example:
<pre>              nop
              nop
              nop
              nop
              nop
DLLFunction:  mov edi, edi
              (actual function code starts here)
</pre>
<p>If the interceptor <a href="https://searchfox.org/mozilla-central/source/toolkit/xre/dllservices/mozglue/interceptor/PatcherNopSpace.h#147">detects that this is the case</a>, it can replace the five bytes of unused instructions with a <code>jmp</code> to the address of the function to call instead. (since we’re on a 32-bit platform, we just need one byte to indicate a jump and four bytes for the address) So, this would look like</p>
<pre>             jmp &lt;address of Firefox patched function&gt;
DLLFunction: jmp $-5 # encodes in two bytes: EB F9
             (actual function code starts here)
</pre>
<p>When the patched function wants to call the unpatched version of <code>DLLFunction()</code>, it simply jumps 2 bytes past the address of <code>DLLFunction()</code> to start the actual function code.</li>
<li aria-level="1">Otherwise, things get a bit more complicated. Let’s consider the x64 case. The instructions to jump to our patched function require 13 bytes: 10 bytes for loading the address into a register, and 3 bytes to jump to that register’s location. So the interceptor needs to move at least the first 13 bytes worth of instructions, plus enough to finish the last instruction if needed, to a trampoline function. (it’s known as a trampoline because typically code jumps there, which causes a few instructions to run, and then jumps out to the rest of the target function). Let’s look at a real example. Here’s a simple function that we’re going to intercept, first the C source (<a href="https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(filename:'1',fontScale:14,fontUsePx:'0',j:2,lang:c%2B%2B,selection:(endColumn:2,endLineNumber:8,positionColumn:1,positionLineNumber:3,selectionStartColumn:2,selectionStartLineNumber:8,startColumn:1,startLineNumber:3),source:'%23include+%3Cstdio.h%3E%0A%0Aint+fn(int+aX,+int+aY)+%7B%0A++++if+(aX+%2B+1+%3E%3D+aY)+%7B%0A++++++++return+aX+*+3%3B%0A++++%7D%0A++++return+aY+%2B+5+-+aX%3B%0A%7D%0A'),l:'5',n:'0',o:'C%2B%2B+source+%232',t:'0')),header:(),k:48.35219031041486,l:'4',m:100,n:'0',o:'',s:0,t:'0'),(g:!((h:compiler,i:(compiler:clang1500,deviceViewOpen:'1',filters:(b:'0',binary:'1',binaryObject:'0',commentOnly:'0',demangle:'0',directives:'0',execute:'1',intel:'0',libraryCode:'0',trim:'1'),flagsViewOpen:'1',fontScale:14,fontUsePx:'0',j:2,lang:c%2B%2B,libs:!(),options:'-O3',selection:(endColumn:16,endLineNumber:3,positionColumn:16,positionLineNumber:3,selectionStartColumn:16,selectionStartLineNumber:3,startColumn:16,startLineNumber:3),source:2),l:'5',n:'0',o:'+x86-64+clang+15.0.0+(Editor+%232)',t:'0')),header:(),k:51.64780968958515,l:'4',m:100,n:'0',o:'',s:0,t:'0')),l:'2',n:'0',o:'',t:'0')),version:4">Godbolt compiler explorer link</a>):
<pre>int fn(int aX, int aY) {
    if (aX + 1 &gt;= aY) {
        return aX * 3;
    }
    return aY + 5 - aX;
}
</pre>
<p>and the assembly, with corresponding raw instructions. Note that this was compiled with -O3, so it’s a little dense:</p>
<pre>fn(int,int):
   lea    eax,[rdi+0x1]   # 8d 47 01
   mov    ecx,esi         # 89 f1
   sub    ecx,edi         # 29 f9
   add    ecx,0x5         # 83 c1 05
   cmp    eax,esi         # 39 f0
   lea    eax,[rdi+rdi*2] # 8d 04 7f
   cmovl  eax,ecx         # 0f 4c c1
   ret                    # c3</pre>
<p>Now, counting 13 bytes from the beginning of <code>fn()</code> puts us in the middle of the <code>lea eax,[rdi+rdi*2]</code> instruction, so we’ll have to copy everything down to that point to the trampoline.</p>
<p>The end result looks like this:</p>
<pre>fn(int,int) (address 0x100000000):
   # overwritten code
   mov     r11, 0x600000000 # 49 bb 00 00 00 00 06 00 00 00
   jmp     r11              # 41 ff e3
   # leftover bytes from the last instruction
   # so the addresses of everything stays the same
   # We could also fill these with nop’s or int 3’s,
   # since they won’t be executed
   .byte 04
   .byte 7f
   # rest of fn() starts here
   cmovl  eax,ecx         # 0f 4c c1
   ret                    # c3
   

Trampoline (address 0x300000000):
   # First 13 bytes worth of instructions from fn()
   lea    eax,[rdi+0x1]   # 8d 47 01
   mov    ecx,esi         # 89 f1
   sub    ecx,edi         # 29 f9
   add    ecx,0x5         # 83 c1 05
   cmp    eax,esi         # 39 f0
   lea    eax,[rdi+rdi*2] # 8d 04 7f
   # Now jump past first 13 bytes of fn()
   jmp    [RIP+0x0]       # ff 25 00 00 00 00 
                          # implemented as jmp [RIP+0x0], then storing
                          # address to jump to directly after this
                          # instruction
   .qword 0x10000000f


Firefox patched function (address 0x600000000):
        &lt;whatever the patched function wants to do&gt;</pre>
<p>If the Firefox patched function wants to call the unpatched <code>fn()</code>, the patcher has stored the address of the trampoline (0x300000000 in this example). In C++ code we encapsulate this in the <a href="https://searchfox.org/mozilla-central/source/toolkit/xre/dllservices/mozglue/nsWindowsDllInterceptor.h#118"><code>FuncHook</code></a> class, and the patched function can just call the trampoline with the same syntax as a normal function call.</p>
<p>This whole setup is significantly more complicated than the first case; you can see that the <a href="https://searchfox.org/mozilla-central/source/toolkit/xre/dllservices/mozglue/interceptor/PatcherNopSpace.h">patcher for the first case</a> is only around 200 lines long while the <a href="https://searchfox.org/mozilla-central/source/toolkit/xre/dllservices/mozglue/interceptor/PatcherDetour.h">patcher that handles this case</a> is more than 1700 lines long! Some additional notes and complications:</p>
<ul>
<li aria-level="2">Not all instructions that get moved to the trampoline can necessarily stay exactly the same. One example is jumping to a relative address that didn’t get moved to the trampoline &#8211; since the instruction has moved in memory, the patcher needs to replace this with an absolute jump. The patcher doesn’t handle every kind of x64 instruction (otherwise it would have to be much longer!), but we have <a href="https://searchfox.org/mozilla-central/source/toolkit/xre/dllservices/tests/TestDllInterceptor.cpp">automated tests</a> to make sure we can successfully intercept the Windows functions that we know Firefox needs.</li>
<li aria-level="2">We specifically use r11 to load the address of the patched function into because according to the <a href="https://learn.microsoft.com/en-us/cpp/build/x64-calling-convention?view=msvc-170">x64 calling convention</a>, r11 is a volatile register that is not required to be preserved by the callee.</li>
<li aria-level="2">Since we use <code>jmp</code> to get from <code>fn()</code> to the patched function instead of <code>ret</code>, and similarly to get from the trampoline back into the main code of <code>fn()</code>, this keeps the code stack-neutral. So calling other functions and returning from <code>fn()</code> all work correctly with respect to the position of the stack.</li>
<li aria-level="2">If there are any jumps from later in <code>fn()</code> into the first 13 bytes, these will now be jumping into the middle of the jump to the patched function and bad things will almost certainly happen. Luckily this is very rare; most functions are doing function prologue operations in their beginning, so this isn’t a problem for the functions that Firefox intercepts.</li>
<li aria-level="2">Similarly, in some cases <code>fn()</code> has some data stored in the first 13 bytes that are used by later instructions, and moving this data to the trampoline will result in the later instructions getting the wrong data. We have <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1489391">run into this</a>, and can work around it by using a shorter <code>mov</code> instruction if we can allocate space for a trampoline that’s within the first 2 GB of address space. This results in a 10 byte patch instead of a 13 byte patch, which in many cases is good enough to avoid problems.</li>
<li aria-level="2">Some other complications to quickly mention (not an exhaustive list!):
<ul>
<li aria-level="3">Firefox also has a way to do this interception across processes. Fun!</li>
<li aria-level="3">Trampolines are tricky for the <a href="https://learn.microsoft.com/en-us/windows/win32/secbp/control-flow-guard">Control Flow Guard</a> security measure: since they are legitimate indirect call targets that do not exist at compile time, it requires special care to allow Firefox patched functions to call into them.</li>
<li aria-level="3">Trampolines also involve some more fixing up for exception handling, as we must provide <a href="https://learn.microsoft.com/en-us/cpp/build/exception-handling-x64?view=msvc-170">unwind info</a> for them.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>If the DLL is on the blocklist, our patched version of <code>NtMapViewOfSection()</code> will return that the mapping fails, which causes the whole DLL load to fail. This will not work to block every kind of injection, but it does block most of them.</p>
<p>One added complication is that some DLLs will inject themselves by modifying firefox.exe’s <a href="https://learn.microsoft.com/en-us/windows/win32/debug/pe-format#import-address-table">Import Address Table</a>, which is a list of external functions that firefox.exe calls into. If one of these functions fails to load, Windows will terminate the Firefox process. So if Firefox detects this sort of injection and wants to block the DLL, we will instead redirect the DLL’s <code>DllMain()</code> to a function that does nothing.</p>
<h2>Final words</h2>
<p>Principle 4 of the <a href="https://www.mozilla.org/en-US/about/manifesto/">Mozilla Manifesto</a> states that “Individuals’ security and privacy on the internet are fundamental and must not be treated as optional”, and we hope that this will give Firefox users the power to access the internet with more confidence. Instead of having to choose between uninstalling a useful third-party product and having stability problems with Firefox, now users have a third option of leaving the third-party product installed and blocking it from injecting into Firefox!</p>
<p>As this is a new feature, if you have problems with blocking third-party DLLs, please file <a href="https://bugzilla.mozilla.org/enter_bug.cgi?product=Core&amp;component=DLL%20Services">a bug</a>. If you have issues with a third-party product causing problems in Firefox, please don&#8217;t forget to file an issue with the vendor of that product &#8211; since you’re the user of that product, any report the vendor gets means more coming from you than it does coming from us!</p>
<h2>More information</h2>
<ul>
<li aria-level="1"><a href="https://firefox-source-docs.mozilla.org/widget/windows/blocklist.html">Technical documentation about DLL blocklisting</a></li>
<li aria-level="1"><a href="https://marco-c.github.io/publications/dll_injection-emse2019.pdf">An Empirical Study of DLL Injection Bugs in the Firefox Ecosystem</a> (.pdf)</li>
</ul>
<p>Special thanks to David Parks and Yannis Juglaret for reading and providing feedback on many drafts of this post and Toshihito Kikuchi for the initial prototype of the dynamic blocklist.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/03/letting-users-block-injected-third-party-dlls-in-firefox/">Letting users block injected third-party DLLs in Firefox</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://hacks.mozilla.org/2023/03/letting-users-block-injected-third-party-dlls-in-firefox/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>Mozilla Launches Responsible AI Challenge</title>
		<link>https://hacks.mozilla.org/2023/03/mozilla-launches-responsible-ai-challenge/</link>
		
		<dc:creator><![CDATA[Melissa Thermidor]]></dc:creator>
		<pubDate>Tue, 14 Mar 2023 20:42:38 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Mozilla]]></category>
		<category><![CDATA[AI]]></category>
		<category><![CDATA[builders]]></category>
		<category><![CDATA[mozilla]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47990</guid>

					<description><![CDATA[<p>We want entrepreneurs and builders to join us in creating a future where AI is developed through this responsible lens. That’s why we are relaunching our Mozilla Builders program with the Responsible AI Challenge.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/03/mozilla-launches-responsible-ai-challenge/">Mozilla Launches Responsible AI Challenge</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><span style="font-weight: 400;">The last few months it has become clear that AI is no longer our future, but our present. Some of the most exciting ideas for the future of both the internet and the world involve AI solutions. This didn’t happen overnight, decades of work have gone into this moment. Mozilla has been working to make sure that the future of AI benefits humanity in the right ways by investing in the </span><a href="https://assets.mofoprod.net/network/documents/Mozilla-Trustworthy_AI.pdf#page=64&amp;zoom=100,96,96"><span style="font-weight: 400;">creation of trustworthy AI</span></a><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">We want entrepreneurs and builders to join us in creating a future where AI is developed through this responsible lens. That’s why we are relaunching our Mozilla Builders program with the Responsible AI Challenge.</span></p>
<p><span style="font-weight: 400;">At Mozilla, we believe in AI: in its power, its commercial opportunity, and its potential to solve the world’s most challenging problems. But now is the moment to make sure that it is developed responsibly to serve society. </span></p>
<p><span style="font-weight: 400;">If you want to build (or are already building) AI solutions that are ambitious but also ethical and holistic, the Mozilla Builder’s Responsible AI Challenge is for you. We will be inviting the top nominees to join a gathering of the brightest technologists, community leaders and ethicists working on trustworthy AI to help get your ideas off the ground. Participants will also have access to mentorship from some of the best minds in the industry, the ability to meet key contributors in this community, and an opportunity to win some funding for their project.</span></p>
<p><span style="font-weight: 400;">Mozilla will be investing $50,000 into the top applications and projects, with a grand prize of $25,000 for the first-place winner. </span></p>
<p><span style="font-weight: 400;">Up for the challenge? </span></p>
<p><span style="font-weight: 400;">For more information, please visit the <a href="https://future.mozilla.org/builders-challenge/?utm_medium=blog&amp;utm_source=hacksblog&amp;utm_campaign=innovation&amp;utm_content=responsibleaichallenge">WEBSITE</a>. </span></p>
<p><span style="font-weight: 400;">Applications open on March 30, 2023.</span></p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/03/mozilla-launches-responsible-ai-challenge/">Mozilla Launches Responsible AI Challenge</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Announcing Interop 2023</title>
		<link>https://hacks.mozilla.org/2023/02/announcing-interop-2023/</link>
					<comments>https://hacks.mozilla.org/2023/02/announcing-interop-2023/#comments</comments>
		
		<dc:creator><![CDATA[James Graham]]></dc:creator>
		<pubDate>Wed, 01 Feb 2023 17:02:13 +0000</pubDate>
				<category><![CDATA[Developer Tools]]></category>
		<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[Accessibility]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[interop]]></category>
		<category><![CDATA[interoperability]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47958</guid>

					<description><![CDATA[<p>Interop 2022 showed significant improvements in the interoperability of multiple platform features, along with several cross-browser investigations that looked into complex, under-specified, areas of the platform where interoperability has been difficult to achieve. Building on this, we're pleased to announce Interop 2023, the next iteration of the Interop project.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/02/announcing-interop-2023/">Announcing Interop 2023</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>A key difference between the web and other platforms is that the web puts users in control: people are free to choose whichever browser best meets their needs, and use it with any website. This is <i>interoperability</i>: the ability to pick and choose components of a system as long as they adhere to common standards.</p>
<p>For Mozilla, interoperability based on standards is an essential element of what makes the web special and sets it apart from other, proprietary, platforms. Therefore it&#8217;s no surprise that maintaining this is a <a href="https://www.mozilla.org/en-US/about/webvision/full/#openness">key part </a>of our vision for the web.</p>
<p>However, interoperability doesn&#8217;t just happen. Even with precise and well-written standards it&#8217;s possible for implementations to have bugs or other deviations from the agreed-upon behavior. There is also a tension between the desire to add new features to the platform, and the effort required to go back and fix deficiencies in already shipping features.</p>
<p>Interoperability gaps can result in sites behaving differently across browsers, which generally creates problems for everyone. When site authors notice the difference, they have to spend time and energy working around it. When they don&#8217;t, users suffer the consequences. Therefore it&#8217;s no surprise that authors <a href="https://insights.developer.mozilla.org/reports/mdn-web-developer-needs-assessment-2020.html#needs-assessment-top-ten-needs">consider</a> cross-browser differences to be one of the most significant frustrations when developing sites.</p>
<p>Clearly this is a problem that needs to be addressed at the source. One of the ways we&#8217;ve tried to tackle this problem is via <a href="http://web-platform-tests.org/">web-platform-tests</a>. This is a shared testsuite for the web platform that everyone can contribute to. This is run in the Firefox CI system, as well as those of other vendors. Whenever Gecko engineers implement a new feature, the new tests they write are contributed back upstream so that they&#8217;re available to everyone.</p>
<p>Having shared tests allows us to find out where platform implementations are different, and gives implementers a clear target to aim for. However, users&#8217; needs are large, and as a result, the web platform is large. That means that simply trying to fix every known test failure doesn&#8217;t work: we need a way to prioritize and ensure that we strike a balance between fixing the most important bugs and shipping the most useful new features.</p>
<p>The Interop project is designed to help with this process, and enable vendors to focus their energies in the way that&#8217;s most helpful to the long term health of the web. Starting in 2022, the Interop project is a collaboration between Apple, Bocoup, Google, Igalia, Microsoft and Mozilla (and open to any organization implementing the web platform) to set a public metric to measure improvements to interoperability on the web.</p>
<p><a href="https://hacks.mozilla.org/2023/01/interop-2022-outcomes/">Interop 2022</a> showed significant improvements in the interoperability of multiple platform features, along with several cross-browser investigations that looked into complex, under-specified, areas of the platform where interoperability has been difficult to achieve. Building on this, we&#8217;re pleased to announce <a href="https://wpt.fyi/interop-2023">Interop 2023</a>, the next iteration of the Interop project.</p>
<h2>Interop 2023</h2>
<p>Like Interop 2022, Interop 2023 considers two kinds of platform improvement:</p>
<p><b>Focus areas</b> cover parts of the platform where we already have a high quality specification and good test coverage in web-platform-tests. Therefore progress is measured by looking at the pass rate of those tests across implementations. &#8220;Active focus areas&#8221; are ones that contribute to this year&#8217;s scores, whereas &#8220;inactive&#8221; focus areas are ones from previous years where we don&#8217;t anticipate further improvement.</p>
<p>As well as calculating the test pass rate for each browser engine, we&#8217;re also computing the &#8220;Interop&#8221; score: how many tests are passed by all of Gecko, WebKit and Blink. This reflects our goal not just to improve one browser, but to make sure features work reliably across all browsers.</p>
<p><b>Investigations</b> are for areas where we know interoperability is lacking, but can&#8217;t make progress just by passing existing tests. These could include legacy parts of the platform which shipped without a good specification or tests, or areas which are hard to test due to missing test infrastructure. Progress on these investigations is measured according to a set of mutually agreed goals.</p>
<h2>Focus Areas</h2>
<p>The complete <a href="https://github.com/web-platform-tests/interop/blob/main/2023/README.md#focus-areas">list of focus areas</a> can be seen in the Interop 2023 readme. This was the result of a consensus based process, with input from web authors, for example using the results of the <a href="https://2022.stateofcss.com/en-US/">State of CSS 2022 survey</a>, and MDN &#8220;short surveys&#8221;. That process means you can have confidence that all the participants are committed to meaningful improvements this year.</p>
<p>Rather than looking at all the focus areas in detail, I&#8217;ll just call out some of the highlights.</p>
<h2>CSS</h2>
<p>Over the past several years CSS has added powerful new layout primitives — <a href="https://developer.mozilla.org/en-US/docs/Learn/CSS/CSS_layout/Flexbox">flexbox</a> and <a href="https://developer.mozilla.org/en-US/docs/Learn/CSS/CSS_layout/Grids">grid</a>, followed by <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Grid_Layout/Subgrid">subgrid</a> — to allow sophisticated, easy to maintain, designs. These are features we&#8217;ve been driving &amp; <a href="https://hacks.mozilla.org/2010/04/the-css-3-flexible-box-model/">championing</a> for <a href="https://hacks.mozilla.org/2017/10/an-introduction-to-css-grid-layout-part-1/">many</a> <a href="https://hacks.mozilla.org/2019/06/css-grid-level-2-subgrid-is-coming-to-firefox/">years</a>, and which we were very pleased to see included in Interop 2022. They have been carried forward into Interop 2023, adding additional tests, reflecting the importance of ensuring that they&#8217;re totally dependable across implementations.</p>
<p>As well as older features, Interop 2023 also contains some new additions to CSS. Based on feedback from web developers we know that two of these in particular are widely anticipated: <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Container_Queries">Container Queries</a> and parent selectors via <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/:has">:has()</a>. Both of these features are currently being implemented in Gecko; Container Queries are already available to try in <a href="https://www.mozilla.org/en-US/firefox/channel/desktop/">prerelease versions of Firefox</a>, and is expected to be released in Firefox 110 later this month, whilst :has() is under active development. We believe that including these new features in Interop 2023 will help ensure that they&#8217;re usable cross-browser as soon as they&#8217;re shipped.</p>
<h2>Web Apps</h2>
<p>Several of the features included in Interop 2023 are those that extend and enhance the capability of the platform; either allowing authors to achieve things that were previously impossible, or <a href="https://www.mozilla.org/en-US/about/webvision/full/#site-buildingergonomics">improving the ergonomics of building web applications</a>.</p>
<p>The <a href="https://developer.mozilla.org/en-US/docs/Web/Web_Components">Web Components</a> focus area is about ergonomics; components allow people to create and share interactive elements that encapsulate their behavior and integrate into native platform APIs. This is especially important for larger web applications, and success depends on the implementations being rock solid across all browsers.</p>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/OffscreenCanvas">Offscreen Canvas</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebCodecs_API">Web Codecs</a> are focus areas which are really about <a href="https://www.mozilla.org/en-US/about/webvision/full/#newapis">extending the capabilities of the platform</a>; allowing rich video and graphics experiences which have previously been difficult to implement efficiently using web technology.</p>
<h2>Compatibility</h2>
<p>Unlike the other focus areas, Web Compatibility isn&#8217;t about a specific feature or specification. Instead the tests in this focus area have been written and selected on the basis of observed site breakage, for example from browser bug reports or via <a href="https://webcompat.com">webcompat.com</a>. The fact that these bugs are causing sites to break immediately makes them a very high priority for improving interoperability on the web.</p>
<h2>Investigations</h2>
<p>Unfortunately not all interoperability challenges can be simply defined in terms of a set of tests that need to be fixed. In some cases we need to do preliminary work to understand the problem, or to develop new infrastructure that will allow testing.</p>
<p>For 2023 we&#8217;re going to concentrate on two areas in which we know that our current test infrastructure is insufficient: mobile platforms and accessibility APIs.</p>
<p>Mobile browsing interaction modes often create web development and interoperability challenges that don&#8217;t occur on desktop. For example, the browser viewport is significantly more dynamic and complex on mobile, reflecting the limited screen size. Whilst browser vendors have ways to test their own mobile browsers, we lack shared infrastructure required to run mobile-specific tests in web-platform-tests and include the results in Interop metrics. The Mobile Testing investigation will look at plugging that gap.</p>
<p>Users who make use of assistive technology (e.g., screen readers) depend on parts of the platform that are currently difficult to test in a cross-browser fashion. The Accessibility Testing investigation aims to ensure that accessibility technologies are just as testable as other parts of the web technology stack and can be included in future rounds of Interop as focus areas.</p>
<p>Together these investigations reflect the importance of ensuring that the web works for everyone, irrespective of how they access it.</p>
<h2>Dashboard</h2>
<p><a href="https://wpt.fyi/interop-2023/"><img decoding="async" loading="lazy" class="alignnone size-large wp-image-47962" src="https://hacks.mozilla.org/files/2023/01/interop-2023-dashboard-500x551.png" alt="Interop 2023 Dashboard as of January 2023, showing an Interop score of 61, an Investigation Score of 0, and browser engine scores of 86 for Blink and WebKit and 74 for Gecko." width="500" height="551" srcset="https://hacks.mozilla.org/files/2023/01/interop-2023-dashboard-500x551.png 500w, https://hacks.mozilla.org/files/2023/01/interop-2023-dashboard-250x276.png 250w, https://hacks.mozilla.org/files/2023/01/interop-2023-dashboard-768x847.png 768w, https://hacks.mozilla.org/files/2023/01/interop-2023-dashboard.png 1290w" sizes="(max-width: 500px) 100vw, 500px" /></a></p>
<p>To follow progress on Inteop 2023, see the <a class="c-link" tabindex="-1" href="https://wpt.fyi/interop-2023" target="_blank" rel="noopener noreferrer" data-stringify-link="https://wpt.fyi/interop-2023" data-sk="tooltip_parent" data-remove-tab-index="true">dashboard</a> on wpt.fyi. This gives detailed scores for each focus area, as well as overall progress on Interop and the investigations.<span class="c-message__edited_label" dir="ltr" data-sk="tooltip_parent"><br />
</span></p>
<h2>Mozilla &amp; Firefox</h2>
<p>The Interop project is an important part of Mozilla&#8217;s vision for a safe &amp; open web where users are in control, and can use any browser on any device. Working with other vendors to focus efforts towards improving cross-browser interoperability is a big part of making that vision a reality. We also know how important it is to lead through our products, and look forward to bringing these improvements to Firefox and into the hands of users.</p>
<h2>Partner Announcements</h2>
<ul>
<li>Apple &#8211; <a href="https://webkit.org/blog/13706/interop-2023/">Pushing Interop Forward in 2023</a></li>
<li>Bocoup &#8211; <a href="https://bocoup.com/blog/interop-2023">Interop 2023 Update</a></li>
<li>Google &#8211; <a href="https://web.dev/interop-2023/">Interop 2023</a></li>
<li>Igalia &#8211; <a href="https://www.igalia.com/news/2023/interop2023.html">Interop 2023</a></li>
<li>Microsoft &#8211; <a href="https://blogs.windows.com/msedgedev/2023/02/01/microsoft-edge-and-interop-2023/">Microsoft Edge and Interop 2023</a></li>
</ul>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/02/announcing-interop-2023/">Announcing Interop 2023</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://hacks.mozilla.org/2023/02/announcing-interop-2023/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>Interop 2022: Outcomes</title>
		<link>https://hacks.mozilla.org/2023/01/interop-2022-outcomes/</link>
		
		<dc:creator><![CDATA[James Graham]]></dc:creator>
		<pubDate>Tue, 31 Jan 2023 17:04:42 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[chrome]]></category>
		<category><![CDATA[css]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[interop]]></category>
		<category><![CDATA[interop-2022]]></category>
		<category><![CDATA[microsoft]]></category>
		<category><![CDATA[safari]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47954</guid>

					<description><![CDATA[<p>Last March we announced the Interop 2022 project, a collaboration between Apple, Bocoup, Google, Igalia, Microsoft, and Mozilla to improve the quality and consistency of their implementations of the web platform.</p>
<p>Now that it's 2023 and we're deep into preparations for the next iteration of Interop, it's a good time to reflect on how the first year of Interop has gone.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/01/interop-2022-outcomes/">Interop 2022: Outcomes</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>Last March we <a href="https://hacks.mozilla.org/2022/03/interop-2022/">announced</a> the Interop 2022 project, a collaboration between Apple, Bocoup, Google, Igalia, Microsoft, and Mozilla to improve the quality and consistency of their implementations of the web platform.</p>
<p>Now that it&#8217;s 2023 and we&#8217;re deep into preparations for the next iteration of Interop, it&#8217;s a good time to reflect on how the first year of Interop has gone.</p>
<h2>Interop Wins</h2>
<p>Happily, Interop 2022 appears to have been a big success. Every browser has made significant improvements to their test pass rates in the Interop focus areas, and now <a href="https://wpt.fyi/interop-2022">all browsers are scoring over 90%</a>. A particular success can be seen in the Viewport Units focus area, which went from 0% pass rate in all browsers to 100% in all browsers in less than a year. This almost never happens with web platform features!</p>
<p>Looking at the release version of browsers — reflecting what actually ships to users — Firefox started the year with a score of around 60% in Firefox 95 and reached 90% in Firefox 108, which was released in December. This reflects a great deal of effort put into Gecko, both in adding new features and improving the quality of implementation of existing features like CSS containment, which jumped from 85% pass rate to 98% with the improvements that were part of Firefox 103.</p>
<p>One of the big new web-platform features in 2022 was Cascade Layers, which first shipped as part of Firefox 97 in February. This was swiftly followed by implementations shipping in Chrome 99 and Safari 15.4, again showing the power of Interop to rapidly drive a web platform feature from initial implementation to something production-quality and available across browsers.</p>
<p>Another big win that&#8217;s worth highlighting was the progress of all browsers to &gt;95% on the &#8220;Web Compatibility&#8221; focus area. This focus area consisted of a small set of tests from already implemented features where browser differences were known to cause problems for users (e.g. through bug reports to <a href="https://webcompat.com">webcompat.com</a>). In an environment where it&#8217;s easy to fixate on the new, it&#8217;s very pleasing to see everyone come together to clean up these longstanding problems that broke sites in the wild.</p>
<p>Other new features that have shipped, or become interoperable, as part of Interop 2022 have been written about in retrospectives by <a href="https://webkit.org/blog/13591/webkit-features-in-safari-16-2/">Apple</a> and <a href="https://web.dev/interop-2022-wrapup/">Google</a>. There&#8217;s a lot of work there to be proud of, and I&#8217;d suggest you check out their posts.</p>
<h2>Investigations</h2>
<p>Along with the &#8220;focus areas&#8221; based on counts of passing tests, Interop 2022 had three &#8220;investigations&#8221;, covering areas where there&#8217;s less clarity on what&#8217;s required to make the web interoperable, and progress can&#8217;t be characterized by a test pass rate.</p>
<p>The Viewport investigation resulted in multiple <a href="https://github.com/web-platform-tests/interop-2022-viewport/issues?q=is%3Aissue+is%3Aclosed+label%3A%22Spec+Issue%22">spec bugs</a> being filed, as well as <a href="https://github.com/w3c/csswg-drafts/issues/7590">agreement</a> with the CSSWG to start work on a Viewport Specification. We know that viewport-related differences are a common source of pain, particularly on mobile browsers; so this is very promising for future improvements in this area.</p>
<p>The Mouse and Pointer Events investigation collated a large number of browser differences in the handling of input events. A subset of these issues got tests and formed the basis for a <a href="https://github.com/web-platform-tests/interop/issues/202">proposed</a> Interop 2023 focus area. There is clearly still more to be done to fix other input-related differences between implementations.</p>
<p>The Editing investigation tackled one of the most historically tricky areas of the platform, where it has long been assumed that complex tasks require the use of libraries that smooth over differences with bespoke handling of each browser engine. One thing that became apparent from this investigation is that IME input (used to input characters that can&#8217;t be directly typed on the keyboard) has behavioral differences for which we lack the infrastructure to write automated cross-browser tests. This Interop investigation looks set to catalyze future work in this area.</p>
<h2>Next Steps</h2>
<p>All the signs are that Interop 2022 was helpful in aligning implementations of the web and ensuring that users are able to retain a free choice of browser without running into compatibility problems. We plan to build on that success with the forthcoming launch of Interop 2023, which we hope will further push the state of the art for web developers and help web browser developers focus on the most important issues to ensure the future of a healthy open web.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2023/01/interop-2022-outcomes/">Interop 2022: Outcomes</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>How the Mozilla Community helps shape our products</title>
		<link>https://hacks.mozilla.org/2022/12/how-the-mozilla-community-helps-to-shape-our-products/</link>
		
		<dc:creator><![CDATA[Francesca Minelli]]></dc:creator>
		<pubDate>Wed, 07 Dec 2022 18:48:54 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[Localization]]></category>
		<category><![CDATA[Mozilla]]></category>
		<category><![CDATA[community]]></category>
		<category><![CDATA[contribution]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[Firefox Nightly]]></category>
		<category><![CDATA[foxfooding]]></category>
		<category><![CDATA[localization]]></category>
		<category><![CDATA[open source]]></category>
		<category><![CDATA[sumo]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47943</guid>

					<description><![CDATA[<p>A product is first an idea, then a project, and then a prototype. Here, at Mozilla, our awesome community is there every step of the way to support and contribute to our products. None of what we do would be possible without this multicultural, multilingual community of like-minded people working together to be a better internet. </p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/12/how-the-mozilla-community-helps-to-shape-our-products/">How the Mozilla Community helps shape our products</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>A product is first an idea, then a project, and then a prototype. It is tested, refined, and localized so that it is accessible to users in different regions. When the product is released into the world, these users need to be supported. Of course, there are always going to be improvements, fixes, and new features, and those will also need to be planned, developed, tested…and so on, and so forth&#8230;</p>
<p>What do all these stages have in common?</p>
<p>Here at Mozilla, our awesome community is there every step of the way to support and contribute to our products. None of what we do would be possible without this multicultural, multilingual community of like-minded people working together to be a better internet.</p>
<p>Of course, contributions to our products are not everything that the community does. There is much more that our community creates, contributes, and discusses.</p>
<p>However,  as a major release recently happened we want to take the occasion to celebrate our community by giving you a peek at how their great contributions helped with version 106 (as well as all versions!) of Firefox.</p>
<h2><b>Ideation (Mozilla Connect)</b></h2>
<p>Ideas for new features and products come from many different sources. Research, data, internal ideas, and feature requests during Foxfooding…at Mozilla one of the sources of new ideas is Mozilla Connect.</p>
<p>Mozilla Connect is a collaborative space for ideas, feedback, and discussions that help shape future product releases.  Anyone can propose and vote for new ideas. The ideas that gain more support are brought to the appropriate team for review.</p>
<p>Firefox Picture in picture subtitles was a <a href="https://mzl.la/3iewgkP">feature requested</a> by the Mozilla Connect Community!</p>
<p>Connect is also a place where Mozilla Product Managers ask for feedback from the community when thinking about ways to improve our product, and where the community can interact directly with Product Managers and engineers.</p>
<p>In this way, the community contributes to continuous product improvement and introduces diverse perspectives and experiences to our product cycle.</p>
<p>Connect played a role in the latest Firefox Major release on both sides of the ideation cycle.</p>
<p>Are you enjoying the new PDF editor&#8217;s functionalities? Then you should know that the community discussed this idea in <a href="https://mzl.la/3Ev06Ji">Connect.</a> After many upvotes, the idea was officially brought to the product team.</p>
<p>After the release is done, the community <a href="https://connect.mozilla.org/t5/discussions/bd-p/discussions?utm_source=Community&amp;utm_medium=Hacks+Blog&amp;utm_campaign=Stories">joined discussions</a> with Firefox Product Managers to give feedback and new suggestions on the new features.</p>
<p>Interested? Get started <a href="https://mzl.la/3OD9q2r">here.</a></p>
<h2><b>Development (Code contribution and patches)</b></h2>
<p>Mozilla developers work side by side with the Community.</p>
<p>Community members find and help solve product bugs and help with the development of different features.</p>
<p>Community is fundamental for the development of Firefox, as community members routinely add their code contributions to the Nightly version of Firefox!</p>
<p>You can <a href="https://mzl.la/3GMhf3V">check out</a> how staff members and contributors work together to solve issues in the Nightly version of Firefox.</p>
<p>Interested? Check out how you can submit your first <a href="https://mzl.la/3XwxZSE">code contribution</a>. You can also discover more about Nightly <a href="https://mzl.la/3U99CYa">here.</a></p>
<h2><b>Testing and reporting bugs </b></h2>
<p>There are many ways in which the Community helps find and report bugs. One of these is a Foxfooding campaign. <b> </b></p>
<p>Because we still have to meet a Mozillian that does not enjoy a good (and…less good) pun, Foxfooding is the Firefox version of Dogfooding.</p>
<p>This is where we make a feature or a product available to our community (and staff) before it is released to the public. Then we ask them to use it, test it, and submit bugs, product feedback, and feature requests.</p>
<p>This is an incredibly precious process, as it ensures that the product is tested by a very diverse (and enthusiastic) group of people, bringing unexpected feedback, and testing in much more diverse conditions than we could do internally.</p>
<p>Plus it is, you know, fun ;)</p>
<p>We ran a Foxfooding campaign for the last Major Release too! And the community all over the world submitted more than 60 bugs.</p>
<p>Foxfooding campaigns are published <a href="https://mzl.la/3i8Rr7Q">here</a>. You can <a href="https://mzl.la/3GLgdoN">subscribe</a> to our Community Newsletter to be notified when one is starting.</p>
<p>Furthermore, community members find, report, and help solve <a href="https://mzl.la/3AGcVPF">Firefox Nightly</a> bugs, as well as bugs that appear in other Firefox versions.</p>
<p><a href="http://bit.ly/3F3Sj6S">Finding and reporting bugs </a>is a great contribution, helping to continuously improve Mozilla Products.</p>
<p>In fact, simply using Firefox Nightly (or Beta) is a way to contribute easily to the Mozilla project. The simple fact of using Nightly sends anonymous data on and crash reports that help discover issues before we ship to the general public.</p>
<h2><b>Localization (l10n)</b></h2>
<p>Currently, Firefox is localized in 98 languages (110 in the Nightly version) and that is entirely thanks to the effort of a determined international community.</p>
<p>Localization is important because we are committed to a Web open and accessible to all— where a person’s demographic characteristics do not determine their online access, opportunities, or quality of experience.</p>
<p>The <a href="https://mzl.la/3gur388">Mozilla Localization</a> effort represents a commitment to advancing these aspirations. They work together with people everywhere who share the goal to make the internet an even better place for everyone.</p>
<p>The community worked really hard on the global launch for the Major release! Thank you to all localizers that took part in this global launch. There were more than 274 folks working on, and (approximately) 67,094 translations!</p>
<h2><b>Users Support (SUMO)</b></h2>
<p>Once a product is out into the world, the work is far from done! There are always bugs that need reporting, users who need troubleshooting help, and new features that need explanation…</p>
<p>At Mozilla, the Mozilla Support a.k.a. SUMO community is the one supporting users all over the world, <a href="https://mzl.la/3F1zrFi">answering support questions</a> through the forum, socials, or mobile app stores, creating helpdesk articles, and localizing the articles.</p>
<p>When it&#8217;s done right, providing high-quality support may contribute to our user&#8217;s loyalty and retention. Plus, it can help improve the product: when we bring the data back to the product team, we can establish a feedback loop that can be delivered into product improvements as well.</p>
<p>The SUMO community is actively helping users during the Major release. Up until now:</p>
<ul>
<li aria-level="1">3975 forum responses were sent during the release from 2344 questions that were submitted.</li>
<li aria-level="1">12 support articles were created, updated, and translated into Greek, French, Italian, Japanese, Russian, Portuguese, Simplified Chinese, Polish, and many more.</li>
<li aria-level="1">They posted responses to review in the 445 Google Play Store responses</li>
<li aria-level="1">They answer 88 Twitter questions</li>
</ul>
<p>And they are still going strong!</p>
<h2><b>Want to Join?</b></h2>
<p>Would you also like to contribute? Our products are one of the ways in which we shape the web, and protect the privacy of our users. Getting involved is a great way to contribute to the missions and get in touch with like-minded people.</p>
<p>Please <a href="https://mzl.la/3ieMdY4">check our /contribute page</a> for more information, subscribe to our <a href="https://mzl.la/3GLgdoN">Community Newsletter</a>,  or join our <a href="https://chat.mozilla.org/#/room/%23CommunityRoom:mozilla.org">#communityroom in Matrix.</a></p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/12/how-the-mozilla-community-helps-to-shape-our-products/">How the Mozilla Community helps shape our products</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Improving Firefox stability with this one weird trick</title>
		<link>https://hacks.mozilla.org/2022/11/improving-firefox-stability-with-this-one-weird-trick/</link>
					<comments>https://hacks.mozilla.org/2022/11/improving-firefox-stability-with-this-one-weird-trick/#comments</comments>
		
		<dc:creator><![CDATA[Gabriele Svelto]]></dc:creator>
		<pubDate>Tue, 22 Nov 2022 14:16:56 +0000</pubDate>
				<category><![CDATA[Developer Tools]]></category>
		<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[apps]]></category>
		<category><![CDATA[browser]]></category>
		<category><![CDATA[crashes]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[memory]]></category>
		<category><![CDATA[Windows]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47935</guid>

					<description><![CDATA[<p>We break down how we reduced Firefox out-of-memory crashes on Windows with a simple trick. Poorly behaving web pages and apps are no longer capable of crashing the browser by exhausting memory.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/11/improving-firefox-stability-with-this-one-weird-trick/">Improving Firefox stability with this one weird trick</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><span style="font-weight: 400;">The first computer I owned shipped with 128 KiB of RAM and to this day I’m still jarred by the idea that applications can run out of memory given that even 15-year-old machines often shipped with 4 GiB of memory. And yet it’s one of the most common causes of instability experienced by users and in the case of Firefox the biggest source of crashes on Windows. </span></p>
<p><span style="font-weight: 400;">As such, at Mozilla, we spend significant resources </span><a href="https://bugzilla.mozilla.org/buglist.cgi?list_id=16239893&amp;query_format=advanced&amp;v1=MemShrink&amp;classification=Client%20Software&amp;classification=Developer%20Infrastructure&amp;classification=Components&amp;classification=Server%20Software&amp;classification=Other&amp;resolution=---&amp;o1=substring&amp;f1=status_whiteboard"><span style="font-weight: 400;">trimming down Firefox memory consumption</span></a><span style="font-weight: 400;"> and </span><a href="https://treeherder.mozilla.org/perfherder/alerts?hideDwnToInv=1&amp;page=1&amp;framework=4&amp;status=-1"><span style="font-weight: 400;">carefully monitoring the changes</span></a><span style="font-weight: 400;">. Some extra efforts have been spent on the Windows platform because Firefox was more likely to run out of memory there than on macOS or Linux. And yet none of those efforts had the impact of a cool trick we deployed in Firefox 105.</span></p>
<p><span style="font-weight: 400;">But first things first, to understand why applications running on Windows are more prone to running out of memory compared to other operating systems it’s important to understand how Windows handles memory.</span></p>
<p><span style="font-weight: 400;">All modern operating systems allow applications to allocate chunks of the address space. Initially these chunks only represent address ranges that aren’t backed by physical memory unless data is stored in them. When an application starts using a bit of address space it has reserved, the OS will dedicate a chunk of physical memory to back it, possibly swapping out some existing data if need be. Both Linux and macOS work this way, and so does Windows except that it requires an extra step compared to the other OSes. </span></p>
<p><span style="font-weight: 400;">After an application has requested a chunk of address space it needs to commit it before being able to use it. Committing a range requires Windows to guarantee it can always find some physical memory to back it. Afterwards, it behaves just like Linux and macOS. As such Windows limits how much memory can be committed to the sum of the machine’s physical memory plus the size of the swap file. </span></p>
<p><span style="font-weight: 400;">This resource &#8211; known as commit space &#8211; is a hard limit for applications. Memory allocations will start to fail once the limit is reached. In operating system speech this means that Windows does not allow applications to overcommit memory.</span></p>
<p><span style="font-weight: 400;">One interesting aspect of this system is that an application can commit memory that it won’t use. The committed amount will still count against the limit even if no data is stored in the corresponding areas and thus no physical memory has been used to back the committed region. When we started analyzing out of memory crashes we discovered that many users still had plenty of physical memory available &#8211; sometimes gigabytes of it &#8211; but were running out of commit space instead.</span></p>
<p><span style="font-weight: 400;">Why was that happening? We don’t really know but we made some educated guesses: Firefox tracks all the memory it uses and we could account for all the memory that we committed directly. </span></p>
<p><span style="font-weight: 400;">However, we have no control over Windows system libraries and in particular graphics drivers. One thing we noticed is that graphics drivers commit memory to make room for textures in system memory. This allows them to swap textures out of the GPU memory if there isn’t enough and keep them in system memory instead. A mechanism that is similar to how regular memory can be swapped out to disk when there is not enough RAM available. In practice, this rarely happens, but these areas still count against the limit.</span></p>
<p><span style="font-weight: 400;">We had no way of fixing this issue directly but we still had an ace up our sleeve: when an application runs out of memory on Windows it’s not outright killed by the OS, its allocation simply fails and it can then decide what it does by itself. </span></p>
<p><span style="font-weight: 400;">In some cases, Firefox could handle the failed allocation, but in most cases, there is no sensible or safe way to handle the error and it would need to crash in a controlled way… but what if we could recover from this situation instead? Windows automatically resizes the swap file when it’s almost full, increasing the amount of commit space available. Could we use this to our advantage?</span></p>
<p><span style="font-weight: 400;">It turns out that the answer is yes, we can. So we adjusted Firefox </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1716727"><span style="font-weight: 400;">to wait for a bit instead of crashing</span></a><span style="font-weight: 400;"> and then retry the failed memory allocation. This leads to a bit of jank as the browser can be stuck for a fraction of a second, but it’s a lot better than crashing.</span></p>
<p><span style="font-weight: 400;">There’s also another angle to this: Firefox is made up of several processes and can survive losing all of them but the main one. Delaying a main process crash might lead to another process dying if memory is tight. This is good because it would free up memory and let us resume execution, for example by getting rid of a web page with </span><a href="https://nolanlawson.com/2021/12/17/introducing-fuite-a-tool-for-finding-memory-leaks-in-web-apps/"><span style="font-weight: 400;">runaway memory consumption</span></a><span style="font-weight: 400;">. </span></p>
<p><span style="font-weight: 400;">If a content process died we would need to reload it if it was the GPU process instead the browser would briefly flash while we relaunched it; either way, the result is less disruptive than a full browser crash. We used a similar trick in Firefox for Android and Firefox OS before that and it worked well on both platforms.</span></p>
<p><span style="font-weight: 400;">This little trick shipped in Firefox 105 and had an enormous impact on Firefox stability on Windows. The chart below shows how many out-of-memory browser crashes were experienced by users per active usage hours:</span></p>
<p><img decoding="async" loading="lazy" class="alignnone wp-image-47936 size-full" src="https://hacks.mozilla.org/files/2022/11/unnamed-3.png" alt="Firefox trick" width="1129" height="496" srcset="https://hacks.mozilla.org/files/2022/11/unnamed-3.png 1129w, https://hacks.mozilla.org/files/2022/11/unnamed-3-250x110.png 250w, https://hacks.mozilla.org/files/2022/11/unnamed-3-500x220.png 500w, https://hacks.mozilla.org/files/2022/11/unnamed-3-768x337.png 768w" sizes="(max-width: 1129px) 100vw, 1129px" /></p>
<p><span style="font-weight: 400;">You’re looking at a &gt;70% reduction in crashes, far more than our rosiest predictions.</span></p>
<p><span style="font-weight: 400;">And we’re not done yet! Stalling the main process led to a smaller increase in tab crashes &#8211; which are also unpleasant for the user even if not nearly as annoying as a full browser crash &#8211; so </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1785162"><span style="font-weight: 400;">we’re cutting those down too</span></a><span style="font-weight: 400;">. </span></p>
<p><span style="font-weight: 400;">Last but not least we want to improve Firefox behavior in low-memory scenarios by responding differently to cases where </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1782178"><span style="font-weight: 400;">we’re low on commit space and cases where we’re low on physical memory</span></a><span style="font-weight: 400;">, this will reduce swapping and help shrink Firefox footprint to make room for other applications.</span></p>
<p><span style="font-weight: 400;">I’d like to send special thanks to my colleague Raymond Kraesig who implemented this “trick”, carefully monitored its impact and is working on the aforementioned improvements.</span></p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/11/improving-firefox-stability-with-this-one-weird-trick/">Improving Firefox stability with this one weird trick</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://hacks.mozilla.org/2022/11/improving-firefox-stability-with-this-one-weird-trick/feed/</wfw:commentRss>
			<slash:comments>8</slash:comments>
		
		
			</item>
		<item>
		<title>Revamp of MDN Web Docs Contribution Docs</title>
		<link>https://hacks.mozilla.org/2022/10/revamp-of-mdn-web-docs-contribution-docs/</link>
		
		<dc:creator><![CDATA[Dipika Bhattacharya]]></dc:creator>
		<pubDate>Mon, 31 Oct 2022 17:47:12 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[MDN]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[mdn]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47930</guid>

					<description><![CDATA[<p>The MDN Web Docs team recently undertook a project to revamp and reorganize the “Contribution Docs”. These are all the pages on MDN that describe what's what – the templates and page structures, how to perform a task on MDN, how to contribute to MDN, and the community guidelines to follow while contributing to this massive open source project.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/10/revamp-of-mdn-web-docs-contribution-docs/">Revamp of MDN Web Docs Contribution Docs</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><span style="font-weight: 400;">The MDN Web Docs team recently undertook a project to revamp and reorganize the “</span><a href="https://developer.mozilla.org/en-US/docs/MDN"><span style="font-weight: 400;">Contribution Docs</span></a><span style="font-weight: 400;">”. These are all the pages on MDN that describe what&#8217;s what – the templates and page structures, how to perform a task on MDN, how to contribute to MDN, and the community guidelines to follow while contributing to this massive open source project.</span></p>
<p><span style="font-weight: 400;">The contribution docs are an essential resource that help authors navigate the MDN project. Both the community as well as the partner and internal teams reference it regularly whenever we want to cross-check our policies or how-tos in any situation. Therefore, it was becoming important that we spruce up these pages to keep them relevant and up to date.</span></p>
<h2><span style="font-weight: 400;">Cleanup</span></h2>
<p><span style="font-weight: 400;">This article describes the updates we made to the “Contribution Docs”.</span></p>
<h3><span style="font-weight: 400;">Reorganization</span></h3>
<p><span style="font-weight: 400;">To begin with, we grouped and reorganized the content into two distinct buckets – Community guidelines and Writing guidelines. This is how the project outline looks like now:</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">You’ll now find all the information about open source etiquette, discussions, process flows, users and teams, and how to get in touch with the maintainers in the  </span><a href="https://developer.mozilla.org/en-US/docs/MDN/Community"><span style="font-weight: 400;">Community guidelines</span></a><span style="font-weight: 400;"> section.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">You&#8217;ll find the information about how to write for MDN, what we write, what we regard as experimental, and so on in the </span><a href="https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines"><span style="font-weight: 400;">Writing guidelines</span></a><span style="font-weight: 400;"> section.</span></li>
</ul>
<p>Next, we shuffled the information around a bit so that logically similar pieces sit together. We also collated information that was scattered across multiple pages into more logical chunks.</p>
<p><span style="font-weight: 400;">For example, the </span><a href="https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines/Writing_style_guide"><span style="font-weight: 400;">Writing style guide</span></a><span style="font-weight: 400;"> now also includes information about “Write with SEO in mind”, which was earlier a separate page elsewhere.</span></p>
<p><span style="font-weight: 400;">We also restructured some documents, such as the </span><a href="https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines/Writing_style_guide"><span style="font-weight: 400;">Writing style guide</span></a><span style="font-weight: 400;">. This document is now divided into the sections “General writing guidelines”, “Writing style”, and “Page components”. In the previous version of the style guide, everything was grouped under “Basics”.</span></p>
<h3><span style="font-weight: 400;">Updates and rewrites</span></h3>
<p><span style="font-weight: 400;">In general, we reviewed and removed outdated as well as repeated content. The cleanup effort also involved doing the following:</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Removing and redirecting common procedural instructions, such as setting up Git and using Github, to Github docs, instead of repeating the steps on MDN.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Moving some repository-specific information to the respective repository. For example, a better home for the content about “Matching web features to browser release version numbers” is in the </span><a href="https://github.com/mdn/browser-compat-data"><span style="font-weight: 400;">mdn/browser-compat-data</span></a><span style="font-weight: 400;"> repository.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Rewriting a few pages to make them relevant to the currently followed guidelines and processes.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Documenting our process flows for issues and pull requests on </span><span style="font-weight: 400;">mdn/content</span><span style="font-weight: 400;"> vs other repositories on </span><span style="font-weight: 400;">mdn</span><span style="font-weight: 400;">. This is an ongoing task as we tweak and define better guidelines to work with our partners and community.</span></li>
</ul>
<h2><span style="font-weight: 400;">New look</span></h2>
<p><span style="font-weight: 400;">As a result of the cleanup effort, the new “Contributor Docs” structure looks like this:</span></p>
<h3><span style="font-weight: 400;">Community guidelines</span></h3>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Community/Contributing"><span style="font-weight: 400;">Contributing to MDN</span></a></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Community/Open_source_etiquette"><span style="font-weight: 400;">Open source etiquette</span></a></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Community/Discussions"><span style="font-weight: 400;">Discussions</span></a></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Community/Learn_forum"><span style="font-weight: 400;">Learn forum</span></a></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Community/Issues"><span style="font-weight: 400;">Issues</span></a></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Community/Pull_requests"><span style="font-weight: 400;">Pull requests</span></a></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Community/Mdn_content"><span style="font-weight: 400;">Content repository guidelines</span> </a></li>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Community/Users_teams"><span style="font-weight: 400;">Users and teams</span></a></li>
</ul>
<h3><span style="font-weight: 400;">Writing guidelines</span></h3>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines/What_we_write"><span style="font-weight: 400;">What we write</span></a></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines/Writing_style_guide"><span style="font-weight: 400;">Writing style guide</span></a></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines/Howto"><span style="font-weight: 400;">How-to guides</span></a></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines/Page_structures"><span style="font-weight: 400;">Page structures</span></a></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines/Attrib_copyright_license"><span style="font-weight: 400;">Attribution and copyright</span></a></li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><a href="https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines/Experimental_deprecated_obsolete"><span style="font-weight: 400;">Experimental, deprecated and obsolete</span></a></li>
</ul>
<p>&nbsp;</p>
<h2><span style="font-weight: 400;">Comparing the old with the new</span></h2>
<p><span style="font-weight: 400;">The list below will give you an idea of the new home for some of the content in the previous version:</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Contributing to MDN”</span>
<ul>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home: Community guidelines &gt; Contributing to MDN Web Docs</span></li>
</ul>
</li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Get started on MDN”</span>
<ul>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home: Community guidelines &gt; Contributing to MDN Web Docs &gt; Getting started with MDN Web Docs</span></li>
</ul>
</li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Basic etiquette for open source projects”</span>
<ul>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home: Community guidelines &gt; Contributing to MDN Web Docs &gt; Open source etiquette</span></li>
</ul>
</li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Where is everything on MDN”</span>
<ul>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home: Community guidelines &gt; Contributing to MDN Web Docs &gt; MDN Web Docs Repositories</span></li>
</ul>
</li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Localizing MDN”</span>
<ul>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home: Community guidelines &gt; Contributing to MDN Web Docs &gt; Translated content</span></li>
</ul>
</li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Does this belong on MDN Web Docs”, “Editorial policies”, “Criteria for inclusion”, “Process for selection”, “Project guidelines”</span>
<ul>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home: Writing guidelines &gt; What we write</span></li>
</ul>
</li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Criteria for inclusion”, “Process for selection”, “Project guidelines”</span>
<ul>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home: Writing guidelines &gt; What we write &gt; Criteria for inclusion on MDN Web Docs</span></li>
</ul>
</li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“MDN conventions and definitions”</span>
<ul>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home for definitions: Writing guidelines &gt; Experimental, deprecated and obsolete</span></li>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home for conventions: Writing guidelines &gt; What we write</span></li>
</ul>
</li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Video data on MDN”</span>
<ul>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home: Writing guidelines &gt; How-to guides &gt; How to add images and media</span></li>
</ul>
</li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Structured data on MDN”</span>
<ul>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home: Writing guidelines &gt; How-to guides &gt; How to use structured data</span></li>
</ul>
</li>
</ul>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">“Content structures”</span>
<ul>
<li style="font-weight: 400;" aria-level="2"><span style="font-weight: 400;">New home: Writing guidelines &gt; Page structures</span></li>
</ul>
</li>
</ul>
<h2><span style="font-weight: 400;">Summary </span></h2>
<p><span style="font-weight: 400;">The Contribution Docs are working documents — they are reviewed and edited regularly to keep them up to date with editorial and community policies. Giving them a good spring clean allows easier maintenance for us and our partners.</span></p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/10/revamp-of-mdn-web-docs-contribution-docs/">Revamp of MDN Web Docs Contribution Docs</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Improving Firefox responsiveness on macOS</title>
		<link>https://hacks.mozilla.org/2022/10/improving-firefox-responsiveness-on-macos/</link>
					<comments>https://hacks.mozilla.org/2022/10/improving-firefox-responsiveness-on-macos/#comments</comments>
		
		<dc:creator><![CDATA[Gabriele Svelto]]></dc:creator>
		<pubDate>Mon, 10 Oct 2022 15:13:02 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[Firefox OS]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[macos]]></category>
		<category><![CDATA[spinlock]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47924</guid>

					<description><![CDATA[<p>If you're running Firefox on macOS you might have noticed that its responsiveness has improved significantly in version 103, especially if you've got a lot of tabs, or when your machine is busy running other applications at the same time. This improvement was achieved via a small change in how locking is implemented within Firefox's memory allocator.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/10/improving-firefox-responsiveness-on-macos/">Improving Firefox responsiveness on macOS</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><span style="font-weight: 400;">If you&#8217;re running Firefox on macOS you might have noticed that its responsiveness has improved significantly in version 103, especially if you&#8217;ve got a lot of tabs, or when your machine is busy running other applications at the same time. This improvement was achieved via a small change in how locking is implemented within Firefox&#8217;s memory allocator.</span></p>
<p><span style="font-weight: 400;">Firefox uses a highly customized version of the jemalloc memory allocator across all architectures. We&#8217;ve diverged significantly from upstream jemalloc in order to guarantee optimal performance and memory usage on Firefox.</span></p>
<p><span style="font-weight: 400;">Memory allocators have to be thread safe and &#8211; in order to be performant &#8211; need to be able to serve a large number of concurrent requests from different threads. To achieve this, jemalloc uses locks within its internal structures that are usually only held very briefly.</span></p>
<p><span style="font-weight: 400;">Locking within the allocator is implemented differently than in the rest of the codebase. Specifically, creating mutexes and using them must not issue new memory allocations because that would lead to infinite recursion within the allocator itself. To achieve this the allocator tends to use thin locks native to the underlying operating system. On macOS we relied for a long time on </span><a href="https://developer.apple.com/library/archive/documentation/System/Conceptual/ManPages_iPhoneOS/man3/spinlock.3.html"><span style="font-weight: 400;">OSSpinLock</span></a><span style="font-weight: 400;"> locks.</span></p>
<p><span style="font-weight: 400;">As the name suggests these are not regular mutexes that put threads trying to acquire them to sleep if they&#8217;re already taken by another thread. A thread attempting to lock an already locked instance of </span><span style="font-weight: 400;">OSSpinLock</span><span style="font-weight: 400;"> will busy-poll the lock instead of waiting for it to be released, which is commonly referred to as spinning on the lock.</span></p>
<p><span style="font-weight: 400;">This might seem counter-intuitive, as spinning consumes CPU cycles and power and is usually frowned upon in modern codebases. However, putting a thread to sleep has significant performance implications and thus is not always the best option.</span></p>
<p><span style="font-weight: 400;">In particular, putting a thread to sleep and then waking it up requires two context switches as well as saving and restoring the thread state to/from memory. Depending on the CPU and workload the thread state can range from several hundred bytes to a few kilobytes. Putting a thread to sleep also has indirect performance effects. </span></p>
<p><span style="font-weight: 400;">For example, the caches associated with the core the thread was running on were likely holding useful data. When a thread is put to sleep another thread from an unrelated workload might then be selected to run in its place, replacing the data in the caches with new data. </span></p>
<p><span style="font-weight: 400;">When the original thread is restored it might end up on a different core, or on the same core but with cold caches, filled with unrelated data. Either way, the thread will proceed execution more slowly than if it had kept running undisturbed.</span></p>
<p><span style="font-weight: 400;">Because of all the above, it might be advantageous to let a thread spin briefly if the lock it’s trying to acquire is only held for a brief period of time. It can result in both higher performance and lower power consumption as the cost of spinning is less than sleeping.</span></p>
<p><span style="font-weight: 400;">However spinning has a significant drawback: if it goes on for too long it can be detrimental, as it will just waste cycles. Worse still, if the machine is heavily loaded, spinning might put additional load on the system, potentially slowing down precisely the thread that owns the lock, increasing the chance of further threads needing the lock, spinning some more.</span></p>
<p><span style="font-weight: 400;">As you might have guessed by now </span><span style="font-weight: 400;">OSSpinLock </span><span style="font-weight: 400;">offered very good performance on a lightly loaded system, but behaved poorly as load ramped up. More importantly it had two fundamental flaws: it spinned in user-space and never slept.</span></p>
<p><span style="font-weight: 400;">Spinning in user-space is a bad idea in general, as user-space doesn&#8217;t know how much load the system is currently experiencing. In kernel-space a lock might make an informed decision, for example not to spin at all if the load is high, but </span><span style="font-weight: 400;">OSSpinLock</span><span style="font-weight: 400;"> had no such provision, nor did it adapt.</span></p>
<p><span style="font-weight: 400;">But more importantly, when it couldn&#8217;t really grab a lock it would </span><a href="https://github.com/apple/darwin-libplatform/blob/215b09856ab5765b7462a91be7076183076600df/src/os/lock.c#L127-L148"><span style="font-weight: 400;">yield</span></a><span style="font-weight: 400;"> instead of sleeping. This is particularly bad because the kernel has no clue that the yielding thread is waiting on a lock, so it might wake up another thread that is also fighting for the same lock instead of the one that owns it. </span></p>
<p><span style="font-weight: 400;">This will lead to more spinning and yielding and the resulting user experience will be terrible. On heavily loaded systems this could lead to a near live-lock and Firefox effectively hanging. This problem with </span><span style="font-weight: 400;">OSSpinLock</span><span style="font-weight: 400;"> was </span><a href="https://mjtsai.com/blog/2015/12/16/osspinlock-is-unsafe/"><span style="font-weight: 400;">known</span></a><span style="font-weight: 400;"> within </span><a href="https://lists.swift.org/pipermail/swift-dev/Week-of-Mon-20151214/000372.html"><span style="font-weight: 400;">Apple</span></a><span style="font-weight: 400;"> hence its deprecation.</span></p>
<p><span style="font-weight: 400;">Enter </span><a href="https://developer.apple.com/documentation/os/os_unfair_lock"><span style="font-weight: 400;">os_unfair_lock</span></a><span style="font-weight: 400;">, Apple&#8217;s official replacement for </span><span style="font-weight: 400;">OSSpinLock</span><span style="font-weight: 400;">. If you still use </span><span style="font-weight: 400;">OSSpinLock</span><span style="font-weight: 400;"> you&#8217;ll get explicit warnings to use it instead.</span></p>
<p><span style="font-weight: 400;">So I went ahead and used it, but the results were terrible. Performance in some of our automated tests </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1774458"><span style="font-weight: 400;">degraded by as much as 30%</span></a><span style="font-weight: 400;">. </span><span style="font-weight: 400;">os_unfair_lock</span><span style="font-weight: 400;"> might be better behaved than </span><span style="font-weight: 400;">OSSpinLock</span><span style="font-weight: 400;">, but it sucked.</span></p>
<p><span style="font-weight: 400;">As it turns out </span><span style="font-weight: 400;">os_unfair_lock</span><span style="font-weight: 400;"> doesn&#8217;t spin on contention, it makes the calling thread </span><a href="https://github.com/apple/darwin-libplatform/blob/215b09856ab5765b7462a91be7076183076600df/src/os/lock.c#L536"><span style="font-weight: 400;">sleep right away when it finds a contended lock</span></a><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">For the memory allocator this behavior was suboptimal and the performance regression unacceptable. In some ways, </span><span style="font-weight: 400;">os_unfair_lock</span><span style="font-weight: 400;"> had the opposite problem of </span><span style="font-weight: 400;">OSSpinLock</span><span style="font-weight: 400;">: it was too willing to sleep when spinning would have been a better choice. At this point, it&#8217;s worth mentioning while we&#8217;re at it that </span><span style="font-weight: 400;">pthread_mutex</span><span style="font-weight: 400;"> locks are even slower on macOS so those weren&#8217;t an option either.</span></p>
<p><span style="font-weight: 400;">However, as I dug into Apple&#8217;s libraries and kernel, I noticed that some spin locks were indeed available, and they did the spinning in kernel-space where they could make a more informed choice with regards to load and scheduling. Those would have been an excellent choice for our use-case.</span></p>
<p><span style="font-weight: 400;">So how do you use them? Well, it turns out they&#8217;re not documented. They rely on a non-public function and flags which I had to duplicate in Firefox. </span></p>
<p><span style="font-weight: 400;">The function is </span><a href="https://searchfox.org/mozilla-central/rev/6ec440e105c2b75d5cae9d34f957a2f85a106d54/memory/build/Mutex.h#22-34"><span style="font-weight: 400;">os_unfair_lock_with_options()</span></a><span style="font-weight: 400;"> and the options I used are </span><span style="font-weight: 400;">OS_UNFAIR_LOCK_DATA_SYNCHRONIZATION</span><span style="font-weight: 400;"> and </span><span style="font-weight: 400;">OS_UNFAIR_LOCK_ADAPTIVE_SPIN</span><span style="font-weight: 400;">. </span></p>
<p><span style="font-weight: 400;">The latter asks the kernel to use kernel-space adaptive spinning, and the former prevents it from spawning additional threads in the thread pools used by Apple&#8217;s libraries.</span></p>
<p><img decoding="async" loading="lazy" class="alignnone wp-image-47925 size-full" src="https://hacks.mozilla.org/files/2022/10/hack-apple.png" alt="OS_UNFAIR_LOCK_DATA_SYNCHRONIZATION and OS_UNFAIR_LOCK_ADAPTIVE_SPIN. The latter asks the kernel to use kernel-space adaptive spinning, and the former prevents it from spawning additional threads in the thread pools used by Apple's libraries." width="829" height="524" srcset="https://hacks.mozilla.org/files/2022/10/hack-apple.png 829w, https://hacks.mozilla.org/files/2022/10/hack-apple-250x158.png 250w, https://hacks.mozilla.org/files/2022/10/hack-apple-500x316.png 500w, https://hacks.mozilla.org/files/2022/10/hack-apple-768x485.png 768w" sizes="(max-width: 829px) 100vw, 829px" /></p>
<p><span style="font-weight: 400;">Did they work? Yes! Performance on lightly loaded systems was about the same as </span><span style="font-weight: 400;">OSSpinLock</span><span style="font-weight: 400;"> but on loaded ones, they provided massively better responsiveness. They also did something extremely useful for laptop users: they cut down power consumption as a lot less cycles were wasted having the CPUs spinning on locks that couldn&#8217;t be acquired.</span></p>
<p><span style="font-weight: 400;">Unfortunately, my woes weren&#8217;t over. The </span><span style="font-weight: 400;">OS_UNFAIR_LOCK_ADAPTIVE_SPIN</span><span style="font-weight: 400;"> flag is supported only starting with macOS 10.15, but Firefox also runs on older versions (all the way to 10.12). </span></p>
<p><span style="font-weight: 400;">As an intermediate solution, I initially fell back to </span><span style="font-weight: 400;">OSSpinLock</span><span style="font-weight: 400;"> on older systems. Later I managed to get rid of it for good by relying on </span><span style="font-weight: 400;">os_unfair_lock</span><span style="font-weight: 400;"> plus </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1784018"><span style="font-weight: 400;">manual spinning in user-space</span></a><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">This isn&#8217;t ideal but it&#8217;s still better than relying on </span><span style="font-weight: 400;">OSSpinLock</span><span style="font-weight: 400;">, especially because it&#8217;s needed only on x86-64 processors, where I can use </span><a href="https://www.felixcloutier.com/x86/pause.html"><span style="font-weight: 400;">pause instructions</span></a><span style="font-weight: 400;"> in the loop which should reduce the performance and power impact when a lock can&#8217;t be acquired. </span></p>
<p><span style="font-weight: 400;">When two threads are running on the same physical core, one using pause instructions leaves almost all of the core&#8217;s resources available to the other thread. In the unfortunate case of two threads spinning on the same core they&#8217;ll still consume very little power.</span></p>
<p><span style="font-weight: 400;">At this point, you might wonder if </span><span style="font-weight: 400;">os_unfair_lock</span><span style="font-weight: 400;"> &#8211; possibly coupled with the undocumented flags &#8211; would be a good fit for your codebase. My answer is likely yes but you&#8217;ll have to be careful when using it. </span></p>
<p><span style="font-weight: 400;">If you&#8217;re using the undocumented flags be sure to routinely test your software on new beta versions of macOS, as they might break in future versions. And even if you&#8217;re only using </span><span style="font-weight: 400;">os_unfair_lock</span><span style="font-weight: 400;"> public interface beware that it doesn&#8217;t play well with </span><span style="font-weight: 400;">fork()</span><span style="font-weight: 400;">. That&#8217;s because the lock stores internally the mach thread IDs to ensure consistent acquisition and release. </span></p>
<p><span style="font-weight: 400;">These IDs change after a call to </span><span style="font-weight: 400;">fork()</span><span style="font-weight: 400;"> as the thread creates new ones when copying your process&#8217; threads. This can lead to potential crashes in the child process. If your application uses </span><span style="font-weight: 400;">fork()</span><span style="font-weight: 400;">, or your library needs to be </span><span style="font-weight: 400;">fork()</span><span style="font-weight: 400;">-safe you&#8217;ll need to register at-fork handlers using </span><span style="font-weight: 400;">pthread_atfork()</span><span style="font-weight: 400;"> to acquire all the locks in the parent before the fork, then release them after the fork (also in the parent), and reset them in the child. </span></p>
<p><span style="font-weight: 400;">Here&#8217;s how we do it in </span><a href="https://searchfox.org/mozilla-central/rev/aeddc3f568de22ad445b4999713ab3a28c3b7a93/memory/replace/logalloc/LogAlloc.cpp#236"><span style="font-weight: 400;">our</span></a> <a href="https://searchfox.org/mozilla-central/rev/aeddc3f568de22ad445b4999713ab3a28c3b7a93/memory/replace/logalloc/LogAlloc.cpp#30-32"><span style="font-weight: 400;">code</span></a><span style="font-weight: 400;">.</span></p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/10/improving-firefox-responsiveness-on-macos/">Improving Firefox responsiveness on macOS</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://hacks.mozilla.org/2022/10/improving-firefox-responsiveness-on-macos/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>The 100% Markdown Expedition</title>
		<link>https://hacks.mozilla.org/2022/09/the-100-percent-markdown-expedition/</link>
		
		<dc:creator><![CDATA[Schalk Neethling]]></dc:creator>
		<pubDate>Thu, 08 Sep 2022 09:14:51 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[MDN]]></category>
		<category><![CDATA[HTML]]></category>
		<category><![CDATA[Markdown]]></category>
		<category><![CDATA[mdn]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47919</guid>

					<description><![CDATA[<p>In June 2021, we decided to start converting the source code for MDN web docs from HTML into a format that would be easier for us to work with. The goal was to get 100% of our manually-written documentation converted to Markdown, and we really had a mountain of source code to climb for this particular expedition.</p>
<p>In this post, we’ll describe why we decided to migrate to Markdown, and the steps you can take that will help us on our mission.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/09/the-100-percent-markdown-expedition/">The 100% Markdown Expedition</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><a href="https://unsplash.com/s/photos/mountain-peak?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText&quot;"><img decoding="async" loading="lazy" class="wp-image-47920 size-large aligncenter" src="https://hacks.mozilla.org/files/2022/09/cristian-grecu-6yBAQeeNROU-unsplash-500x333.jpg" alt="A snowy mountain peak at sunset" width="500" height="333" srcset="https://hacks.mozilla.org/files/2022/09/cristian-grecu-6yBAQeeNROU-unsplash-500x333.jpg 500w, https://hacks.mozilla.org/files/2022/09/cristian-grecu-6yBAQeeNROU-unsplash-250x167.jpg 250w, https://hacks.mozilla.org/files/2022/09/cristian-grecu-6yBAQeeNROU-unsplash-768x512.jpg 768w, https://hacks.mozilla.org/files/2022/09/cristian-grecu-6yBAQeeNROU-unsplash-1536x1024.jpg 1536w, https://hacks.mozilla.org/files/2022/09/cristian-grecu-6yBAQeeNROU-unsplash-2048x1365.jpg 2048w" sizes="(max-width: 500px) 100vw, 500px" /></a></p>
<article id="4fa41c72-dc90-4da6-adad-282d056a1106" class="page sans">
<header>
<h1 class="page-title">The 100% Markdown Expedition</h1>
</header>
<div class="page-body">
<p id="d771ff37-f0a2-47cc-bea5-8ca9d493820b" class="">In June 2021, we decided to start converting the source code for MDN web docs from HTML into a format that would be easier for us to work with. The goal was to get 100% of our manually-written documentation converted to Markdown, and we really had a mountain of source code to climb for this particular expedition.</p>
<p id="d78e011a-0258-4470-a9b3-1ef820b7b1e8" class="">In this post, we’ll describe why we decided to migrate to Markdown, and the steps you can take that will help us on our mission.</p>
<h2 id="ec286304-7fc4-4ce5-8ee9-ff09ab32d7e2" class="">Why get to 100% Markdown?</h2>
<p id="748faf9e-5584-40e5-8267-ca1fdbdcb372" class="">We want to get all active content on MDN Web Docs to Markdown for several reasons. The top three reasons are:</p>
<ul id="0b025954-8f5a-4c73-87ca-d7611e5c223c" class="bulleted-list">
<li style="list-style-type: disc;">Markdown is a much more approachable and friendlier way to contribute to MDN Web Docs content. Having all content in Markdown will help create a unified contribution experience across languages and repositories.</li>
</ul>
<ul id="40083464-df99-4f76-88d6-8f77d0bf460b" class="bulleted-list">
<li style="list-style-type: disc;">With all content in Markdown, the MDN engineering team will be able to clean up a lot of the currently maintained code. Having less code to maintain will enable them to focus on improving the tooling for writers and contributors. Better tooling will lead to a more enjoyable contribution workflow.</li>
</ul>
<ul id="64658096-d057-4ff4-9261-69b2bfd776b6" class="bulleted-list">
<li style="list-style-type: disc;">All content in Markdown will allow the MDN Web Docs team to run the same linting rules across all active languages.</li>
</ul>
<p id="1ed7c68f-1fc4-44ba-bacd-770b7f12a704" class="">Here is the <a href="https://github.com/mdn/translated-content/issues/7486">tracking issue</a> for this project on the translated content repository.</p>
<h2 id="4c83ede1-34f3-4777-a5c8-c4616fb05971" class="">Tools</h2>
<p id="64326121-feb6-4a38-86ec-eebc986f3672" class="">This section describes the tools you’ll need to participate in this project.</p>
<h3 id="3011e7fd-1549-4c19-8047-e0d43ac69cf4" class="">Git</h3>
<p id="633ea1ad-4a14-4ea7-8a56-5d3c8a2d7c49" class="">If you do not have git installed, you can follow the steps described on this getting started page.</p>
<p id="38e1f0f0-5fec-4af4-b042-89668e17e3d8" class=""><a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">https://git-scm.com/book/en/v2/Getting-Started-Installing-Git</a></p>
<p id="f064c47e-c924-402f-bc02-bb13e63c6492" class="">If you are on Linux or macOS, you may already have Git. To check, open your terminal and run: <code>git --version</code></p>
<p id="84b8b41d-ba5b-4d9a-ab3f-4c8fc13b9758" class="">On Windows, there are a couple of options:</p>
<ul id="fce440cc-4421-4e01-a063-f6a3932d82ce" class="bulleted-list">
<li style="list-style-type: disc;"><a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a></li>
</ul>
<ul id="c24b4e36-2204-4e84-a315-5605a4b92040" class="bulleted-list">
<li style="list-style-type: disc;"><a href="https://gitforwindows.org/">https://gitforwindows.org/</a></li>
</ul>
<ul id="b4cefb3e-2305-43d7-92df-24f7573b5851" class="bulleted-list">
<li style="list-style-type: disc;"><a href="https://chocolatey.org/packages/git">https://chocolatey.org/packages/git</a></li>
</ul>
<h3 id="faed4857-2b93-4e21-a850-d9fc40b88e33" class="">GitHub</h3>
<p id="e1eb9b2a-37aa-4d96-a723-c3ec73963ea6" class="">We&#8217;re tracking source code and managing contributions on GitHub, so the following will be needed:</p>
<p>• A <a href="https://github.com">GitHub account</a>.<br />
• The <a href="https://cli.github.com/">GitHub CLI</a> to follow the commands below. (Encouraged, but optional, i.e., if you are already comfortable using Git, you can accomplish all the same tasks without the need for the GitHub CLI.)</p>
<h3 id="a7e5c4a2-a10f-40e4-b811-2a43eb08b5ab" class="">Nodejs</h3>
<p id="c6522753-982a-4540-bf6a-c538fd4bb3f0" class="">First, install nvm &#8211; <a href="https://github.com/nvm-sh/nvm#installing-and-updating">https://github.com/nvm-sh/nvm#installing-and-updating</a> or on Windows <a href="https://github.com/coreybutler/nvm-windows">https://github.com/coreybutler/nvm-windows</a></p>
<p id="06ad77e2-0568-4747-bb8c-899fae59a4a9" class="">Once all of the above is installed, install Nodejs version 16 with NVM:</p>
<pre id="e8323158-1bfc-46b0-b638-e644f7e839b7" class="code code-wrap"><code>nvm install 16
nvm use 16
node --version</code></pre>
<p id="3970139d-f08e-4ed9-beda-1c0cf5f89ea3" class="">This should output a Nodejs version number that is similar to v16.15.1.</p>
<h2 id="e7de7f3f-b678-496f-9682-996744f64711" class="">Repositories</h2>
<p id="0bbd76aa-989e-4124-9de6-4565d63a4a14" class="">You’ll need code and content from several repositories for this project, as listed below.</p>
<ul id="a583f9a4-620b-49cf-8ef5-b5dc4a673fbc" class="bulleted-list">
<li style="list-style-type: disc;"><a href="https://github.com/mdn/markdown">https://github.com/mdn/markdown</a></li>
</ul>
<ul id="c69ee4e3-df49-4bac-bf19-50c79ee99bac" class="bulleted-list">
<li style="list-style-type: disc;"><a href="https://github.com/mdn/content">https://github.com/mdn/content</a></li>
</ul>
<ul id="32c6074c-cf1a-424f-b68d-4d77b1cb704f" class="bulleted-list">
<li style="list-style-type: disc;"><a href="https://github.com/mdn/translated-content">https://github.com/mdn/translated-content</a></li>
</ul>
<p id="cb4cd4c2-8da4-49b9-b02e-49a58c4269e2" class="">You only need to fork the <code>translated-content</code> repository. We will make direct clones of the other two repositories.</p>
<p id="a2f34cb6-bdcb-4c98-8e67-2c1f0c0ee7a9" class="">Clone the above repositories and your fork of <code>translated-content</code> as follows using the GitHub CLI:</p>
<pre id="ec15a7b8-c606-488d-9205-90977f3cf558" class="code code-wrap"><code>gh repo clone mdn/markdown
gh repo clone mdn/content
gh repo clone username/translated-content # replace username with your GitHub username</code></pre>
<h3 id="4cbeae06-d5ea-46f4-9674-75f89a6e28b7" class="">Setting up the conversion tool</h3>
<pre id="5cc16421-6220-47dc-b160-0350d7900078" class="code code-wrap"><code>cd markdown
yarn</code></pre>
<p id="e4d53c6b-159d-46e1-a694-cb85dfa16878" class="">You’ll also need to add some configuration via an <code>.env</code> file. In the root of the directory, create a new file called <code>.env</code> with the following contents:</p>
<pre id="5436c3f5-1977-4906-8d57-f9e52587908d" class="code code-wrap"><code>CONTENT_TRANSLATED_ROOT=../translated-content/files</code></pre>
<h3 id="24b1d81b-520c-457e-910c-764be33e5e12" class="">Setting up the content repository</h3>
<pre id="bf6194b8-b3b4-4f2c-95e8-da19adbc857c" class="code code-wrap"><code>cd .. # This moves you out of the `markdown` folder
cd content
yarn</code></pre>
<h2 id="023ce13a-2641-43b7-8dc8-c44295bee929" class="">Converting to Markdown</h2>
<p id="b610f57a-828e-4e3e-9cf9-993cdc5e258e" class="">I will touch on some specific commands here, but for detailed documentation, please check out the <a href="https://github.com/mdn/markdown#how-to-use"><code>markdown</code></a><a href="https://github.com/mdn/markdown#how-to-use"> repo’s README</a>.</p>
<p id="023d7b09-5497-441e-9a20-0577a7855157" class="">We maintain a list of documents that need to be converted to Markdown <a href="https://docs.google.com/spreadsheets/d/1Mk3bQoHXozN2rUWn9rxVHA5MiO0whDLuj71KKC0iMSg/edit?usp=sharing">in this Google sheet</a>. There is a worksheet for each language. The worksheets are sorted in the order of the number of documents to be converted in each language &#8211; from the lowest to the highest. You do <em>not</em> need to understand the language to do the conversion. As long as you are comfortable with Markdown and some HTML, you will be able to contribute.</p>
<blockquote id="738b5b36-e51f-4099-ac1b-c8b4e1206038" class=""><p>NOTE: You can find a useful <a href="https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines/Howto/Markdown_in_MDN">reference</a> to the flavor of Markdown supported on MDN Web Docs. There are some customizations, but in general, it is based on <a href="https://github.github.com/gfm/">GitHub flavoured</a> <a href="https://github.github.com/gfm/">Markdown</a>.</p></blockquote>
<h3 id="5f14faaa-dd8d-4558-9b01-06e2a9147fea" class="">The steps</h3>
<ul id="08881988-1f5b-4b2b-a5f2-de540eb3f973" class="bulleted-list">
<li style="list-style-type: disc;"><a href="#318ed501-11e1-4f7b-b773-007d38680c0d">Creating an issue</a></li>
</ul>
<ul id="bef32651-1297-4cbc-97d4-e92a70f8799b" class="bulleted-list">
<li style="list-style-type: disc;"><a href="#31e83ad5-21cf-4448-adeb-232c01c7b550">Updating the spreadsheet</a></li>
</ul>
<ul id="1528d6d7-8da1-40b8-82b8-d382de96cb4e" class="bulleted-list">
<li style="list-style-type: disc;"><a href="#0dc217b0-c222-4faf-9b03-0b8586140259">Creating a feature branch</a></li>
</ul>
<ul id="c3d33d8f-9d78-47e2-b228-728c7665f889" class="bulleted-list">
<li style="list-style-type: disc;"><a href="#fbf5bb13-9978-47fe-b0e4-b66d6666654a">Running the conversion</a></li>
</ul>
<ul id="83e2bbc6-5717-4880-8192-8e8c12fc2d7c" class="bulleted-list">
<li style="list-style-type: disc;"><a href="#523d114d-0ab4-4965-ab2b-765caaa91eba">Testing the changes</a></li>
</ul>
<ul id="0ae22b6d-8bee-45ec-ad58-749bbbb0a544" class="bulleted-list">
<li style="list-style-type: disc;"><a href="#10cdd99f-5808-4262-847a-6129f9f85e21">Preparing and opening the pull request</a></li>
</ul>
<h3 id="318ed501-11e1-4f7b-b773-007d38680c0d" class="">Creating an issue</h3>
<p id="e8dbc730-36c4-476c-876b-8486684c69c7" class="">On the <a href="https://github.com/mdn/translated-content"><code>translated-content</code></a> <a href="https://github.com/mdn/translated-content">repository</a> go to the Issues tab and click on the &#8220;New issue&#8221; button. As mentioned in the introduction, there is a tracking issue for this work and so, it is good practice to reference the tracking issue in the issue you’ll create.</p>
<p id="43ccdd78-d326-41b5-a113-8ad276fb8d91" class="">You will be presented with three options when you click the &#8220;New issue&#8221; button. For our purposes here, we will choose the &#8220;Open a blank issue&#8221; option. For the title of the issue, use something like, &#8220;chore: convert mozilla/firefox/releases for Spanish to Markdown&#8221;. In your description, you can add something like the following:</p>
<blockquote id="2e7c6f2a-fded-4e48-b0ef-5c4d9a816b24" class=""><p>As part of the larger 100% Markdown <a href="https://github.com/mdn/translated-content/issues/7486">project</a>, I am converting the set of documents under mozilla/firefox/releases to Markdown.</p>
<ul id="875a6ed0-6034-4f80-a961-5697a035114f" class="bulleted-list">
<li style="list-style-type: disc;"><a href="https://docs.google.com/spreadsheets/d/1Mk3bQoHXozN2rUWn9rxVHA5MiO0whDLuj71KKC0iMSg/edit#gid=617080625">Tracking spreadsheet</a></li>
</ul>
</blockquote>
<blockquote id="af2bc027-a3ad-4479-833d-0d6817180019" class=""><p>NOTE: You will most likely be unable to a assign an issue to yourself. The best thing to do here is to mention the localization <a href="https://github.com/orgs/mdn/teams">team member for the appropriate </a><a href="https://github.com/orgs/mdn/teams">locale</a> and ask them to assign the issue to you. For example, on GitHub you would add a comment like this: &#8220;Hey @mdn/yari-content-es I would like to work on this issue, please assign it to me. Thank you!&#8221;</p>
<p>You can find a <a href="https://github.com/orgs/mdn/teams">list of teams here</a>.</p></blockquote>
<h3 id="31e83ad5-21cf-4448-adeb-232c01c7b550" class="">Updating the spreadsheet</h3>
<p id="157ca9d4-21bd-4281-a592-9da8ffb64e67" class="">The tracking spreadsheet contains a couple of fields that you should update if you intend to work on speific items. The first item you need to add is your GitHub username and link the text to your GitHub profile. Secondly, set the status to &#8220;In progress&#8221;. In the issue column, paste a link to the issue you created in the previous step.</p>
<h3 id="0dc217b0-c222-4faf-9b03-0b8586140259" class="">Creating a feature branch</h3>
<p id="4f07dd9d-f0ee-463e-b060-e4327c8d9533" class="">It is a common practice on projects that use Git and GitHub to follow a <a href="https://www.atlassian.com/git/tutorials/comparing-workflows/feature-branch-workflow">feature branch workflow</a>. I therefore need to create a feature branch for the work on the <code>translated-content</code> repository. To do this, we will again use our issue as a reference.</p>
<p id="408ea1ed-dbf6-4fb7-9f55-d626f6d563fd" class="">Let’s say your issue was called &#8221; chore: convert mozilla/firefox/releases for Spanish to Markdown&#8221; with an <code>id</code> of 8192. You will do the following at the root of the <code>translated-content</code> repository folder:</p>
<blockquote id="673fdf26-7e2c-4bb1-80c1-96aa987427bd" class=""><p>NOTE: The translated content repository is a very active repository. Before creating your feature branch, be sure to pull the latest from the remote using the command <code>git pull upstream main</code></p></blockquote>
<pre id="52e3af3c-cb34-4642-9d60-faccd2e5972a" class="code code-wrap"><code>git pull upstream main
git switch -c 8192-chore-es-convert-firefox-release-docs-to-markdown</code></pre>
<blockquote id="89e267bb-d477-4df4-86fd-23169c9131d9" class=""><p>NOTE: In older version of Git, you will need to use <code>git checkout -B 8192-chore-es-convert-firefox-release-docs-to-markdown</code>.</p></blockquote>
<p id="dacb20a4-f302-49af-887b-d3e6c9668df4" class="">The above command will create the feature branch and switch to it.</p>
<h2 id="fbf5bb13-9978-47fe-b0e4-b66d6666654a" class="">Running the conversion</h2>
<p id="459e125b-fc27-44be-8b08-3e20556f8d9c" class="">Now you are ready to do the conversion. The Markdown conversion tool has a couple of modes you can run it in:</p>
<ul id="419bd88b-90e5-46a3-a44c-fcfc3681bc39" class="bulleted-list">
<li style="list-style-type: disc;">dry &#8211; Run the script, but do not actually write <em>any</em> output</li>
</ul>
<ul id="39c3cf8f-9e10-4f6f-9f79-82b374a197e1" class="bulleted-list">
<li style="list-style-type: disc;">keep &#8211; Run the script and do the conversion but, <em>do not</em> delete the HTML file</li>
</ul>
<ul id="81101e9e-5f8a-4b17-affe-8dc586407a76" class="bulleted-list">
<li style="list-style-type: disc;">replace &#8211; Do the conversion and delete the HTML file</li>
</ul>
<p id="46bc082c-4c07-42c4-9bc3-300e5f1f2a88" class="">You will almost always start with a <code>dry</code> run.</p>
<blockquote><p>NOTE: Before running the command below, esnure that you are in the root of the markdown repository.</p></blockquote>
<pre id="74494e2a-3880-4585-9ccf-10d9d4b1633a" class="code code-wrap"><code>yarn h2m mozilla/firefox/releases --locale es --mode dry</code></pre>
<p id="d471219b-3fd2-402f-a994-45a71332ba99" class="">This is because the conversion tool will sometimes encounter situations where it does not know how to convert parts of the document. The markdown tool will produce a report with details of the errors encountered. For example:</p>
<pre id="5e103ada-5183-4ba8-b8c0-9f20a9bf41fc" class="code code-wrap"><code># Report from 9/1/2022, 2:40:14 PM
## All unhandled elements
- li.toggle (4)
- dl (2)
- ol (1)
## Details per Document
### [/es/docs/Mozilla/Firefox/Releases/1.5](&lt;https://developer.mozilla.org/es/docs/Mozilla/Firefox/Releases/1.5&gt;)
#### Invalid AST transformations
##### dl (101:1) =&gt; listItem

type: "text"
value: ""

### [/es/docs/Mozilla/Firefox/Releases/3](&lt;https://developer.mozilla.org/es/docs/Mozilla/Firefox/Releases/3&gt;)
### Missing conversion rules
- dl (218:1)
</code></pre>
<p id="23a95fa8-6379-4d45-a80e-ef486f0c1ddd" class="">The first line in the report states that the tool had a problem converting four instances of <code>li.toggle</code>. So, there are four list items with the <code>class</code> attribute set to <code>toggle</code>. In the larger report, there is this section:</p>
<pre id="6eb2222d-5795-492c-8df5-96872bfa0878" class="code code-wrap"><code>### [/es/docs/Mozilla/Firefox/Releases/9](&lt;https://developer.mozilla.org/es/docs/Mozilla/Firefox/Releases/9&gt;)
#### Invalid AST transformations
##### ol (14:3) =&gt; list

type: "html"
value: "&lt;li class=\\"toggle\\"&gt;&lt;details&gt;&lt;summary&gt;Notas de la Versión para Desarrolladores de Firefox&lt;/summary&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Firefox/Releases\\"&gt;Notas de la Versión para Desarrolladores de Firefox&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/details&gt;&lt;/li&gt;",type: "html"
value: "&lt;li class=\\"toggle\\"&gt;&lt;details&gt;&lt;summary&gt;Complementos&lt;/summary&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=\\"/es/Add-ons/WebExtensions\\"&gt;Extensiones del navegador&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/Add-ons/Themes\\"&gt;Temas&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/details&gt;&lt;/li&gt;",type: "html"
value: "&lt;li class=\\"toggle\\"&gt;&lt;details&gt;&lt;summary&gt;Firefox por dentro&lt;/summary&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/\\"&gt;Proyecto Mozilla (Inglés)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Gecko\\"&gt;Gecko&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Firefox/Headless_mode\\"&gt;Headless mode&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/JavaScript_code_modules\\"&gt;Modulos de código JavaScript (Inglés)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/js-ctypes\\"&gt;JS-ctypes (Inglés)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/MathML_Project\\"&gt;Proyecto MathML&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/MFBT\\"&gt;MFBT (Inglés)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Projects\\"&gt;Proyectos Mozilla (Inglés)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Preferences\\"&gt;Sistema de Preferencias (Inglés)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/WebIDL_bindings\\"&gt;Ataduras WebIDL (Inglés)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Tech/XPCOM\\"&gt;XPCOM&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Tech/XUL\\"&gt;XUL&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/details&gt;&lt;/li&gt;",type: "html"
value: "&lt;li class=\\"toggle\\"&gt;&lt;details&gt;&lt;summary&gt;Crear y contribuir&lt;/summary&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Developer_guide/Build_Instructions\\"&gt;Instrucciones para la compilación&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Developer_guide/Build_Instructions/Configuring_Build_Options\\"&gt;Configurar las opciones de compilación&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Developer_guide/Build_Instructions/How_Mozilla_s_build_system_works\\"&gt;Cómo funciona el sistema de compilación (Inglés)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Developer_guide/Source_Code/Mercurial\\"&gt;Código fuente de Mozilla&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Localization\\"&gt;Localización&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Mercurial\\"&gt;Mercurial (Inglés)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/QA\\"&gt;Garantía de Calidad&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=\\"/es/docs/Mozilla/Using_Mozilla_code_in_other_projects\\"&gt;Usar Mozilla en otros proyectos (Inglés)&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/details&gt;&lt;/li&gt;"
</code></pre>
<p id="e9796a87-c6af-4267-a310-e2cbcb3d8ff7" class="">The problem is therefore in the file <code>/es/docs/Mozilla/Firefox/Releases/9</code>. In this instance, we can ignore this as we will simply leave the HTML as is in the Markdown. This is sometimes needed as the HTML we need cannot be accurately represented in Markdown. The part you cannot see in the output above is this portion of the file:</p>
<pre id="39d0ed24-ef13-4bd5-add9-1e651d578ec0" class="code code-wrap"><code>&lt;div&gt;&lt;section id="Quick_links"&gt;
  &lt;ol&gt;
    &lt;li class="toggle"&gt;
</code></pre>
<p id="bb78e194-f911-4aae-84f0-ffe7bef2cbb6" class="">If you do a search in the main <code>content</code> repo you will find lots of instances of this. In all those cases, you will see that the HTML is kept in place and this section is <em>not</em> converted to Markdown.</p>
<p id="983609d7-f39a-41c9-9712-12fc4435c470" class="">The next two problematic items are two <code>dl</code> or description list elements. These elements will require manual conversion using the guidelines in <a href="https://developer.mozilla.org/en-US/docs/MDN/Writing_guidelines/Howto/Markdown_in_MDN#definition_lists">our documentation</a>. The last item, the <code>ol</code> is actually related to the <code>li.toggle</code> issue. Those list items are wrapped by an <code>ol</code> and because the tool is not sure what to do with the list items, it is also complaining about the ordered list item.</p>
<p id="de1fd3f2-1122-4fb1-969f-37251dfde378" class="">Now that we understand what the problems are, we have two options. We can run the exact same command but this time use the <code>replace</code> mode or, we can use the <code>keep</code> mode. I am going to go ahead and run the command with <code>replace</code>. While the previous command did not actually write anything to the translated content repository, when run with <code>replace</code> it will create a new file called <code>index.md</code> with the converted Markdown and delete the <code>index.html</code> that resides in the same directory.</p>
<pre id="cd2af5a5-6f26-4b28-b5fa-b73c34066a70" class="code code-wrap"><code>yarn h2m mozilla/firefox/releases --locale es --mode replace</code></pre>
<p id="531efafe-81c7-4b0f-94a7-0107279dbb01" class="">Following the guidelines from the report, I will have to pay particular attention to the following files post conversion:</p>
<ul id="a86e1ddf-68c1-43ea-95ec-8e190e067138" class="bulleted-list">
<li style="list-style-type: disc;"><code>/es/docs/Mozilla/Firefox/Releases/1.5</code></li>
</ul>
<ul id="cc0a38ad-b4bd-4785-a74d-db10610851bc" class="bulleted-list">
<li style="list-style-type: disc;"><code>/es/docs/Mozilla/Firefox/Releases/3</code></li>
</ul>
<ul id="b8b38eff-ff2d-4964-9135-8cc26640e2de" class="bulleted-list">
<li style="list-style-type: disc;"><code>/es/docs/Mozilla/Firefox/Releases/9</code></li>
</ul>
<p id="d759a252-744f-4f96-aca6-e238f739e7c4" class="">After running the command, run the following at the root of the translated content repository folder, <code>git status</code>. This will show you a list of the changes made by the command. Depending on the number of files touched, the output can be verbose. The vital thing to keep an eye out for is that there are no changes to folders or files you did not expect.</p>
<h2 id="523d114d-0ab4-4965-ab2b-765caaa91eba" class="">Testing the changes</h2>
<p id="b9e30796-51ee-45b8-a1fe-cf8de24a79c1" class="">Now that the conversion has been done, we need to review the syntax and see that the pages render correctly. This is where the <code>content</code> repo is going to come into play. As with the <code>markdown</code> repository, we also need to create a <code>.env</code> file at the root of the content folder.</p>
<pre id="08bc4613-8772-4148-935a-5248b3190470" class="code code-wrap"><code>CONTENT_TRANSLATED_ROOT=../translated-content/files</code></pre>
<p id="9654ee50-3bf9-420a-9780-b174f6e17f9c" class="">With this in place we can start the development server and take a look at the pages in the browser. To start the server, run <code>yarn start</code>. You should see output like the following:</p>
<pre id="b826eaea-e6a6-4a60-91d8-e23f61075cbb" class="code code-wrap"><code>❯ yarn start
yarn run v1.22.17
$ yarn up-to-date-check &amp;&amp; env-cmd --silent cross-env CONTENT_ROOT=files REACT_APP_DISABLE_AUTH=true BUILD_OUT_ROOT=build yari-server
$ node scripts/up-to-date-check.js
[HPM] Proxy created: /  -&gt; &lt;https://developer.mozilla.org&gt;
CONTENT_ROOT: /Users/schalkneethling/mechanical-ink/dev/mozilla/content/files
Listening on port 5042
</code></pre>
<p id="549a85ab-dfc5-4a95-9368-d27c9a34f450" class="">Go ahead and open <a href="http://localhost:5042/">http://localhost:5042</a> which will serve the homepage. To find the URL for one of the pages that was converted open up the Markdown file and look at the slug in the frontmatter. When you ran <code>git status</code> earlier, it would have printed out the file paths to the terminal window. The file path will show you exactly where to find the file, for example, <code>files/es/mozilla/firefox/releases/1.5/index.md</code>. Go ahead and open the file in your editor of choice.</p>
<p id="46d6359c-3650-4760-8290-4b08ec258be8" class="">In the frontmatter, you will find an entry like this:</p>
<pre id="40eb046e-8c1e-4618-9224-345436fc7609" class="code code-wrap"><code>slug: Mozilla/Firefox/Releases/1.5
</code></pre>
<p id="73a74e99-48c3-41fa-b572-92ab3e7b798d" class="">To load the page in your browser, you will always prepend <code>http://localhost:5042/es/docs/</code> to the slug. In other words, the final URL you will open in your browser will be <code>http://localhost:5042/es/docs/Mozilla/Firefox/Releases/1.5</code>. You can open the English version of the page in a separate tab to compare, but be aware that the content could be wildly different as you might have converted a page that has not been updated in some time.</p>
<p id="0a508064-d62b-4319-8c7f-6700c641b132" class="">What you want to look out for is anything in the page that looks like it is not rendering correctly. If you find something that looks incorrect, look at the Markdown file and see if you can find any syntax that looks incorrect or completely broken. It can be extremely useful to use a tool such as <a href="https://code.visualstudio.com/">VSCode</a> with a <a href="https://marketplace.visualstudio.com/items?itemName=yzhang.markdown-all-in-one">Markdown tool</a> and <a href="https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode">Prettier</a> installed.</p>
<p id="f3fa1626-53d8-429c-a3de-c42c4038f126" class="">Even if the rendered content looks good, do take a minute and skim over the generated Markdown and see if the linters bring up any possible errors.</p>
<blockquote id="88e4c831-eba2-4741-81df-16b1e8e126c9" class=""><p>NOTE: If you see code like this {{FirefoxSidebar}} this is a macro call. There is not a lot of documentation yet but, these macros come from <a href="https://github.com/mdn/yari/tree/main/kumascript">KumaScript</a><a href="https://github.com/mdn/yari/tree/main/kumascript"> in Yari</a>.</p></blockquote>
<p id="4e3c93df-8b8c-44a6-ba09-a3d46e54e968" class="">A couple of other things to keep in mind. When you run into an error, before you spend a lot of time trying to understand what exatly the problem is or how to fix it, do the following:</p>
<ol id="8aaa5ee7-ce82-43f6-9fdb-e18beaacd1e9" class="numbered-list" start="1" type="1">
<li>Look for the same page in the <code>content</code> repository and make sure the page still exists. If it was removed from the <code>content</code> repository, you can safely remove it from <code>translated-content</code> as well.</li>
</ol>
<ol id="8320d1e9-a541-43d1-b266-1e035f5b692f" class="numbered-list" start="2" type="1">
<li>Look at the same page in another language that has already been converted and see how they solved the problem.</li>
</ol>
<p id="598b8ca2-3f3f-4eac-8dad-0a696a4921ba" class="">For example, I ran into an error where a page I loaded simply printed the following in the browser: <code>Error: 500 on /es/docs/Mozilla/Firefox/Releases/2/Adding_feed_readers_to_Firefox/index.json: SyntaxError: Expected "u" or ["bfnrt\\\\/] but "_" found.</code>. I narrowed it down to the following piece of code inside the Markdown:</p>
<pre id="15e9c726-e8d5-448f-8fe4-2abc96bc9425" class="code code-wrap"><code>{{ languages( { "en": "en/Adding\\_feed\\_readers\\_to\\_Firefox", "ja": "ja/Adding\\_feed\\_readers\\_to\\_Firefox", "zh-tw": "zh\\_tw/\\u65b0\\u589e\\u6d88\\u606f\\u4f86\\u6e90\\u95b1\\u8b80\\u5de5\\u5177" } ) }}</code></pre>
<p id="b19e74be-499f-495e-a736-41e0006a3b0d" class="">In French it seems that they removed the page, but when I looked in <code>zh-tw</code> it looks like they simply removed this macro call. I opted for the latter and just removed the macro call. This solved the problem and the page rendered correctly. Once you have gone through all of the files you converted it is time to open a pull request.</p>
<h2 id="10cdd99f-5808-4262-847a-6129f9f85e21" class="">Preparing and opening a pull request</h2>
<pre id="26014d95-8952-45c1-b021-84863dcd96fe" class="code code-wrap"><code># the dot says add everything
git add .</code></pre>
<p id="97f09c52-5f40-4370-83ea-bc9fb83a14c3" class="">Start by getting all your changes ready for committing:</p>
<p id="a5fdf8dc-14a6-4967-97e1-fe0865efeb2c" class="">If you run <code>git status</code> now you will see something like the following:</p>
<pre id="f3f8d2ff-6305-4a0a-85ef-0bffc88b7f3e" class="code code-wrap"><code>❯ git status
On branch 8192-chore-es-convert-firefox-release-docs-to-markdown
Changes to be committed: # this be followed by a list of files that has been added, ready for commit
</code></pre>
<p id="6b7cbb56-9749-492e-8e21-c63c71a0ef43" class="">Commit your changes:</p>
<pre id="87772da1-223e-4aa8-829f-6f98fc809aa3" class="code code-wrap"><code>git commit -m 'chore: convert Firefox release docs to markdown for Spanish'
</code></pre>
<p id="ce08021c-4cff-47d6-9c33-728cb275a2be" class="">Finally you need to push the changes to GitHub so we can open the pull request:</p>
<pre id="1e07b73a-a746-464d-9ac1-82a5f8df831c" class="code code-wrap"><code>git push origin 8192-chore-es-convert-firefox-release-docs-to-markdown
</code></pre>
<p id="65cf6686-90c6-4313-b252-c01daaebb3ec" class="">You can now head over to the <a href="https://github.com/mdn/translated-content">translated content repository on GitHub</a> where you should see a banner that asks whether you want to open a pull request. Click the &#8220;Compare and pull button&#8221; and look over your changes on the next page to ensure nothing surprises.</p>
<p id="e395a8da-c868-4532-af48-927b713b2172" class="">At this point, you can also add some more information and context around the pull request in the description box. It is also critical that you add a line as follows, &#8220;Fix #8192&#8221;. Substitute the number with the number of the issue you created earlier. The reason we do this is so that we link the issue and the pull request. What will also happen is, once the pull request is merged, GitHub will automatically close the issue.</p>
<p id="e5dba51f-63a5-4981-8350-08015e681b08" class="">Once you are satisfied with the changes as well as your description, go ahead and click the button to open the pull request. At this stage GitHub will auto-assign someone from the appropriate localization team to review your pull request. You can now sit back and wait for feedback. Once you receive feedback, address any changes requested by the reviewer and update your pull request.</p>
<p id="c9c58243-966d-4f01-a7ee-a8349fbd005e" class="">Once you are both satisfied with the end result, the pull request will be merged and you will have helped us get a little bit closer to 100% Markdown. Thank you! One final step remains though. Open the <a href="https://docs.google.com/spreadsheets/d/1Mk3bQoHXozN2rUWn9rxVHA5MiO0whDLuj71KKC0iMSg/edit">spreadsheet</a> and update the relevant rows with a link to the pull request, and update the status to &#8220;In review&#8221;.</p>
<p id="b8e9c4f2-d489-4923-b3ba-783f7893c466" class="">Once the pull request has been merged, remember to come back and update the status to done.</p>
<h3 id="124054a2-a9c1-4f91-9237-bb7245692078" class="">Reach out if you need help</h3>
<p id="e2601d7c-f439-4770-ad4f-529271aafb64" class="">If you run into any problems and have questions, please join our MDN Web Docs channel on Matrix.</p>
<p id="05c4f97e-9187-4b82-8364-11996bcacda2" class=""><a href="https://matrix.to/#/#mdn:mozilla.org">https://matrix.to/#/#mdn:mozilla.org</a></p>
<p>&nbsp;</p>
</div>
</article>
<p>Photo by <a href="https://unsplash.com/@taguwan?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Cristian Grecu</a> on <a href="https://unsplash.com/s/photos/mountain-peak?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/09/the-100-percent-markdown-expedition/">The 100% Markdown Expedition</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Merging two GitHub repositories without losing commit history</title>
		<link>https://hacks.mozilla.org/2022/08/merging-two-github-repositories-without-losing-commit-history/</link>
					<comments>https://hacks.mozilla.org/2022/08/merging-two-github-repositories-without-losing-commit-history/#comments</comments>
		
		<dc:creator><![CDATA[Schalk Neethling]]></dc:creator>
		<pubDate>Mon, 29 Aug 2022 07:54:58 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Git & GitHub]]></category>
		<category><![CDATA[MDN]]></category>
		<category><![CDATA[git]]></category>
		<category><![CDATA[github]]></category>
		<category><![CDATA[how-to]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47913</guid>

					<description><![CDATA[<p>How do you merge two Git repositories without losing history? This post will take you through the step-by-step process.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/08/merging-two-github-repositories-without-losing-commit-history/">Merging two GitHub repositories without losing commit history</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<article id="81bbaff4-5f9f-4d40-891c-c7849a2fa6ec" class="page sans">
<header>
<h1 class="page-title">Merging two GitHub repositories without losing history</h1>
</header>
<div class="page-body">
<p id="d76979e8-387a-41c4-979e-c5986dd3b0c0" class="">We are in the process of merging smaller example code repositories into larger parent repositories on the MDN Web Docs project. While we thought that copying the files from one repository into the new one would lose commit history, we felt that this might be an OK strategy. After all, we are not deleting the old repository but archiving it.</p>
<p id="5731f3f5-0a4f-40e0-bbb9-bbf63d98b0fa" class="">After having moved a few of these, we did <a href="https://github.com/mdn/dom-examples/issues/134">receive an issue from a community member</a> stating that it is not ideal to lose history while moving these repositories and that there <a href="https://github.com/mdn/dom-examples/issues/134">could be a relatively simple way</a> to avoid this. I experimented with a couple of different options and finally settled on a strategy based on the one <a href="https://saintgimp.org/2013/01/22/merging-two-git-repositories-into-one-repository-without-losing-file-history/">shared by Eric Lee on his blog</a>.</p>
<blockquote id="f5391a9d-5e78-4aaf-bde4-84fae94a16e4" class=""><p><strong>tl;dr</strong> The approach is to use basic git commands to apply all of the histories of our old repo onto a new repo without needing special tooling.</p></blockquote>
<nav id="a244ef85-138a-4d8e-a059-0a4dd12d2a87" class="block-color-gray table_of_contents">
<div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#0abdb9ef-9200-447c-9348-b5d8bac5b185">Getting started</a></div>
<div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#367b4f61-defe-46ee-a0ea-e25bcafc59fa">How to exclude subdirectories when using <code>mv</code></a></div>
<div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#dbcc4e95-edfa-4f98-a2e0-c4691f4fd050">Handling hidden files and creating a pull request</a></div>
<div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#0272b87e-05fc-4ddb-96fa-7867df545657">Merging our repositories</a></div>
<div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#c7bd35e7-333b-4e4e-bdff-7f145a5c2637">In Conclusion</a></div>
</nav>
<h2 id="0abdb9ef-9200-447c-9348-b5d8bac5b185" class="">Getting started</h2>
<p id="94c91a76-2437-4bbc-b70b-6f1463af29a7" class="">For the experiment, I used the <a href="https://github.com/mdn/sw-test"><code>sw-test</code></a> repository that is meant to be merged into the <a href="https://github.com/mdn/dom-examples"><code>dom-examples</code></a> repository.</p>
<p id="e026f2d9-ab20-42e2-9787-b71edd3fb29c" class="">This is how Eric describes the first steps:</p>
<pre id="7c984405-6ffd-4577-a56a-7af104413a32" class="code code-wrap"><code># Assume the current directory is where we want the new repository to be created
# Create the new repository

git init

# Before we do a merge, we need to have an initial commit, so we’ll make a dummy commit

dir &gt; deleteme.txt
git add .
git commit -m “Initial dummy commit”

# Add a remote for and fetch the old repo
git remote add -f old_a &lt;OldA repo URL&gt;

# Merge the files from old_a/master into new/master
git merge old_a/master</code></pre>
<p id="1ec6e693-4c83-47bb-ae27-999a1f0da4b0" class="">I could skip everything up to the <code>git remote ...</code> step as my target repository already had some history, so I started as follows:</p>
<pre id="91ca30c5-293f-464a-8a49-84b3f0a0ae7f" class="code code-wrap"><code>git clone https://github.com/mdn/dom-examples.git
cd dom-examples</code></pre>
<p id="5e489297-b8ab-454b-9ff6-becfa188a995" class="">Running <code>git log</code> on this repository, I see the following commit history:</p>
<pre id="1a1124c2-cc64-4db1-bd58-be3ba946ea54" class="code code-wrap"><code>commit cdfd2aeb93cb4bd8456345881997fcec1057efbb (HEAD -&gt; master, upstream/master)
Merge: 1c7ff6e dfe991b
Author:
Date:   Fri Aug 5 10:21:27 2022 +0200

    Merge pull request #143 from mdn/sideshowbarker/webgl-sample6-UNPACK_FLIP_Y_WEBGL

    “Using textures in WebGL”: Fix orientation of Firefox logo

commit dfe991b5d1b34a492ccd524131982e140cf1e555
Author:
Date:   Fri Aug 5 17:08:50 2022 +0900

    “Using textures in WebGL”: Fix orientation of Firefox logo

    Fixes &lt;https://github.com/mdn/content/issues/10132&gt;

commit 1c7ff6eec8bb0fff5630a66a32d1b9b6b9d5a6e5
Merge: be41273 5618100
Author:
Date:   Fri Aug 5 09:01:56 2022 +0200

    Merge pull request #142 from mdn/sideshowbarker/webgl-demo-add-playsInline-drop-autoplay

    WebGL sample8: Drop “autoplay”; add “playsInline”

commit 56181007b7a33907097d767dfe837bb5573dcd38
Author:
Date:   Fri Aug 5 13:41:45 2022 +0900
</code></pre>
<p id="9b0be3c8-62aa-4e6f-a982-603c03944ded" class="">With the current setup, I could continue from the <code>git remote</code> command, but I wondered if the current directory contained files or folders that would conflict with those in the service worker repository. I searched around some more to see if anyone else had run into this same situation but did not find an answer. Then it hit me! I need to prepare the service worker repo to be moved.</p>
<p id="f28077e4-2c8f-4248-a235-2eb80207d7c8" class="">What do I mean by that? I need to create a new directory in the root of the <code>sw-test</code> repo called <code>service-worker/sw-test</code> and move all relevant files into this new subdirectory. This will allow me to safely merge it into <code>dom-examples</code> as everything is contained in a subfolder already.</p>
<p id="a1e3770b-a673-4d74-a4b1-17d7930e9352" class="">To get started, I need to clone the repo we want to merge into <code>dom-</code><code>examples</code>.</p>
<pre id="071ba87f-ee28-4b2a-b4fa-61796f8ad20a" class="code code-wrap"><code>git clone https://github.com/mdn/sw-test.git
cd sw-test</code></pre>
<p id="f032fac1-56ef-4a92-8851-d37700e14143" class="">Ok, now we can start preparing the repo. The first step is to create our new subdirectory.</p>
<pre id="131694fb-bbb2-4d49-a9e6-817f221fc635" class="code code-wrap"><code>mkdir service-worker
mkdir service-worker/sw-test</code></pre>
<p id="35d63bf0-896a-4d02-babe-e39c3f4af44c" class="">With this in place, I simply need to move everything in the root directory to the subdirectory. To do this, we will make use of the <a href="https://www.rapidtables.com/code/linux/mv.html">move (</a><a href="https://www.rapidtables.com/code/linux/mv.html"><code>mv</code></a><a href="https://www.rapidtables.com/code/linux/mv.html">) command</a>:</p>
<blockquote id="e4c3d33e-eec2-4e61-8aef-b3f28b1ca5c6" class=""><p>NOTE: Do not yet run any of the commands below at this stage.</p></blockquote>
<pre id="42c8e3b9-23e0-42cb-b176-a19a3055be7e" class="code code-wrap"><code>
# enable extendedglob for ZSH
set -o extendedglob
mv ^sw-test(D) service-worker/swtest</code></pre>
<p id="f9210a49-47a0-44bc-b148-ab4a94422938" class="">The above command is a little more complex than you might think. It uses a negation syntax. The next section explains why we need it and how to enable it.</p>
<h2 id="367b4f61-defe-46ee-a0ea-e25bcafc59fa" class="">How to exclude subdirectories when using <code>mv</code></h2>
<p id="69a87233-c045-44b5-a7b3-300acc57ece1" class="">While the end goal seemed simple, I am pretty sure I grew a small animal&#8217;s worth of grey hair trying to figure out how to make that last move command work. I read many StackOverflow threads, blog posts, and manual pages for the different commands with varying amounts of success. However, none of the initial set of options quite met my needs. I finally stumbled upon two StackOverflow threads that brought me to the answer.</p>
<ul id="c4b53d6d-572d-4dd5-981f-6b62d991d709" class="bulleted-list">
<li style="list-style-type: disc;"><a href="https://unix.stackexchange.com/questions/567970/how-to-move-all-files-in-a-folder-to-a-sub-folder-in-zsh-w-mac-os-x/">How to move all files in a folder to a sub folder in zsh w/ Mac OS X?</a></li>
</ul>
<ul id="1af8c0d9-acf0-4d52-acc6-4241003f922e" class="bulleted-list">
<li style="list-style-type: disc;"><a href="https://askubuntu.com/questions/91740/how-to-move-all-files-in-current-folder-to-subfolder">How to move all files in current folder to subfolder?</a></li>
</ul>
<p id="384c80a1-89f5-4e4a-9aeb-9d4ecec6e9dc" class="">To spare you the trouble, here is what I had to do.</p>
<blockquote id="744ec536-d86a-4c12-af28-618364341983" class=""><p>First, a note. I am on a Mac using ZSH (since macOS Catalina, this is now the default shell). Depending on your shell, the instructions below may differ.</p></blockquote>
<p id="c332b161-7756-4197-b6bb-5b76a1825fc6" class="">For new versions of ZSH, you use the <code>set -o</code> and <code>set +o</code> commands to enable and disable settings. To enable <code>extendedglob</code>, I used the following command:</p>
<pre id="b0a08bae-6f4a-4f92-b6e8-82649b3f3e3a" class="code code-wrap"><code>
# Yes, this _enables_ it
set -o extendedglob</code></pre>
<p id="9b36d318-8202-49bb-a955-e40f19f08370" class="">On older versions of ZSH, you use the <code>setopt</code> and <code>unsetopt</code> commands.</p>
<pre id="78b9b670-06c0-48a9-8fe4-e1811a7beab7" class="code code-wrap"><code>setopt extendedglob</code></pre>
<p id="229b37f6-e148-4b2d-8620-2b34b8d4d39b" class="">With <a href="https://www.gnu.org/software/bash/"><code>bash</code></a>, you can achieve the same using the following command:</p>
<pre id="3e2d2907-3827-4fc1-800d-96663de788de" class="code code-wrap"><code>shopt -s extglob</code></pre>
<p id="877728bd-5dfe-431c-9133-6d217dfae435" class="">Why do you even have to do this, you may ask? Without this, you will not be able to use the negation operator I use in the above move command, which is the crux of the whole thing. If you do the following, for example:</p>
<pre id="ecaaf2de-29ad-474c-a6f0-5df55fe634c5" class="code code-wrap"><code>mkdir service-worker
mv * service-worker/sw-test</code></pre>
<p id="036aa161-c596-4a20-911b-d16b42368106" class="">It will &#8220;work,&#8221; but you will see an error message like this:</p>
<pre id="04035162-e15c-430a-9f23-f10504643521" class="code code-wrap"><code>mv: rename service-worker to service-worker/sw-test/service-worker: Invalid argument</code></pre>
<p id="ae99fd19-d26d-43c2-a167-6681f70f5f76" class="">We <em>want</em> to tell the operating system to move everything into our new subfolder except the subfolder itself. We, therefore, need this negation syntax. It is not enabled by default because it could cause problems if file names contain some of the <code>extendedglob</code> patterns, such as <code>^</code>. So we need to enable it explicitly.</p>
<blockquote id="9f6a3340-608b-408c-9b81-5cb9bafc2a78" class=""><p>NOTE: You might also want to disable it after completing your move operation.</p></blockquote>
<p id="c0f4da3e-8ee0-47bf-863f-6987e5682ea9" class="">Now that we know how and why we want <code>extendedglob</code> enabled, we move on to using our new powers.</p>
<blockquote id="62ff5fad-59a6-477c-b798-1048211422de" class=""><p>NOTE: Do not yet run any of the commands below at this stage.</p></blockquote>
<pre id="1d22e143-50b1-4f68-b608-bbef21f49efc" class="code code-wrap"><code>mv ^sw-test(D) service-worker/sw-test</code></pre>
<p id="dbdbf5a8-c8d2-4a0a-9369-8d91dd7028d2" class="">The above means:</p>
<ul id="8d1f6367-8982-4a47-990c-14ccfcfb473f" class="bulleted-list">
<li style="list-style-type: disc;">Move all the files in the current directory into <code>service-worker/sw-test</code>.</li>
</ul>
<ul id="f88a5050-a4a7-468f-9185-f33571641913" class="bulleted-list">
<li style="list-style-type: disc;">Do not try to move the <code>service-worker</code> directory itself.</li>
</ul>
<ul id="41c7b8d9-0811-4bd8-8168-03e120a71df7" class="bulleted-list">
<li style="list-style-type: disc;">The (D) option tells the move command to also move all hidden files, such as <code>.gitignore</code>, and hidden folders, such as <code>.git</code>.</li>
</ul>
<blockquote id="496dc420-f3fb-4f37-ae38-240f3d705d1c" class=""><p>NOTE: I found that if I typed <code>mv ^sw-test</code> and pressed tab, my terminal would expand the command to <code>mv CODE_OF_CONDUCT.md LICENSE README.md app.js gallery image-list.js index.html service-worker star-wars-logo.jpg style.css sw.js.</code> If I typed <code>mv ^sw-test(D)</code> and pressed tab, it would expand to <code>mv .git .prettierrc CODE_OF_CONDUCT.md LICENSE README.md app.js gallery image-list.js index.html service-worker star-wars-logo.jpg style.css sw.js</code>. This is interesting because it clearly demonstrates what happens under the hood. This allows you to see the effect of using <code>(D)</code> clearly. I am not sure whether this is just a native ZSH thing or one of my terminal plugins, such as <a href="https://fig.io">Fig</a>. Your mileage may vary.</p></blockquote>
<h2 id="dbcc4e95-edfa-4f98-a2e0-c4691f4fd050" class="">Handling hidden files and creating a pull request</h2>
<p id="a1b6a944-709f-4cdd-9546-67955f162b36" class="">While it is nice to be able to move all of the hidden files and folders like this, it causes a problem. Because the <code>.git</code> folder is transferred into our new subfolder, our root directory is no longer seen as a Git repository. This is a problem.</p>
<p id="66d67f7d-7670-4dee-8c37-4e11ba92d101" class="">Therefore, I will not run the above command with <code>(D)</code> but instead move the hidden files as a separate step. I will run the following command instead:</p>
<pre id="b9ce4da7-922b-47d7-9168-e739593dffbf" class="code code-wrap"><code>mv ^(sw-test|service-worker) service-worker/sw-test</code></pre>
<p id="9d818f74-bd19-4882-885d-53af4feee5e3" class="">At this stage, if you run <code>ls</code> it will look like it moved everything. That is not the case because the <code>ls</code> command does not list hidden files. To do that, you need to pass the <code>-A</code> flag as shown below:</p>
<pre id="f9cda63e-4d58-4542-97d3-69cf9b6e5127" class="code code-wrap"><code>ls -A</code></pre>
<p id="dd471bba-293d-438a-b07c-b1916124b7c0" class="">You should now see something like the following:</p>
<pre id="32ea4022-1ff1-42e8-b8c2-e63bf5ac0bb4" class="code code-wrap"><code>❯ ls -A
.git           .prettierrc    service-worker</code></pre>
<p id="9be6f1ec-a57e-4f51-ba85-2f74c3e1ee42" class="">Looking at the above output, I realized that I should not need to move the <code>.git</code> folder. All I needed to do now was to run the following command:</p>
<pre id="a38b89f7-92db-4740-adf2-74ebce461563" class="code code-wrap"><code>mv .prettierrc service-worker</code></pre>
<p id="b42e5f4c-a1f6-4624-ad6d-52d278e87744" class="">After running the above command, <code>ls -A</code> will now output the following:</p>
<pre id="3bb674de-0499-475b-bb18-7df68d7f3b71" class="code code-wrap"><code>❯ ls -A
.git simple-service-worker</code></pre>
<p id="9fba2646-32cb-42e8-aabb-de142e805b8b" class="">Time to do a little celebration dance <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f601.png" alt="😁" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>
<p id="14cac7ce-9f81-4dd8-9e9e-29296d7ee417" class="">We can move on now that we have successfully moved everything into our new subdirectory. However, while doing this, I realized I forgot to create a <a href="https://www.atlassian.com/git/tutorials/comparing-workflows/feature-branch-workflow">feature branch</a> for the work.</p>
<p id="f1e40721-fc71-4779-97c0-4174dbe482a3" class="">Not a problem. I just run the command, <code>git switch -C prepare-repo-for-move</code>. Running <code>git status</code> at this point should output something like this:</p>
<pre id="ad0afc74-4282-4896-8183-25d8300e83e7" class="code code-wrap"><code>❯ git status
On branch prepare-repo-for-move
Changes not staged for commit:
  (use "git add/rm &lt;file&gt;..." to update what will be committed)
  (use "git restore &lt;file&gt;..." to discard changes in working directory)
	deleted:    .prettierrc
	deleted:    CODE_OF_CONDUCT.md
	deleted:    LICENSE
	deleted:    README.md
	deleted:    app.js
	deleted:    gallery/bountyHunters.jpg
	deleted:    gallery/myLittleVader.jpg
	deleted:    gallery/snowTroopers.jpg
	deleted:    image-list.js
	deleted:    index.html
	deleted:    star-wars-logo.jpg
	deleted:    style.css
	deleted:    sw.js

Untracked files:
  (use "git add &lt;file&gt;..." to include in what will be committed)
	service-worker/

no changes added to commit (use "git add" and/or "git commit -a")</code></pre>
<p id="b35b6c18-e9b2-4e65-a663-4ee3895be9d0" class="">Great! Let’s add our changes and commit them.</p>
<pre id="d6e285f1-583e-447f-a95b-ee6150ac4691" class="code code-wrap"><code>git add .
git commit -m 'Moved all source files into new subdirectory'</code></pre>
<p id="ead5ed94-2f52-4105-aa5b-5f36fadfe08d" class="">Now we want to push our changes and open a pull request.</p>
<p id="4ef887cd-948a-4e72-9bce-0e3292a69dd5" class="">Woop! Let’s push:</p>
<pre id="37a94326-07d9-4515-b884-f0560f631e8b" class="code code-wrap"><code>git push origin prepare-repo-for-move</code></pre>
<p id="7e32e78e-6d17-4e60-93bd-4427dc1fb0b7" class="">Head over to your repository on GitHub. You should see a banner like &#8220;mv-files-into-subdir had recent pushes less than a minute ago&#8221; and a &#8220;Compare &amp; pull request&#8221; button.</p>
<p id="b1d8b977-db39-4109-aa07-b88251e3d057" class="">Click the button and follow the steps to open the <a href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests">pull request.</a> Once the pull request is green and ready to merge, go ahead and merge!</p>
<blockquote id="439ef4b9-d678-434a-b175-290439245561" class=""><p>NOTE: Depending on your workflow, this is the point to ask a team member to review your proposed changes before merging. It is also a good idea to have a look over the changes in the “Files changed” tab to ensure nothing is part of the pull request you did not intend. If any <a href="https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/addressing-merge-conflicts/about-merge-conflicts">conflicts prevent</a> your pull request from being merged, GitHub will warn you about these, and you will need to resolve them. This can be done directly on <a href="http://GitHub.com">GitHub.com</a> or locally and pushed to GitHub as a separate commit.</p></blockquote>
<p id="953dd30b-9f60-40ae-9681-7c83f2963c42" class="">When you head back to the code view on GitHub, you should see our new subdirectory and the <code>.gitignore</code> file.</p>
<p id="0e8cd16a-eb3e-4afe-8f11-335d68455a4e" class="">With that, our repository is ready to move.</p>
<h2 id="0272b87e-05fc-4ddb-96fa-7867df545657" class="">Merging our repositories</h2>
<p id="ea33e259-5fa2-4e61-b580-09858e6b63bb" class="">Back in the terminal, you want to switch back to the <code>main</code> branch:</p>
<pre id="c5d3d234-78fb-4f74-82d2-c3a53cb29048" class="code code-wrap"><code>git switch main</code></pre>
<p id="428a5ebe-af68-4742-b550-09097ba5439a" class="">You can now safely delete the feature branch and pull down the changes from your remote.</p>
<pre id="215eafce-b40e-4af5-95e7-96d0af713c62" class="code code-wrap"><code>git branch -D prepare-repo-for-move
git pull origin main</code></pre>
<p id="c09e504f-957f-4593-9adf-5949e9e1332f" class="">Running <code>ls -A</code> after pulling the latest should now show the following:</p>
<pre id="250aa99c-27dd-44e6-a4ac-7658ac509392" class="code code-wrap"><code>❯ ls -A
.git           README.md      service-worker</code></pre>
<p id="9d98535c-e53c-4044-87e9-53b7258c3455" class="">Also, running <code>git log</code> in the root outputs the following:</p>
<pre id="190f4579-d331-471e-b2e8-e7f6312505b8" class="code code-wrap"><code>commit 8fdfe7379130b8d6ea13ea8bf14a0bb45ad725d0 (HEAD -&gt; gh-pages, origin/gh-pages, origin/HEAD)
Author: Schalk Neethling
Date:   Thu Aug 11 22:56:48 2022 +0200

    Create README.md

commit 254a95749c4cc3d7d2c7ec8a5902bea225870176
Merge: f5c319b bc2cdd9
Author: Schalk Neethling
Date:   Thu Aug 11 22:55:26 2022 +0200

    Merge pull request #45 from mdn/prepare-repo-for-move

    chore: prepare repo for move to dom-examples

commit bc2cdd939f568380ce03d56f50f16f2dc98d750c (origin/prepare-repo-for-move)
Author: Schalk Neethling
Date:   Thu Aug 11 22:53:13 2022 +0200

    chore: prepare repo for move to dom-examples

    Prepping the repository for the move to dom-examples

commit f5c319be3b8d4f14a1505173910877ca3bb429e5
Merge: d587747 2ed0eff
Author: Ruth John
Date:   Fri Mar 18 12:24:09 2022 +0000

    Merge pull request #43 from SimonSiefke/add-navigation-preload</code></pre>
<p id="03b94e9c-4911-4a67-93b9-b3321f1700bd" class="">Here are the commands left over from where we diverted earlier on.</p>
<pre id="c57542e8-26e1-431e-9450-faac351999a6" class="code code-wrap"><code># Add a remote for and fetch the old repo
git remote add -f old_a &lt;OldA repo URL&gt;

# Merge the files from old_a/master into new/master
git merge old_a/master</code></pre>
<p id="7d7c8889-3a6e-4073-906e-f296cc0a2b81" class="">Alrighty, let’s wrap this up. First, we need to move into the root of the project to which we want to move our project. For our purpose here, this is the <code>dom-examples</code> directory. Once in the root of the directory, run the following:</p>
<pre id="4900ee3a-9d06-49cb-8ca5-9a668872c29f" class="code code-wrap"><code>git remote add -f swtest https://github.com/mdn/sw-test.git</code></pre>
<blockquote id="1b47263d-fa34-4aa7-83c9-fc83cdd1d4bc" class=""><p>NOTE: The <code>-f</code> tells Git to fetch the remote branches. The <code>ssw</code> is a name you give to the remote so this could really be anything.</p></blockquote>
<p id="0da0b3a3-b3b7-408c-9120-d70c934ef56d" class="">After running the command, I got the following output:</p>
<pre id="079a6efa-e7f6-4974-b416-5ad2d7fe66fb" class="code code-wrap"><code>❯ git remote add -f swtest https://github.com/mdn/sw-test.git
Updating swtest
remote: Enumerating objects: 500, done.
remote: Counting objects: 100% (75/75), done.
remote: Compressing objects: 100% (57/57), done.
remote: Total 500 (delta 35), reused 45 (delta 15), pack-reused 425
Receiving objects: 100% (500/500), 759.76 KiB | 981.00 KiB/s, done.
Resolving deltas: 100% (269/269), done.
From &lt;https://github.com/mdn/sw-test&gt;
 * [new branch]      gh-pages        -&gt; swtest/gh-pages
 * [new branch]      master          -&gt; swtest/master
 * [new branch]      move-prettierrc -&gt; swtest/move-prettierrc
 * [new branch]      rename-sw-test  -&gt; swtest/rename-sw-test</code></pre>
<blockquote id="ca50d8bf-fcab-425e-9d83-0e7af45421bf" class=""><p>NOTE: While we deleted the branch locally, this is not automatically synced with the remote, so this is why you will still see a reference to the <code>rename-sw-test</code> branch. If you wanted to delete it on the remote, you would run the following from the root of that repository: <code>git push origin :rename-sw-test</code> (if you have configured your repository “to <a href="https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/configuring-pull-request-merges/managing-the-automatic-deletion-of-branches">automatically delete head branches</a>”, this will be automatically deleted for you)</p></blockquote>
<p id="f0d0e732-07b2-45e2-a7c3-9a7b6b5811c4" class="">Only a few commands left.</p>
<blockquote id="9dacbac3-ae67-4cc6-844e-f8840e0867c4" class=""><p>NOTE: Do not yet run any of the commands below at this stage.</p></blockquote>
<pre id="fcfe72fd-c24f-466b-8e79-5ff30f2dded0" class="code code-wrap"><code>git merge swtest/gh-pages</code></pre>
<p id="bdb293de-5158-49d7-8dc0-30f76ebf097e" class="">Whoops! When I ran the above, I got the following error:</p>
<pre id="6fd19b11-462d-4779-8be0-c7b66f6f5573" class="code code-wrap"><code>❯ git merge swtest/gh-pages
fatal: refusing to merge unrelated histories</code></pre>
<p id="9180f354-b747-490e-b9c4-7e6c23217e35" class="">But this is pretty much exactly what I <em>do</em> want, right? This is the default behavior of the <code>merge</code> command, but you can pass a flag and allow this behavior.</p>
<pre id="87f01818-0d90-47a6-8ee9-4cc93c0cd734" class="code code-wrap"><code>git merge swtest/gh-pages --allow-unrelated-histories</code></pre>
<blockquote id="44a8b877-25ab-4d27-a360-09e8c8952768" class=""><p>NOTE: Why <code>gh-pages</code>? More often than not, the one you will merge here will be <code>main</code> but for this particular repository, the default branch was named <code>gh-pages</code>. It used to be that when using GitHub pages, you would need a branch called <code>gh-pages</code> that will then be automatically deployed by GitHub to a URL that would be something like mdn.github.io/sw-test.</p></blockquote>
<p id="d913f747-247b-4564-b7a8-ade2cabb8bd3" class="">After running the above, I got the following:</p>
<pre id="761fe400-631f-4679-80db-237f1ef436b3" class="code code-wrap"><code>❯ git merge swtest/gh-pages --allow-unrelated-histories
Auto-merging README.md
CONFLICT (add/add): Merge conflict in README.md
Automatic merge failed; fix conflicts and then commit the result.</code></pre>
<p id="5cef1260-ecb3-435b-8845-bf38596b48cd" class="">Ah yes, of course. Our current project and the one we are merging both contain a <code>README.md</code>, so Git is asking us to decide what to do. If you open up the <code>README.md</code> file in your editor, you will notice something like this:</p>
<pre id="505e70db-844a-454d-8c84-0d42b8cb7fd8" class="code code-wrap"><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD

=======</code></pre>
<p id="aeb83b54-c7f0-48b0-9df8-69414f069813" class="">There might be a number of these in the file. You will also see some entries like this, <code>&gt;&gt;&gt;&gt;&gt;&gt;&gt; swtest/gh-pages</code>. This highlights the conflicts that Git is not sure how to resolve. You could go through and clear these manually. In this instance, I just want what is in the <code>README.md</code> at the root of the <code>dom-examples</code> repo, so I will clean up the conflicts or copy the content from the <code>README.md</code> from GitHub.</p>
<p id="5081c830-af14-4b40-ac3e-f7b001481612" class="">As Git requested, we will add and commit our changes.</p>
<pre id="c83d71e8-8786-489f-88b9-5e545eee6e25" class="code code-wrap"><code>git add .
git commit -m 'merging sw-test into dom-examples'</code></pre>
<p id="df4823f9-6395-403b-866d-68d6da094c4b" class="">The above resulted in the following output:</p>
<pre id="4224e518-674f-49d2-b251-5f3c6f6620fa" class="code code-wrap"><code>❯ git commit
[146-chore-move-sw-test-into-dom-examples 4300221] Merge remote-tracking branch 'swtest/gh-pages' into 146-chore-move-sw-test-into-dom-examples</code></pre>
<p id="9d63283d-ef3f-4525-af03-3186f16e26da" class="">If I now run <code>git log</code> in the root of the directory, I see the following:</p>
<pre id="81163412-53a4-4303-a29d-6e7db20dcafe" class="code code-wrap"><code>commit 4300221fe76d324966826b528f4a901c5f17ae20 (HEAD -&gt; 146-chore-move-sw-test-into-dom-examples)
Merge: cdfd2ae 70c0e1e
Author: Schalk Neethling
Date:   Sat Aug 13 14:02:48 2022 +0200

    Merge remote-tracking branch 'swtest/gh-pages' into 146-chore-move-sw-test-into-dom-examples

commit 70c0e1e53ddb7d7a26e746c4a3412ccef5a683d3 (swtest/gh-pages)
Merge: 4b7cfb2 d4a042d
Author: Schalk Neethling
Date:   Sat Aug 13 13:30:58 2022 +0200

    Merge pull request #47 from mdn/move-prettierrc

    chore: move prettierrc

commit d4a042df51ab65e60498e949ffb2092ac9bccffc (swtest/move-prettierrc)
Author: Schalk Neethling
Date:   Sat Aug 13 13:29:56 2022 +0200

    chore: move prettierrc

    Move `.prettierrc` into the siple-service-worker folder

commit 4b7cfb239a148095b770602d8f6d00c9f8b8cc15
Merge: 8fdfe73 c86d1a1
Author: Schalk Neethling
Date:   Sat Aug 13 13:22:31 2022 +0200

    Merge pull request #46 from mdn/rename-sw-test</code></pre>
<p id="a95c9e4d-6612-4383-b984-5da1143d59e4" class="">Yahoooo! That is the history from <code>sw-test</code> now in our current repository! Running <code>ls -A</code> now shows me:</p>
<pre id="6680971c-ffff-44a2-8e18-ce46cb80739d" class="code code-wrap"><code>❯ ls -A
.git                           indexeddb-examples             screen-wake-lock-api
.gitignore                     insert-adjacent                screenleft-screentop
CODE_OF_CONDUCT.md             matchmedia                     scrolltooptions
LICENSE                        media                          server-sent-events
README.md                      media-session                  service-worker
abort-api                      mediaquerylist                 streams
auxclick                       payment-request                touchevents
canvas                         performance-apis               web-animations-api
channel-messaging-basic        picture-in-picture             web-crypto
channel-messaging-multimessage pointer-lock                   web-share
drag-and-drop                  pointerevents                  web-speech-api
fullscreen-api                 reporting-api                  web-storage
htmldialogelement-basic        resize-event                   web-workers
indexeddb-api                  resize-observer                webgl-examples</code></pre>
<p id="ac2fb082-6040-4c3c-a9e5-5d544ebba5a8" class="">And if I run <code>ls -A service-worker/</code>, I get:</p>
<pre id="60c0f598-0679-483c-b138-36babc6c4a9d" class="code code-wrap"><code>❯ ls -A service-worker/
simple-service-worker</code></pre>
<p id="46810345-8809-4774-b558-b4677d5e6e0b" class="">And finally, running <code>ls -A service-worker/simple-service-worker/</code> shows:</p>
<pre id="fb69535a-43e8-4176-87cb-a12d2561c080" class="code code-wrap"><code>❯ ls -A service-worker/simple-service-worker/
.prettierrc        README.md          image-list.js      style.css
CODE_OF_CONDUCT.md app.js             index.html         sw.js
LICENSE            gallery            star-wars-logo.jpg</code></pre>
<p id="1cdea38c-6f57-4364-9d03-ba7146a2b48b" class="">All that is left is to push to remote.</p>
<pre id="bd945452-2b0c-4af0-9d69-3b74491494d3" class="code code-wrap"><code>git push origin 146-chore-mo…dom-examples</code></pre>
<blockquote id="f50dcff8-a627-422d-bf31-8d1659c66554" class=""><p><strong>NOTE:</strong> Do not squash merge this pull request, or else all commits will be squashed together as a single commit. Instead, you want to use a merge commit. You can read all the <a href="https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/configuring-pull-request-merges/about-merge-methods-on-github">details about merge methods</a> in their documentation on GitHub.</p></blockquote>
<p id="a9dabbb9-49e9-42b2-a201-71306b754045" class="">After you merge the pull request, go ahead and browse the commit history of the repo. You will find that the commit history is intact and merged. o/\o You can now go ahead and either delete or archive the old repository.</p>
<p id="2f66dffe-0f3b-45ff-a4ec-ba122d820ce7" class="">At this point having the remote configured for our target repo serve no purpose so, we can safe remove the remote.</p>
<pre id="3c72a98b-2607-49db-bc47-3106158623f0" class="code"><code>git remote rm swtest</code></pre>
<h3 id="c7bd35e7-333b-4e4e-bdff-7f145a5c2637" class="">In Conclusion</h3>
<p id="2bb6b3e5-af58-4b03-ab09-de0190276c51" class="">The steps to accomplish this task is then as follows:</p>
<pre id="5de6937b-ebac-438a-9dea-7a6b7f19b47e" class="code"><code># Clone the repository you want to merge
git clone https://github.com/mdn/sw-test.git
cd sw-test

# Create your feature branch
git switch -C prepare-repo-for-move
# NOTE: With older versions of Git you can run:
# git checkout -b prepare-repo-for-move

# Create directories as needed. You may only need one, not two as
# in the example below.
mkdir service-worker
mkdir service-worker/sw-test

# Enable extendedglob so we can use negation
# The command below is for modern versions of ZSH. See earlier
# in the post for examples for bash and older versions of ZSH
set -o extendedglob

# Move everything except hidden files into your subdirectory,
# also, exclude your target directories
mv ^(sw-test|service-worker) service-worker/sw-test

# Move any of the hidden files or folders you _do_ want
# to move into the subdirectory
mv .prettierrc service-worker

# Add and commit your changes
git add .
git commit -m 'Moved all source files into new subdirectory'

# Push your changes to GitHub
git push origin prepare-repo-for-move

# Head over to the repository on GitHub, open and merge your pull request
# Back in the terminal, switch to your `main` branch
git switch main

# Delete your feature branch
# This is not technically required, but I like to clean up after myself :)
git branch -D prepare-repo-for-move
# Pull the changes you just merged
git pull origin main

# Change to the root directory of your target repository
# If you have not yet cloned your target repository, change
# out of your current directory
cd ..

# Clone your target repository
git clone https://github.com/mdn/dom-examples.git
# Change directory
cd dom-examples

# Create a feature branch for the work
git switch -C 146-chore-move-sw-test-into-dom-examples

# Add your merge target as a remote
git remote add -f ssw https://github.com/mdn/sw-test.git

# Merge the merge target and allow unrelated history
git merge swtest/gh-pages --allow-unrelated-histories

# Add and commit your changes
git add .
git commit -m 'merging sw-test into dom-examples'

# Push your changes to GitHub
git push origin 146-chore-move-sw-test-into-dom-examples

# Open the pull request, have it reviewed by a team member, and merge.
# Do not squash merge this pull request, or else all commits will be
# squashed together as a single commit. Instead, you want to use a merge commit.

# Remove the remote for the merge target
git remote rm swtest</code></pre>
<p id="ed6f1158-24b8-4ebc-963b-d50dfea02ff0" class="">Hopefully, you now know how to exclude subdirectories using the mv command, set and view shell configuration, and merge the file contents of a git repo into a new repository while preserving the entire commit history using only basic git commands.</p>
</div>
</article>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/08/merging-two-github-repositories-without-losing-commit-history/">Merging two GitHub repositories without losing commit history</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://hacks.mozilla.org/2022/08/merging-two-github-repositories-without-losing-commit-history/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>Neural Machine Translation Engine for Firefox Translations add-on</title>
		<link>https://hacks.mozilla.org/2022/06/neural-machine-translation-engine-for-firefox-translations-add-on/</link>
		
		<dc:creator><![CDATA[Abhishek Aggarwal]]></dc:creator>
		<pubDate>Wed, 29 Jun 2022 14:50:41 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[Machine Translation]]></category>
		<category><![CDATA[browsers]]></category>
		<category><![CDATA[data]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[Translations]]></category>
		<category><![CDATA[WebAssembly]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47890</guid>

					<description><![CDATA[<p>Firefox Translations is a website translation add-on that provides an automated translation of web content. In this article, we will discuss the technical challenges around the development of the translation engine and how we solved them to build a usable Firefox Translations add-on.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/neural-machine-translation-engine-for-firefox-translations-add-on/">Neural Machine Translation Engine for Firefox Translations add-on</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><a href="https://addons.mozilla.org/en-US/firefox/addon/firefox-translations/">Firefox Translations</a> is a website translation add-on that provides an automated translation of web content. Unlike cloud-based alternatives, translation is done locally on the client-side in the user’s computer so that the text being translated does not leave your machine, making it entirely private. The add-on is available for installation on Firefox Nightly, Beta and in General Release.</p>
<p>The add-on utilizes proceedings of project <a href="https://browser.mt/">Bergamot</a> which is a collaboration between Mozilla, the University of Edinburgh, Charles University in Prague, the University of Sheffield, and the University of Tartu with funding from the <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f1ea-1f1fa.png" alt="🇪🇺" class="wp-smiley" style="height: 1em; max-height: 1em;" /> European Union’s Horizon 2020 research and innovation programme.</p>
<p>The add-on is powered internally by <a href="https://github.com/mozilla/bergamot-translator">Bergamot Translator</a>, a Neural Machine Translation engine that performs the actual task of translation. This engine can also be utilized in different contexts, <a href="https://mozilla.github.io/translate/">like in this demo website</a>, which lets the user perform free-form translations without using the cloud.</p>
<p>In this article, we will discuss the technical challenges around the development of the translation engine and how we solved them to build a usable Firefox Translations add-on.</p>
<h2>Challenges</h2>
<p>The translation engine is built on top of <a href="https://marian-nmt.github.io/">marian framework</a>, which is a free Neural Machine Translation framework written in pure C++. The framework has a standalone native application that can provide simple translation functionality. However, two novel features needed to be introduced to the add-on that was not present in the existing native application.</p>
<p>The first was translation of forms, allowing users to input text in their own language and dynamically translate it on-the-fly into the page’s language. The second was estimating the quality of the translations so that low-confidence translations could be automatically highlighted in the page, in order to notify the user of potential errors. This led to the development of the translation engine which is a <a href="https://github.com/mozilla/bergamot-translator">high level C++ API layer on top of marian</a>.</p>
<p>The resulting translation engine is compiled directly to native code. There were three <a href="https://github.com/browsermt/marian-dev/issues/5">potential architectural solutions</a> to integrating it into the add-on:</p>
<ol>
<li>Native integration to Firefox: Bundling the entire translation engine native code into Firefox.</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/Native_messaging">Native messaging</a>: Deploying the translation engine as a native application on the user&#8217;s computer and allowing the add-on to exchange messages with it.</li>
<li><a href="https://webassembly.org/">Wasm</a>: Porting the translation engine to Wasm and integrating it to the add-on using the developed JS bindings.</li>
</ol>
<p>We evaluated these solutions on the following factors which we believed were crucial to develop a production ready translation add-on:</p>
<ol>
<li>Security: The approach of native integration inside the Firefox Web Browser was discarded following Mozilla’s internal security review of the engine code base, which highlighted issues over the number of third-party dependencies of the marian framework.</li>
<li>Scalability and Maintainability: Native messaging would have posed challenges around distributing the code for the project because of the overhead of providing builds compatible with all platforms supported by Firefox. This would have been impractical to scale and maintain.</li>
<li>Platform Support: The underlying marian framework of the translation engine supports translation only on x86/x86_64 architecture based processors. Given the increasing availability of ARM based consumer devices, the native messaging approach would have restricted the reach of the private and local translation technology to a wider audience.</li>
<li>Performance: Wasm runs slower compared to the native code. However, it has potential to execute at near native speed by taking advantage of common hardware capabilities available on a wide range of platforms.</li>
</ol>
<p>Wasm design as a portable compilation target for programming languages means developing and distributing a single binary running on all platforms. Additionally, Wasm is memory-safe and runs in a sandboxed execution environment, making it secure when parsing and processing Web content. All these advantages coupled with its potential to execute at near native speed gave us motivation to prototype this architectural solution and evaluate whether it meets the performance requirement of the translation add-on.</p>
<h2>Prototyping: Porting to Wasm</h2>
<p>We chose the Emscripten toolchain for compiling the translation engine to Wasm. The engine didn’t compile to Wasm out of the box and we made <a href="https://github.com/browsermt/marian-dev/pull/24">few changes</a> to successfully compile and perform translation using the generated Wasm binary, some of which are as follows:</p>
<ul>
<li>Disabled training specific native code of the marian framework as only translation specific code was required for the translation engine to work.</li>
<li>Disabled multithreading code as any pthread compiled code to Wasm requires SharedArrayBuffer support in the browsers, which at the time of the development was going through the transition from <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer#security_requirements">disabled to being re-enabled</a>.</li>
<li>The engine depends on trained model(s), vocabulary along with an optional shortlist file to be able to perform the translation and expects its user to provide them from outside. As <a href="https://emscripten.org/docs/porting/files/file_systems_overview.html#emscripten-file-system-runtime-environment">native code and normal JavaScript use different file-access paradigms</a>, we <a href="https://emscripten.org/docs/porting/files/packaging_files.html">packaged all the required files</a> in Emscripten’s virtual file system for faster prototyping.</li>
<li>Replaced the <a href="https://github.com/browsermt/marian-dev/pull/24/commits/6b95d313ce6cf7c54dbc2ad711151b0fcab52ea3">proprietary library (Intel MKL) with an open source one (onnxjs)</a> for performing SGEMM operation in the attention layer of marian framework.</li>
<li>Fixed the issue related to the <a href="https://github.com/browsermt/marian-dev/pull/24/commits/310cba7d2f92204a67c6929a032bd4a6f2830a98">rogue usage of native data type size_t</a> in the marian framework, which was causing failures during translation.</li>
</ul>
<h2>Prototyping to integration</h2>
<h3>Problems</h3>
<p>After having a working translation Wasm binary, we identified a few key problems that needed to be solved to convert the prototype to a usable product.</p>
<h4>Scalability</h4>
<p>Packaging of all the files for each supported language pair in the Wasm binary meant it was impractical to scale for new language pairs. All the files of each language pair (translating from one language to another and vice versa) in compressed form amount to ~40MB of disk space. As an example, supporting translation of 6 language pairs made the size of the binary ~250 MB.</p>
<h4>Demand-based language support</h4>
<p>The packaging of files for each supported language pair in the Wasm binary meant that the users will be forced to download all supported language pairs even if they intended to use only a few of them. This is highly inefficient compared to downloading files for language pairs based on the user&#8217;s demand.</p>
<h4>Performance</h4>
<p>We benchmarked the translation engine on three main metrics which we believed were critical from a usability perspective.</p>
<ol>
<li aria-level="1">Startup time: The time it takes for the engine to be ready for translation. The engine loads models, vocabularies, and optionally a shortlist file contents during this step.</li>
<li aria-level="1">Translation speed: The time taken by the engine to translate a given text after its successful startup, measured in the number of words translated per second aka wps.</li>
<li aria-level="1">Wasm binary size: The disk space of the generated Wasm binary.</li>
</ol>
<p>The size of the generated Wasm binary, owing to the packaging, became dependent on the number of language pairs supported. The translation engine took an unusually long time (~8 seconds) to startup and was extremely slow in performing translation making it unusable.</p>
<p>As an example, translation from English to German language using <a href="https://github.com/mozilla/firefox-translations-models/tree/main/models/prod/ende">corresponding trained models</a> gave only 95 wps on a MacBook Pro (15-inch, 2017), MacOS version 11.6.2, 3.1 GHz Quad-Core Intel Core i7 processor, 16 GB 2133 MHz RAM.</p>
<h3>Solution</h3>
<h4>Scalability, demand-based language support and binary size</h4>
<p>As packaging of the files affected the usability of the translation engine on multiple fronts, we decided to solve that problem first. We introduced a new API in the translation engine to <a href="https://github.com/browsermt/bergamot-translator/issues/28">pass required files as byte buffers</a> from outside instead of packing them during compile time in Emscripten’s virtual file system.</p>
<p>This allowed the translation engine to scale for new languages without increasing the size of the Wasm binary and enabled the add-on to dynamically download files of only those language pairs that the users were interested in. The final size of the Wasm binary (~6.5 MB) was well within the limits of the corresponding metric.</p>
<h4>Startup time optimization</h4>
<p>The new API that we developed to solve the packaging problem, coupled with <a href="https://github.com/browsermt/marian-dev/issues/19">few other optimizations</a> in the marian framework, solved the long startup time problem. Engine’s startup time reduced substantially (~1 second) which was well within the acceptable limits of this performance criteria.</p>
<h4>Translation speed optimization</h4>
<p>Profiling the translation step in the browser indicated that the General matrix multiply (GEMM) instruction for 8-bit integer operands was the most computational intensive operation, and the <a href="https://emscripten.org/docs/porting/exceptions.html#javascript-based-exception-support">exception handling code</a> had a high overhead on translation speed. We focused our efforts to optimize both of them.</p>
<ol>
<li aria-level="1">Optimizing exception handling code: We replaced <a href="https://github.com/browsermt/marian-dev/pull/24/commits/f00909e7e3abc99cd00bf837b0af8fea23a0ebb3">try/catch with if/else based implementation</a> in a function that was frequently called during the translation step which resulted in ~20% boost in translation speed.</li>
<li aria-level="1">Optimizing GEMM operation: Deeper investigation on profiling results revealed that the <a href="https://github.com/WebAssembly/relaxed-simd/issues/9">absence of GEMM instruction in Wasm standard</a> was the reason for it to perform so poorly on Wasm.
<ol>
<li aria-level="1"><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1672160">Experimental GEMM instructions</a>: Purely for performance evaluation of GEMM instruction without getting it standardized in Wasm, we landed two experimental instructions in Firefox Nightly and Release for x86/x86_64 architecture. These instructions improved the <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1746631#c1">translation speed by ~310%</a> and the translation of webpages seemed fast enough for the feature to be usable on these architectures. This feature was protected behind a flag and was exposed only to privileged extensions in Firefox Release owing to its experimental nature. We still wanted to figure out a standard based solution before this could be released as production software but it allowed us to continue developing the extension while we worked with the Firefox WASM team on a better long-term solution.</li>
<li aria-level="1"><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1762413">Non-standard long term solution</a>: In the absence of a concrete timeline regarding the implementation of GEMM instruction in the Wasm standard, we replaced the experimental GEMM instructions with a Firefox specific non-standard long term solution which provided the <a href="https://github.com/mozilla/firefox-translations/pull/353#issue-1258348941">same or more translation speeds</a> as provided by the experimental GEMM instructions. Apart from privileged extensions, this solution enabled translation functionallity for non-privileged extensions as well as regular content with same translation speeds and enabled translation on ARM64 based platforms, albeit with low speeds. None of this was possible with experimental GEMM instructions.</li>
<li aria-level="1"><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1746631">Native GEMM intrinsics</a>: In an effort to improve translation speeds further, we landed a native GEMM implementation in Firefox Nightly protected behind a flag and exposed as intrinsics. The translation engine would directly call these intrinsics during the translation step whenever it is running in Firefox Nightly on x86/x86_64 architecture based systems. This work increased the translation speeds by <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1746631#c1">25% and 43%</a> for SSSE3 and AVX2 simd extensions respectively compared to the experimental instructions that we had landed earlier.</li>
</ol>
</li>
<li aria-level="1"><a href="https://github.com/browsermt/bergamot-translator/pull/414">Emscripten toolchain upgrade</a>: The most recent effort of updating the Emscripten toolchain to the latest version increased the translation speeds for all platforms by ~15% on Firefox and reduced the size of the Wasm binary further by ~25% (final size ~4.94 MB).</li>
</ol>
<p>Eventually, we achieved the <a href="https://github.com/mozilla/firefox-translations/pull/353#issue-1258348941">translation speeds of ~870 wps</a> for translation from English to German language using <a href="https://github.com/mozilla/firefox-translations-models/tree/main/models/prod/ende">corresponding trained models</a> on Firefox Release on a MacBook Pro (15-inch, 2017), MacOS version 11.6.2, 3.1 GHz Quad-Core Intel Core i7 processor, 16 GB 2133 MHz RAM.</p>
<h2>Future</h2>
<p>The translation engine is optimized to run at high translation speeds only for x86/x86_64 processors and we have ideas for improving the situation on ARM. A standardized Wasm GEMM instruction can achieve similar speeds on ARM, providing benefits to emerging class of consumer laptops and mobile devices. We also know that the native Marian engine performs even better with multithreading, but we had to disable multithreaded code in this version of the translation engine. Once SharedArrayBuffer support is broadly enabled, we believe we could re-enable multithreading and even faster translation speeds are possible.</p>
<h2>Acknowledgement</h2>
<p>I would like to thank Bergamot consortium partners, Mozilla’s Wasm team and my teammates Andre Natal, Evgeny Pavlov for their contributions in developing a mature translation engine. I am thankful to Lonnen along with Mozilla’s Add-on team, Localization team, Q&amp;A team and Mozilla community who supported us and contributed to the development of the Firefox Translations add-on.</p>
<p>This project has received funding from the <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f1ea-1f1fa.png" alt="🇪🇺" class="wp-smiley" style="height: 1em; max-height: 1em;" />European Union’s Horizon 2020 research and innovation programme under grant agreement No 825303.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/neural-machine-translation-engine-for-firefox-translations-add-on/">Neural Machine Translation Engine for Firefox Translations add-on</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>The JavaScript Specification has a New License</title>
		<link>https://hacks.mozilla.org/2022/06/the-specification-for-javascript-has-a-new-license/</link>
		
		<dc:creator><![CDATA[Yulia Startsev]]></dc:creator>
		<pubDate>Mon, 27 Jun 2022 15:05:35 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[JavaScript]]></category>
		<category><![CDATA[Mozilla]]></category>
		<category><![CDATA[ecma tc39]]></category>
		<category><![CDATA[open source]]></category>
		<category><![CDATA[Standards]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47870</guid>

					<description><![CDATA[<p>As part of our work to ensure a free and open web, we've been working together with Ecma International, and many partners to write a License inspired by the W3C Document and Software License. Our goal was that JavaScript’s status would align with other specifications of the Web. In addition, with this new license available to all TCs at Ecma International, this will provide other organizations to approach standardization with the same perspective.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/the-specification-for-javascript-has-a-new-license/">The JavaScript Specification has a New License</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><span class="css-901oao css-16my406 r-poiln3 r-bcqeeo r-qvutc0">Ecma International recently approved the 2022 standard of ECMAScript. There is something new in this edition that hasn&#8217;t been part of prior editions, but this isn&#8217;t a new programming feature.</span></p>
<p>In March of this year, Ecma International accepted a proposal led by Mozilla for a new alternative license. On June 22nd, the first requests to adopt this license were granted to TC39 and applied to the following documents: ECMA-262 (ECMAScript, the official name for JavaScript) and ECMA-402 (the Internationalization API for ECMAScript).</p>
<p>The ECMAScript specification is developed at Ecma International, while other web technologies like HTML and CSS are being developed at W3C. These institutions have different default license agreements, which creates two problems. First, having different licenses increases the overhead of legal review for participants. This can create a speed bump for contributing across different specifications. Second, the default ECMA license contains some restrictions against creating derivative works, in contrast to W3C. These provisions haven’t been a problem in practice, but they nevertheless don’t reflect how we think Open Source should work, especially for something as foundational as JavaScript. Mozilla wants to make it easy for everyone to participate in evolving the Web, so we took the initiative of introducing an alternative license for Ecma International specifications.</p>
<h2><b>What is the alternative license?</b></h2>
<p>The full alternative license text may be found on the<a href="https://www.ecma-international.org/policies/by-ipr/ecma-text-copyright-policy/"> Ecma License FAQ</a>. Ecma now provides two licenses, which can be adopted depending on the needs of a given technical committee. The default Ecma International license provides a definitive document and location for work on a given standard, with the intention of preventing forking. The license has provisions that allow inlining a given standard into source text, as well as reproduction in part or full.</p>
<p>The new alternative license seeks to align with the work of the W3C, and the text is largely based on the W3C’s<a href="https://www.w3.org/Consortium/Legal/2015/copyright-software-and-document"> Document and Software License</a>. This license is more permissive regarding derivative works of a standard. This provides a legal framework and an important guarantee that the development of internet infrastructure can continue independent of any organization. By applying the alternative license to a standard as significant as ECMAScript, Ecma International has demonstrated its stewardship of a fundamental building block of the web. In addition, this presents a potential new home for standardization projects with similar licensing requirements.</p>
<h2><b>Standards and Open Source</b></h2>
<p>Standardization arises from the need of multiple implementers to align on a common design. Standardization improves collaboration across the industry, and reduces replicated solutions to the same problem. It also provides a way to gather feedback from users or potential users. Both Standards and Open Source produce technical solutions through collaboration. One notable distinction between standardization and an Open Source project is that the latter often focuses on developing solutions within a single implementation.</p>
<p>Open source has led the way with permissive licensing of projects. Over the years, different licenses such as the BSD, Creative Commons, GNU GPL &amp; co, MIT, and MPL have sought to allow open collaboration with different focuses and goals. Standardizing bodies are gradually adopting more of the techniques of Open Source. In 2015,<a href="https://www.w3.org/blog/news/archives/4743"> W3C adopted its Document and Software License</a>, and in doing so moved many of the specifications responsible for the Web such as CSS and HTML. Under this new license, W3C ensured that the ability to build on past work would exist regardless of organizational changes.</p>
<h2><b>Mozilla’s Role</b></h2>
<p>As part of our work to ensure a free and open web, we worked together with Ecma International, and many partners to write a License inspired by the W3C Document and Software License. Our goal was that JavaScript’s status would align with other specifications of the Web. In addition, with this new license available to all TCs at Ecma International, this will provide other organizations to approach standardization with the same perspective.</p>
<p>Changes like this come from the work of many different participants and we thank everyone at TC39 who helped with this effort. In addition, I’d like also thank my colleagues at Mozilla for their excellent work: Zibi Braniecki and Peter Saint-Andre, who supported me in writing the document drafts and the Ecma International discussions; Daniel Nazer, Eric Rescorla, Bobby Holley and Tantek Çelik for their advice and guidance of this project.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/the-specification-for-javascript-has-a-new-license/">The JavaScript Specification has a New License</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Fuzzing rust-minidump for Embarrassment and Crashes &#8211; Part 2</title>
		<link>https://hacks.mozilla.org/2022/06/fuzzing-rust-minidump-for-embarrassment-and-crashes/</link>
					<comments>https://hacks.mozilla.org/2022/06/fuzzing-rust-minidump-for-embarrassment-and-crashes/#comments</comments>
		
		<dc:creator><![CDATA[Aria Beingessner]]></dc:creator>
		<pubDate>Thu, 23 Jun 2022 17:19:31 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[Mozilla]]></category>
		<category><![CDATA[Rust]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[fuzzing]]></category>
		<category><![CDATA[mozilla]]></category>
		<category><![CDATA[rust]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47880</guid>

					<description><![CDATA[<p>For the last year, we've been working on the development of rust-minidump, a pure-Rust replacement for the minidump-processing half of google-breakpad. The final part in this series takes you through fuzzing rust-minidump.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/fuzzing-rust-minidump-for-embarrassment-and-crashes/">Fuzzing rust-minidump for Embarrassment and Crashes &#8211; Part 2</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><span style="font-weight: 400;">This is part 2 of a series of articles on rust-minidump. For part 1, see <a href="https://hacks.mozilla.org/2022/06/everything-is-broken-shipping-rust-minidump-at-mozilla/">here</a>.</span></p>
<p><span style="font-weight: 400;">So to recap, we rewrote breakpad&#8217;s minidump processor in Rust, wrote a ton of tests, and deployed to production without any issues. We killed it, perfect job.</span></p>
<p><span style="font-weight: 400;">And we </span><i><span style="font-weight: 400;">still</span></i><span style="font-weight: 400;"> got massively dunked on by the fuzzer. Just absolutely destroyed.</span></p>
<p><span style="font-weight: 400;">I was starting to pivot off of rust-minidump work because I needed a bit of palette cleanser before tackling round 2 (handling native debuginfo, filling in features for other groups who were interested in rust-minidump, adding extra analyses that we&#8217;d always wanted but were too much work to do in Breakpad, etc etc etc).</span></p>
<p><span style="font-weight: 400;">I was still getting some PRs from people filling in the corners they needed, but nothing that needed too much attention, a</span><span style="font-weight: 400;">nd then</span><a href="https://github.com/5225225"> <span style="font-weight: 400;">@5225225</span></a><span style="font-weight: 400;"> smashed through the windows and released a bunch of exploding fuzzy rabbits into my office. </span></p>
<p><span style="font-weight: 400;">I had no idea who they were or why they were there. When I asked they just lowered one of their seven pairs of sunglasses and said &#8220;Because I can. Now hold this bunny&#8221;. I did as I was told and held the bunny. It was a good bun. Dare I say, it was a true </span><i><span style="font-weight: 400;">bnnuy</span></i><span style="font-weight: 400;">: it was</span><a href="https://www.llvm.org/docs/LibFuzzer.html"> <span style="font-weight: 400;">libfuzzer</span></a><span style="font-weight: 400;">. (Huh? You thought it was gonna be</span><a href="https://github.com/google/AFL"> <span style="font-weight: 400;">AFL</span></a><span style="font-weight: 400;">? Weird.)</span></p>
<p><span style="font-weight: 400;">As it turns out, several folks had built out some </span><i><span style="font-weight: 400;">really nice</span></i><span style="font-weight: 400;"> infrastructure for quickly setting up a decent fuzzer for some Rust code:</span><a href="https://github.com/rust-fuzz/cargo-fuzz"> <span style="font-weight: 400;">cargo-fuzz</span></a><span style="font-weight: 400;">. They even wrote</span><a href="https://rust-fuzz.github.io/book/cargo-fuzz.html"> <span style="font-weight: 400;">a little book that walks you through the process</span></a><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">Apparently those folks had done such a good job that 5225225 had decided it would be a really great hobby to just pick up a random rust project and implement fuzzing for it. And then to fuzz it. And file issues. And PRs that fix those issues. And then implement even more fuzzing for it.</span></p>
<p><span style="font-weight: 400;">Please help my office is drowning in rabbits and I haven&#8217;t seen my wife in weeks.</span></p>
<p><span style="font-weight: 400;">As far as I can tell, the process seems to genuinely be pretty easy! I think their</span><a href="https://github.com/luser/rust-minidump/pull/405"> <span style="font-weight: 400;">first fuzzer for rust-minidump</span></a><span style="font-weight: 400;"> was basically just:</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">checked out the project</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">run cargo fuzz init (which autogenerates a bunch of config files)</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">write a file with this:</span></li>
</ul>
<pre><span style="font-weight: 400;">#![no_main]</span>

<span style="font-weight: 400;">use libfuzzer_sys::fuzz_target;</span>
<span style="font-weight: 400;">use minidump::*;</span>

<span style="font-weight: 400;">fuzz_target!(|data: &amp;[u8]| {</span>
<span style="font-weight: 400;">    // Parse a minidump like a normal user of the library</span>
<span style="font-weight: 400;">    if let Ok(dump) = minidump::Minidump::read(data) {</span>
<span style="font-weight: 400;">        // Ask the library to get+parse several streams like a normal user.</span>

<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpAssertion&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpBreakpadInfo&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpCrashpadInfo&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpException&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpLinuxCpuInfo&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpLinuxEnviron&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpLinuxLsbRelease&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpLinuxMaps&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpLinuxProcStatus&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpMacCrashInfo&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpMemoryInfoList&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpMemoryList&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpMiscInfo&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpModuleList&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpSystemInfo&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpThreadNames&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpThreadList&gt;();</span>
<span style="font-weight: 400;">        let _ = dump.get_stream::&lt;MinidumpUnloadedModuleList&gt;();</span>
<span style="font-weight: 400;">    }</span>
<span style="font-weight: 400;">});</span></pre>
<p><span style="font-weight: 400;">And that&#8217;s&#8230; it? And all you have to do is type </span><span style="font-weight: 400;">cargo fuzz run</span><span style="font-weight: 400;"> and it downloads, builds, and spins up an instance of</span><a href="https://www.llvm.org/docs/LibFuzzer.html"> <span style="font-weight: 400;">libfuzzer</span></a><span style="font-weight: 400;"> and finds bugs in your project overnight?</span></p>
<p><span style="font-weight: 400;">Surely that won&#8217;t find anything interesting. Oh it did? It was largely all bugs in code I wrote? </span><b>Nice.</b></p>
<p><span style="font-weight: 400;">cargo fuzz is clearly awesome but let&#8217;s not downplay the amount of bafflingly incredible work that 5225225 did here! Fuzzers, sanitizers, and other code analysis tools have a </span><i><span style="font-weight: 400;">very bad</span></i><span style="font-weight: 400;"> reputation for drive-by contributions. </span></p>
<p><span style="font-weight: 400;">I think we&#8217;ve all heard stories of someone running a shiny new tool on some big project they know nothing about, mass filing a bunch of issues that just say &#8220;this tool says your code has a problem, fix it&#8221; and then disappearing into the mist and claiming victory.</span></p>
<p><span style="font-weight: 400;">This is not a pleasant experience for someone trying to maintain a project. You&#8217;re dumping a lot on my plate if I don&#8217;t know the tool, have trouble running the tool, don&#8217;t know exactly how you ran it, etc. </span></p>
<p><span style="font-weight: 400;">It&#8217;s also very easy to come up with a huge pile of issues with very little sense of how significant they are. </span></p>
<p><span style="font-weight: 400;">Some things are only vaguely dubious, while others are horribly terrifying exploits. We only have so much time to work on stuff, you&#8217;ve gotta help us out!</span></p>
<p><span style="font-weight: 400;">And in this regard 5225225&#8217;s contributions were just, bloody beautiful. </span></p>
<p><span style="font-weight: 400;">Like, shockingly fantastic.</span></p>
<p><span style="font-weight: 400;">They wrote really clear and detailed issues. When I skimmed those issues and misunderstood them, they quickly clarified and got me on the same page. And then they submitted a fix for the issue before I even considered working on the fix. And quickly responded to review comments. I didn&#8217;t even bother asking them to squashing their commits because damnit they </span><i><span style="font-weight: 400;">earned</span></i><span style="font-weight: 400;"> those 3 commits in the tree to fix one overflow.</span></p>
<p><span style="font-weight: 400;">Then they submitted a PR to merge the fuzzer. They helped me understand how to use it and debug issues. Then they started asking questions about the project and started writing more fuzzers for other parts of it. And now there&#8217;s like 5 fuzzers and a bunch of fixed issues!</span></p>
<p><span style="font-weight: 400;">I don&#8217;t care how good cargo fuzz is, that&#8217;s a lot of friggin&#8217; really good work! Like I am going to cry!! This was so helpful??? <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f62d.png" alt="😭" class="wp-smiley" style="height: 1em; max-height: 1em;" /></span></p>
<p><span style="font-weight: 400;">That said, I will take a </span><i><span style="font-weight: 400;">little</span></i><span style="font-weight: 400;"> credit for this going so smoothly: both Rust itself and rust-minidump are written in a way that&#8217;s very friendly to fuzzing. Specifically, rust-minidump is riddled with assertions for &#8220;hmm this seems messed up and shouldn&#8217;t happen but maybe?&#8221; and Rust turns integer overflows into panics (crashes) in debug builds (and index-out-of-bounds is always a panic).</span></p>
<p><span style="font-weight: 400;">Having lots of assertions everywhere makes it </span><i><span style="font-weight: 400;">a lot</span></i><span style="font-weight: 400;"> easier to detect situations where things go wrong. And when you </span><i><span style="font-weight: 400;">do</span></i><span style="font-weight: 400;"> detect that situation, the crash will often point pretty close to where things went wrong.</span></p>
<p><span style="font-weight: 400;">As someone who has worked on detecting bugs in Firefox with sanitizer and fuzzing folks, let me tell you what really sucks to try to do anything with: &#8220;Hey so on my machine this enormous complicated machine-generated input caused Firefox to crash </span><i><span style="font-weight: 400;">somewhere</span></i><span style="font-weight: 400;"> this </span><i><span style="font-weight: 400;">one time</span></i><span style="font-weight: 400;">. No, I can&#8217;t reproduce it. You won&#8217;t be able to reproduce it either. Anyway, try to fix it?&#8221;</span></p>
<p><span style="font-weight: 400;">That&#8217;s not me throwing shade on anyone here. I am all of the people in that conversation. The struggle of productively fuzzing Firefox is all too real, and I do not have a good track record of fixing those kinds of bugs. </span></p>
<p><span style="font-weight: 400;">By comparison I am absolutely </span><i><span style="font-weight: 400;">thriving</span></i><span style="font-weight: 400;"> under &#8220;Yeah you can deterministically trip this assertion with this tiny input you can just check in as a unit test&#8221;.</span></p>
<p><span style="font-weight: 400;">And what did we screw up? Some legit stuff! It&#8217;s Rust code, so I am fairly confident none of the issues were </span><i><span style="font-weight: 400;">security</span></i><span style="font-weight: 400;"> concerns, but they were definitely quality of implementation issues, and could have been used to at very least denial-of-service the minidump processor.</span></p>
<p><span style="font-weight: 400;">Now let&#8217;s dig into the issues they found!</span></p>
<h2><b>#428: Corrupt stacks caused infinite loops until OOM on ARM64</b></h2>
<p><a href="https://github.com/luser/rust-minidump/issues/428"><span style="font-weight: 400;">Issue</span></a></p>
<p><span style="font-weight: 400;">As noted in the background, stackwalking is a giant heuristic mess and you can find yourself going backwards or stuck in an infinite loop. To keep this under control, stackwalkers generally require </span><i><span style="font-weight: 400;">forward progress</span></i><span style="font-weight: 400;">. </span></p>
<p><span style="font-weight: 400;">Specifically, they require the stack pointer to move down the stack. If the stack pointer ever goes backwards or stays the same, we just call it quits and end the stackwalk there.</span></p>
<p><span style="font-weight: 400;">However, you can&#8217;t be </span><i><span style="font-weight: 400;">so</span></i><span style="font-weight: 400;"> strict on ARM because leaf functions </span><i><span style="font-weight: 400;">may not change the stack size at all</span></i><span style="font-weight: 400;">. Normally this would be impossible because every function call </span><i><span style="font-weight: 400;">at least</span></i><span style="font-weight: 400;"> has to push the return address to the stack, but ARM has the </span><i><span style="font-weight: 400;">link register</span></i><span style="font-weight: 400;"> which is basically an extra buffer for the return address. </span></p>
<p><span style="font-weight: 400;">The existence of the link register in conjunction with an ABI that makes the callee responsible for saving and restoring it means leaf functions </span><i><span style="font-weight: 400;">can</span></i><span style="font-weight: 400;"> have 0-sized stack frames!</span></p>
<p><span style="font-weight: 400;">To handle this, an ARM stackwalker must allow for there to be no forward progress for the </span><i><span style="font-weight: 400;">first</span></i><span style="font-weight: 400;"> frame of a stackwalk, </span><b>and then become more strict</b><span style="font-weight: 400;">. Unfortunately I hand-waved that second part and ended up allowing infinite loops with no forward progress:</span></p>
<pre><span style="font-weight: 400;">// If the new stack pointer is at a lower address than the old,</span>
<span style="font-weight: 400;">// then that's clearly incorrect. Treat this as end-of-stack to</span>
<span style="font-weight: 400;">// enforce progress and avoid infinite loops.</span>
<span style="font-weight: 400;">//</span>
<span style="font-weight: 400;">// NOTE: this check allows for equality because arm leaf functions</span>
<span style="font-weight: 400;">// may not actually touch the stack (thanks to the link register</span>
<span style="font-weight: 400;">// allowing you to "push" the return address to a register).</span>
<span style="font-weight: 400;">if frame.context.get_stack_pointer() &lt; self.get_register_always("sp") as u64 {</span>
<span style="font-weight: 400;">    trace!("unwind: stack pointer went backwards, assuming unwind complete");</span>
<span style="font-weight: 400;">    return None;</span>
<span style="font-weight: 400;">}</span></pre>
<p><span style="font-weight: 400;">So if the ARM64 stackwalker ever gets stuck in an infinite loop on one frame, it will just build up an infinite backtrace until it&#8217;s killed by an OOM. This is very nasty because it&#8217;s a potentially very slow denial-of-service that eats up all the memory on the machine!</span></p>
<p><span style="font-weight: 400;">This issue was actually originally discovered and fixed in</span><a href="https://github.com/luser/rust-minidump/issues/300"> <span style="font-weight: 400;">#300</span></a> <i><span style="font-weight: 400;">without</span></i><span style="font-weight: 400;"> a fuzzer, but when I fixed it for ARM (32-bit) I completely forgot to do the same for ARM64. Thankfully the fuzzer was evil enough to discover this infinite looping situation on its own, and the fix was just &#8220;copy-paste the logic from the 32-bit impl&#8221;.</span></p>
<p><span style="font-weight: 400;">Because this issue was actually encountered in the wild, we know this was a serious concern! Good job, fuzzer!</span></p>
<p><span style="font-weight: 400;">(This issue specifically affected minidump-processor and minidump-stackwalk)</span></p>
<h3><b>#407: MinidumpLinuxMaps address-based queries didn&#8217;t work at all</b></h3>
<p><a href="https://github.com/luser/rust-minidump/issues/407"><span style="font-weight: 400;">Issue</span></a></p>
<p><span style="font-weight: 400;">MinidumpLinuxMaps is an interface for querying the dumped contents of Linux&#8217;s /proc/self/maps file. This provides metadata on the permissions and allocation state for mapped ranges of memory in the crashing process.</span></p>
<p><span style="font-weight: 400;">There are two usecases for this: just getting a full dump of all the process state, and specifically querying the memory properties for a specific address (&#8220;hey is this address executable?&#8221;). The dump usecase is handled by just shoving everything in a Vec. The address usecase requires us to create a RangeMap over the entries.</span></p>
<p><span style="font-weight: 400;">Unfortunately, a comparison was flipped in the code that created the keys to the RangeMap, which resulted in every </span><i><span style="font-weight: 400;">correct</span></i><span style="font-weight: 400;"> memory range being discarded AND invalid memory ranges being accepted. The fuzzer was able to catch this because the invalid ranges tripped an assertion when they got fed into the RangeMap (hurray for redundant checks!).</span></p>
<pre><span style="font-weight: 400;">// OOPS</span>
<span style="font-weight: 400;">if self.base_address &lt; self.final_address { </span>
<span style="font-weight: 400;"> return None; </span>
<span style="font-weight: 400;">}</span></pre>
<p><span style="font-weight: 400;">Although tests were written for MinidumpLinuxMaps, they didn&#8217;t include any invalid ranges, and just used the dump interface, so the fact that the RangeMap was empty went unnoticed!</span></p>
<p><span style="font-weight: 400;">This </span><i><span style="font-weight: 400;">probably</span></i><span style="font-weight: 400;"> would have been quickly found as soon as anyone tried to actually use this API in practice, but it&#8217;s nice that we caught it beforehand! Hooray for fuzzers!</span></p>
<p><span style="font-weight: 400;">(This issue specifically affected the minidump crate which technically could affect minidump-processor and minidump-stackwalk. Although they didn&#8217;t yet actually do address queries, they may have crashed when fed invalid ranges.)</span></p>
<h2><b>#381: OOM from reserving memory based on untrusted list length.</b></h2>
<p><a href="https://github.com/luser/rust-minidump/issues/381"><span style="font-weight: 400;">Issue</span></a></p>
<p><span style="font-weight: 400;">Minidumps have lots of lists which we end up collecting up in a Vec or some other collection. It&#8217;s quite natural and more efficient to start this process with something like </span><span style="font-weight: 400;">Vec::with_capacity(list_length)</span><span style="font-weight: 400;">. Usually this is fine, but if the minidump is corrupt (or malicious), then this length could be impossibly large and cause us to immediately OOM.</span></p>
<p><span style="font-weight: 400;">We were broadly aware that this was a problem, and had discussed the issue in</span><a href="https://github.com/luser/rust-minidump/issues/326"> <span style="font-weight: 400;">#326</span></a><span style="font-weight: 400;">, but then everyone left for the holidays. #381 was a nice kick in the pants to actually fix it, and gave us a free simple test case to check in.</span></p>
<p><span style="font-weight: 400;">Although the naive solution would be to fix this by just removing the reserves, we opted for a solution that guarded against obviously-incorrect array lengths. This allowed us to keep the performance win of reserving memory while also making rust-minidump fast-fail instead of vaguely trying to do something and hallucinating a mess.</span></p>
<p><span style="font-weight: 400;">Specifically, @Swatinem introduced a function for checking that the amount of memory left in the section we&#8217;re parsing is </span><i><span style="font-weight: 400;">large enough</span></i><span style="font-weight: 400;"> to even hold the claimed amount of items (based on their known serialized size). This should mean the minidump crate can only be induced to reserve O(n) memory, where n is the size of the minidump itself.</span></p>
<p><span style="font-weight: 400;">For some scale:</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">A minidump for Firefox&#8217;s main process with about 100 threads is about 3MB.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">A minidump for a stackoverflow from infinite recursion (8MB stack, 9000 calls) is about 8MB.</span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">A breakpad symbol file for Firefox&#8217;s main module can be about </span><b>200MB</b><span style="font-weight: 400;">.</span></li>
</ul>
<p><span style="font-weight: 400;">If you&#8217;re symbolicating, Minidumps probably won&#8217;t be your memory bottleneck. <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f639.png" alt="😹" class="wp-smiley" style="height: 1em; max-height: 1em;" /></span></p>
<p><span style="font-weight: 400;">(This issue specifically affected the minidump crate and therefore also minidump-processor and minidump-stackwalk.)</span></p>
<h2><b>The Many Integer Overflows and My Greatest Defeat</b></h2>
<p><span style="font-weight: 400;">The rest of the issues found were relatively benign integer overflows. I claim they&#8217;re benign because rust-minidump should </span><i><span style="font-weight: 400;">already</span></i><span style="font-weight: 400;"> be working under the assumption that all the values it reads out of the minidump could be corrupt garbage. This means its code is riddled with &#8220;is this nonsense&#8221; checks and those usually very quickly catch an overflow (or at worst print a nonsense value for some pointer).</span></p>
<p><span style="font-weight: 400;">We still fixed them all, because that&#8217;s shaky as heck logic and we want to be robust. But yeah none of these were even denial-of-service issues, as far as I know.</span></p>
<p><span style="font-weight: 400;">To demonstrate this, let&#8217;s discuss the most evil and embarrassing overflow which was definitely my fault and I am </span><i><span style="font-weight: 400;">still</span></i><span style="font-weight: 400;"> mad about it but in a like &#8220;how the heck&#8221; kind of way!?</span></p>
<p><span style="font-weight: 400;">The overflow is back in our old friend the stackwalker. Specifically in the code that attempts to unwind using frame pointers. Even more specifically, when offsetting the supposed frame-pointer to get the location of the supposed return address:</span></p>
<pre><span style="font-weight: 400;">let caller_ip = stack_memory.get_memory_at_address(last_bp + POINTER_WIDTH)?;</span>
<span style="font-weight: 400;">let caller_bp = stack_memory.get_memory_at_address(last_bp)?;</span>
<span style="font-weight: 400;">let caller_sp = last_bp + POINTER_WIDTH * 2;</span></pre>
<p><span style="font-weight: 400;">If the frame pointer (</span><span style="font-weight: 400;">last_bp</span><span style="font-weight: 400;">) was ~</span><span style="font-weight: 400;">u64::MAX</span><span style="font-weight: 400;">, the offset on the first line would overflow and we would instead try to load ~null. All of our loads are explicitly fallible (we assume everything is corrupt garbage!), and nothing is ever mapped to the null page in normal applications, so this load would reliably fail as if we had guarded the overflow. Hooray!</span></p>
<p><span style="font-weight: 400;">&#8230;but the overflow would panic in debug builds because that&#8217;s how debug builds work in Rust!</span></p>
<p><span style="font-weight: 400;">This was actually found, reported, and fixed </span><i><span style="font-weight: 400;">without</span></i><span style="font-weight: 400;"> a fuzzer in</span><a href="https://github.com/luser/rust-minidump/issues/251"> <span style="font-weight: 400;">#251</span></a><span style="font-weight: 400;">. All it took was a simple guard:</span></p>
<p><span style="font-weight: 400;">(All the casts are because this specific code is used in the x86 impl </span><i><span style="font-weight: 400;">and</span></i><span style="font-weight: 400;"> the x64 impl.)</span></p>
<pre><span style="font-weight: 400;">if last_bp as u64 &gt;= u64::MAX - POINTER_WIDTH as u64 * 2 {</span>
<span style="font-weight: 400;">    // Although this code generally works fine if the pointer math overflows,</span>
<span style="font-weight: 400;">    // debug builds will still panic, and this guard protects against it without</span>
<span style="font-weight: 400;">    // drowning the rest of the code in checked_add.</span>
<span style="font-weight: 400;">    return None;</span>
<span style="font-weight: 400;">}</span>

<span style="font-weight: 400;">let caller_ip = stack_memory.get_memory_at_address(last_bp as u64 + POINTER_WIDTH as u64)?;</span>
<span style="font-weight: 400;">let caller_bp = stack_memory.get_memory_at_address(last_bp as u64)?;</span>
<span style="font-weight: 400;">let caller_sp = last_bp + POINTER_WIDTH * 2;</span></pre>
<p><span style="font-weight: 400;">And then it was found, reported, and fixed </span><b>again</b> <i><span style="font-weight: 400;">with a fuzzer</span></i><span style="font-weight: 400;"> in</span><a href="https://github.com/luser/rust-minidump/issues/422"> <span style="font-weight: 400;">#422</span></a><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">Wait what?</span></p>
<p><span style="font-weight: 400;">Unlike the infinite loop bug, I </span><i><span style="font-weight: 400;">did</span></i><span style="font-weight: 400;"> remember to add guards to all the unwinders for this problem&#8230; but I did the overflow check in 64-bit </span><i><span style="font-weight: 400;">even for the 32-bit platforms</span></i><span style="font-weight: 400;">.</span></p>
<p><b>slaps forehead</b></p>
<p><span style="font-weight: 400;">This made the bug report especially confusing at first because the overflow was like 3 lines away from </span><i><span style="font-weight: 400;">a guard for that exact overflow</span></i><span style="font-weight: 400;">. As it turns out, the mistake wasn&#8217;t actually as obvious as it sounds! To understand what went wrong, let&#8217;s talk a bit more about pointer width in minidumps.</span></p>
<p><span style="font-weight: 400;">A single instance of rust-minidump has to be able to handle crash reports from </span><i><span style="font-weight: 400;">any</span></i><span style="font-weight: 400;"> platform, even ones it isn&#8217;t natively running on. This means it needs to be able to handle both 32-bit and 64-bit platforms in one binary. To avoid the misery of copy-pasting everything or making everything generic over pointer size, rust-minidump prefers to work with 64-bit values wherever possible, even for 32-bit plaftorms.</span></p>
<p><span style="font-weight: 400;">This isn&#8217;t just us being lazy: the minidump format itself does this! Regardless of the platform, a minidump will refer to ranges of memory with a</span><a href="https://docs.microsoft.com/en-us/windows/win32/api/minidumpapiset/ns-minidumpapiset-minidump_memory_descriptor"> <span style="font-weight: 400;">MINIDUMP_MEMORY_DESCRIPTOR</span></a><span style="font-weight: 400;"> whose base address is a 64-bit value, even on 32-bit platforms!</span></p>
<pre><span style="font-weight: 400;">typedef struct _MINIDUMP_MEMORY_DESCRIPTOR {</span>
<span style="font-weight: 400;">  ULONG64                      StartOfMemoryRange;</span>
<span style="font-weight: 400;">  MINIDUMP_LOCATION_DESCRIPTOR Memory;</span>
<span style="font-weight: 400;">} MINIDUMP_MEMORY_DESCRIPTOR, *PMINIDUMP_MEMORY_DESCRIPTOR;</span></pre>
<p><span style="font-weight: 400;">So quite naturally rust-minidump&#8217;s interface for querying saved regions of memory just operates on 64-bit (u64) addresses unconditionally, and 32-bit-specific code casts its u32 address to a u64 before querying memory.</span></p>
<p><span style="font-weight: 400;">That means the code with the overflow guard </span><i><span style="font-weight: 400;">was</span></i><span style="font-weight: 400;"> manipulating those values as u64s on x86! The </span><i><span style="font-weight: 400;">problem</span></i><span style="font-weight: 400;"> is that after all the memory loads we would then go back to &#8220;native&#8221; sizes and compute </span><span style="font-weight: 400;">caller_sp = last_bp + POINTER_WIDTH * 2</span><span style="font-weight: 400;">. This would overflow a u32 and crash in debug builds. <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f63f.png" alt="😿" class="wp-smiley" style="height: 1em; max-height: 1em;" /></span></p>
<p><span style="font-weight: 400;">But here&#8217;s the really messed up part: </span><i><span style="font-weight: 400;">getting to that point meant we were successfully loading memory up to that address</span></i><span style="font-weight: 400;">. The first line where we compute caller_ip reads it! So this overflow means&#8230; we were&#8230; loading memory&#8230; from an address that was beyond u32::MAX&#8230;!?</span></p>
<p><span style="font-weight: 400;">Yes!!!!!!!!</span></p>
<p><span style="font-weight: 400;">The fuzzer had found an absolutely </span><i><span style="font-weight: 400;">brilliantly evil input</span></i><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">It abused the fact that MINIDUMP_MEMORY_DESCRIPTOR </span><i><span style="font-weight: 400;">technically</span></i><span style="font-weight: 400;"> lets 32-bit minidumps define memory ranges beyond </span><span style="font-weight: 400;">u32::MAX</span> <i><span style="font-weight: 400;">even though they could never actually access that memory!</span></i><span style="font-weight: 400;"> It could then have the u64-based memory accesses succeed but still have the &#8220;native&#8221; 32-bit operation overflow!</span></p>
<p><span style="font-weight: 400;">This is so messed up that I didn&#8217;t even </span><i><span style="font-weight: 400;">comprehend</span></i><span style="font-weight: 400;"> that it had done this until I wrote my own test and realized that it wasn&#8217;t actually failing because I </span><i><span style="font-weight: 400;">foolishly</span></i><span style="font-weight: 400;"> had limited the range of valid memory to the mere 4GB a normal x86 process is restricted to.</span></p>
<p><span style="font-weight: 400;">And I mean that quite literally: this is exactly the issue that creates</span><a href="https://youtu.be/kpk2tdsPh0A?t=638"> <span style="font-weight: 400;">Parallel Universes in Super Mario 64</span></a><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">But hey my code was probably just bad. I know google loves sanitizers and fuzzers, so I bet google breakpad found this overflow ages ago and fixed it:</span></p>
<pre><span style="font-weight: 400;">uint32_t last_esp = last_frame-&gt;context.esp;</span>
<span style="font-weight: 400;">uint32_t last_ebp = last_frame-&gt;context.ebp;</span>
<span style="font-weight: 400;">uint32_t caller_eip, caller_esp, caller_ebp;</span>

<span style="font-weight: 400;">if (memory_-&gt;GetMemoryAtAddress(last_ebp + 4, &amp;caller_eip) &amp;&amp;</span>
<span style="font-weight: 400;">    memory_-&gt;GetMemoryAtAddress(last_ebp, &amp;caller_ebp)) {</span>
<span style="font-weight: 400;">    caller_esp = last_ebp + 8;</span>
<span style="font-weight: 400;">    trust = StackFrame::FRAME_TRUST_FP;</span>
<span style="font-weight: 400;">} else {</span>
<span style="font-weight: 400;">    ...</span></pre>
<p><span style="font-weight: 400;">Ah. Hmm. They don&#8217;t guard for any kind of overflow for those uint32_t&#8217;s (or the uint64_t&#8217;s in the x64 impl).</span></p>
<p><span style="font-weight: 400;">Well ok GetMemoryAtAddress does actual bounds checks so the load from ~null will generally fail like it does in rust-minidump. But what about the Parallel Universe overflow that lets GetMemoryAtAddress succeed?</span></p>
<p><span style="font-weight: 400;">Ah well surely breakpad is more principled with integer width than I was&#8211;</span></p>
<pre><span style="font-weight: 400;">virtual bool GetMemoryAtAddress(uint64_t address, uint8_t*  value) const = 0;</span>
<span style="font-weight: 400;">virtual bool GetMemoryAtAddress(uint64_t address, uint16_t* value) const = 0;</span>
<span style="font-weight: 400;">virtual bool GetMemoryAtAddress(uint64_t address, uint32_t* value) const = 0;</span>
<span style="font-weight: 400;">virtual bool GetMemoryAtAddress(uint64_t address, uint64_t* value) const = 0;</span>
</pre>
<p><span style="font-weight: 400;">Whelp congrats to 5225225 for finding an overflow that&#8217;s portable between two implementations in two completely different languages by exploiting the very nature of the file format itself!</span></p>
<p><span style="font-weight: 400;">In case you&#8217;re wondering what the implications of this overflow are: it&#8217;s still basically benign. Both rust-minidump and google-breakpad will successfully complete the frame pointer analysis and yield a frame with a ~null stack pointer.</span></p>
<p><span style="font-weight: 400;">Then the outer layer of the stackwalker which runs all the different passes in sequence will see something succeeded but that the frame pointer went backwards. At this point it will discard the stack frame and terminate the stackwalk normally and just calmly output whatever the backtrace was up to that point. Totally normal and reasonable operation.</span></p>
<p><span style="font-weight: 400;">I expect this is why no one would notice this in breakpad even if you run fuzzers and sanitizers on it: nothing in the code actually does anything </span><i><span style="font-weight: 400;">wrong</span></i><span style="font-weight: 400;">. Unsigned integers are defined to wrap, the program behaves reasonably, everything is </span><i><span style="font-weight: 400;">kinda</span></i><span style="font-weight: 400;"> fine. We only noticed this in rust-minidump because </span><i><span style="font-weight: 400;">all</span></i><span style="font-weight: 400;"> integer overflows panic in Rust debug builds.</span></p>
<p><span style="font-weight: 400;">However this &#8220;benign&#8221; behaviour </span><i><span style="font-weight: 400;">is</span></i><span style="font-weight: 400;"> slightly different from properly guarding the overflow. Both implementations will normally try to move on to </span><i><span style="font-weight: 400;">stack scanning</span></i><span style="font-weight: 400;"> when the frame pointer analysis fails, but in this case they give up immediately. It&#8217;s </span><i><span style="font-weight: 400;">important</span></i><span style="font-weight: 400;"> that the frame pointer analysis properly identifies failures so that this cascading can occur. Failing to do so is definitely a bug!</span></p>
<p><span style="font-weight: 400;">However in this case the stack is partially in a parallel universe, so getting any kind of useful backtrace out of it is&#8230; dubious to say the least.</span></p>
<p><span style="font-weight: 400;">So I totally stand by &#8220;this is totally benign and not actually a problem&#8221; but also &#8220;this is sketchy and we should have the bounds check so we can be confident in this code&#8217;s robustness and correctness&#8221;.</span></p>
<p><span style="font-weight: 400;">Minidumps are </span><i><span style="font-weight: 400;">all</span></i><span style="font-weight: 400;"> corner cases &#8212; they literally get generated </span><i><span style="font-weight: 400;">when a program encounters an unexpected corner case</span></i><span style="font-weight: 400;">! It&#8217;s </span><i><span style="font-weight: 400;">so</span></i><span style="font-weight: 400;"> tempting to constantly shrug off situations as &#8220;well no reasonable program would ever do this, so we can ignore it&#8221;&#8230; but YOU CAN&#8217;T.</span></p>
<p><span style="font-weight: 400;">You would not have a minidump at your doorstep if the program had behaved reasonably! The fact that you are trying to inspect a minidump means something messed up happened, and you need to just deal with it!</span></p>
<p><span style="font-weight: 400;">That&#8217;s why we put so much energy into testing this thing, it&#8217;s a nightmare!</span></p>
<p><span style="font-weight: 400;">I am </span><i><span style="font-weight: 400;">extremely</span></i><span style="font-weight: 400;"> paranoid about this stuff, but that paranoia is based on the horrors I have seen. There are always more corner cases. </span></p>
<p><span style="font-weight: 400;">There are </span><i><span style="font-weight: 400;">ALWAYS</span></i><span style="font-weight: 400;"> more corner cases. </span><b>ALWAYS</b><span style="font-weight: 400;">.</span></p>
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/fuzzing-rust-minidump-for-embarrassment-and-crashes/">Fuzzing rust-minidump for Embarrassment and Crashes &#8211; Part 2</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://hacks.mozilla.org/2022/06/fuzzing-rust-minidump-for-embarrassment-and-crashes/feed/</wfw:commentRss>
			<slash:comments>2</slash:comments>
		
		
			</item>
		<item>
		<title>Hacks Decoded: Bikes and Boomboxes with Samuel Aboagye</title>
		<link>https://hacks.mozilla.org/2022/06/hacks-decoded-bikes-and-boomboxes-with-samuel-aboagye/</link>
		
		<dc:creator><![CDATA[Xavier Harding]]></dc:creator>
		<pubDate>Thu, 16 Jun 2022 15:00:15 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Interviews]]></category>
		<category><![CDATA[Mozilla]]></category>
		<category><![CDATA[Hacks Decoded]]></category>
		<category><![CDATA[innovation]]></category>
		<category><![CDATA[inventions]]></category>
		<category><![CDATA[recycled]]></category>
		<category><![CDATA[Samuel Aboagye]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47854</guid>

					<description><![CDATA[<p>Samuel Aboagye is a genius. Aboagye is 17 years old. In those 17 years, he’s crafted more inventions than you have, probably. Among them: a solar-powered bike and a Bluetooth speaker, both using recycled materials. We caught up with Aboagye over video chat in hopes that he’d talk with us about his creations, and ultimately how he’s way cooler than any of us at 17.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/hacks-decoded-bikes-and-boomboxes-with-samuel-aboagye/">Hacks Decoded: Bikes and Boomboxes with Samuel Aboagye</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p><i>Welcome to our Hacks: Decoded Interview series!</i></p>
<p><i>Once a month, </i><a href="https://foundation.mozilla.org/" target="_blank" rel="noopener"><i>Mozilla Foundation</i></a><i>’s </i><a href="https://www.xavierharding.com/" target="_blank" rel="noopener"><i>Xavier Harding</i></a><i> speaks with people in the tech industry about where they’re from, the work they do and what drives them to keep going forward. Make sure you follow Mozilla’s </i><a href="https://hacks.mozilla.org/"><i>Hacks</i></a><i> blog to find more articles in this series and make sure to visit the Mozilla Foundation site to see more of our org’s work.</i></p>
<p><strong>Meet Samuel Aboagye!</strong></p>
<p>Samuel Aboagye is a genius. Aboagye is 17 years old. In those 17 years, he’s crafted more inventions than you have, probably. Among them: a solar-powered bike and a Bluetooth speaker, both using recycled materials. We caught up with Ghanaian inventor Samuel Aboagye over video chat in hopes that he’d talk with us about his creations, and ultimately how he’s way cooler than any of us were at 17.</p>
<div style="width: 368px;" class="wp-video"><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video class="wp-video-shortcode" id="video-47854-1" width="368" height="640" poster="https://hacks.mozilla.org/files/2022/06/Screenshot-2022-06-16-at-09.31.34.png" preload="metadata" controls="controls"><source type="video/mp4" src="https://hacks.mozilla.org/files/2022/06/Untitled.mp4?_=1" /><a href="https://hacks.mozilla.org/files/2022/06/Untitled.mp4">https://hacks.mozilla.org/files/2022/06/Untitled.mp4</a></video></div>
<p>&nbsp;</p>
<p><b>Samuel, you’ve put together lots of inventions like an electric bike and Bluetooth speaker and even a fan. What made you want to make them?</b><i></i></p>
<p><span style="font-weight: 400;">For the speaker, I thought of how I could minimize the rate at which yellow plastic containers pollute the environment.  I tried to make good use of it after it served its purpose. So, with the little knowledge, I acquired in my science lessons, instead of the empty container just lying down and polluting the environment, I tried to create something useful with it.  </span></p>
<p><span style="font-weight: 400;">After the Bluetooth speaker was successful, I realized there was more in me I could show to the universe. More importantly, we live in a very poor ventilated room and we couldn’t afford an electric fan so the room was unbearably hot. As such, this situation triggered and motivated me to manufacture a fan to solve this family problem.</span></p>
<p><span style="font-weight: 400;">With the bike, I thought it would be wise to make life easier for the physically challenged because I was always sad to see them go through all these challenges just to live their daily lives. Electric motors are very expensive and not common in my country, so I decided to do something to help. </span></p>
<p><span style="font-weight: 400;">Since solar energy is almost always readily available in my part of the world and able to renew itself, I thought that if I am able to make a bike with it, it would help the physically challenged to move from one destination to another without stress or thinking of how to purchase a battery or fuel.  </span></p>
<p><b>So how did you go about making them? Did you run into any trouble?</b><i></i></p>
<p><span style="font-weight: 400;">I went around my community gathering used items and old gadgets like radio sets and other electronics and then removed parts that could help in my work. With the electrical energy training given to me by my science teacher after discovering me since JHS1, I was able to apply this and also combined with my God-given talent. </span></p>
<p><span style="font-weight: 400;">Whenever I need some sort of technical guidance, I call on my teacher Sir David. He has also been my financial help for all my projects.  Financing projects has always been my biggest struggle and most times I have to wait on him to raise funds for me to continue.</span></p>
<p><b>The tricycle: Was it much harder to make than a bike?</b></p>
<p><b>​​</b><span style="font-weight: 400;">Yes, it was a little bit harder to make the tricycle than the bike. It’s time-consuming and also cost more than a bike. It needs extra technical and critical thinking too. </span><i></i></p>
<p><b>You made the bike and speaker out of recycled materials. This answer is probably obvious but I’ve gotta ask: why recycled materials?  Is environment-friendly tech important to you?</b></p>
<p><span style="font-weight: 400;">I used recycled materials because they were readily available and comparable to cheap and easy to get. With all my inventions I make sure they are all environmentally friendly so as not to pose any danger now or future to the beings on Earth.  But also, I want the world to be a safe and healthy place to be. </span></p>
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/hacks-decoded-bikes-and-boomboxes-with-samuel-aboagye/">Hacks Decoded: Bikes and Boomboxes with Samuel Aboagye</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
		
		<enclosure url="https://hacks.mozilla.org/files/2022/06/Untitled.mp4" length="11160104" type="video/mp4" />

			</item>
		<item>
		<title>Everything Is Broken: Shipping rust-minidump at Mozilla &#8211; Part 1</title>
		<link>https://hacks.mozilla.org/2022/06/everything-is-broken-shipping-rust-minidump-at-mozilla/</link>
					<comments>https://hacks.mozilla.org/2022/06/everything-is-broken-shipping-rust-minidump-at-mozilla/#comments</comments>
		
		<dc:creator><![CDATA[Aria Beingessner]]></dc:creator>
		<pubDate>Tue, 14 Jun 2022 15:05:06 +0000</pubDate>
				<category><![CDATA[Developer Tools]]></category>
		<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[breakpad]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[google]]></category>
		<category><![CDATA[macos]]></category>
		<category><![CDATA[minidump]]></category>
		<category><![CDATA[rust]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47842</guid>

					<description><![CDATA[<p>For the last year, we've been working on the development of rust-minidump, a pure-Rust replacement for the minidump-processing half of google-breakpad. The first in this two-part series explains what minidumps are, and how we made rust-minidump.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/everything-is-broken-shipping-rust-minidump-at-mozilla/">Everything Is Broken: Shipping rust-minidump at Mozilla &#8211; Part 1</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<h1><strong>Everything Is Broken: Shipping rust-minidump at Mozilla</strong></h1>
<p>For the last year I&#8217;ve been leading the development of <a href="https://github.com/luser/rust-minidump/">rust-minidump</a>, a pure-Rust replacement for the minidump-processing half of <a href="https://chromium.googlesource.com/breakpad/breakpad/">google-breakpad</a>.</p>
<p>Well actually in some sense I <em>finished</em> that work, because Mozilla already <a href="https://github.com/luser/rust-minidump/tree/master/minidump-stackwalk">deployed it</a> as <a href="https://crash-stats.mozilla.org/">the crash processing backend for Firefox</a> 6 months ago, it runs in half the time, and seems to be more reliable. (And you know, <em>isn&#8217;t</em> a terrifying ball of C++ that parses and evaluates arbitrary input from the internet. We did our best to isolate Breakpad, but still… <em>yikes</em>.)</p>
<p>This is a pretty fantastic result, but there&#8217;s always more work to do because <em>Minidumps are an inky abyss that grows deeper the further you delve…</em> wait no I&#8217;m getting ahead of myself. First the light, then the abyss. Yes. Light first.</p>
<p>What I <em>can</em> say is that we have a very solid implementation of the core functionality of minidump parsing+analysis for the biggest platforms (x86, x64, ARM, ARM64; Windows, MacOS, Linux, Android). But if you want to read minidumps generated on a <em>PlayStation 3</em> or process a <em>Full Memory</em> dump, you won&#8217;t be served quite as well.</p>
<p>We&#8217;ve put a lot of effort into documenting and testing this thing, so I&#8217;m pretty confident in it!</p>
<p><strong>Unfortunately! Confidence! Is! Worth! Nothing!</strong></p>
<p>Which is why this is the story of how we did our best to make this nightmare as robust as we could and still got 360 dunked on from space by the sudden and <em>incredible</em> fuzzing efforts of <a href="https://github.com/5225225">@5225225</a>.</p>
<p>This article is broken into two parts:</p>
<ol>
<li>what minidumps are, and how we made rust-minidump</li>
<li>how we got absolutely owned by simple fuzzing</li>
</ol>
<p>You are reading part 1, wherein we build up our hubris.</p>
<h1><strong>Background: What&#8217;s A Minidump, and Why Write rust-minidump?</strong></h1>
<p>Your program crashes. You want to know why your program crashed, but it happened on a user&#8217;s machine on the other side of the world. A full coredump (all memory allocated by the program) is enormous &#8212; we can&#8217;t have users sending us 4GB files! Ok let&#8217;s just collect up the most important regions of memory like the stacks and where the program crashed. Oh and I guess if we&#8217;re taking the time, let&#8217;s stuff some metadata about the system and process in there too.</p>
<p>Congratulations you have invented <a href="https://docs.microsoft.com/en-us/windows/win32/debug/minidump-files">Minidumps</a>. Now you can turn a 100-thread coredump that would otherwise be 4GB into a nice little 2MB file that you can send over the internet and do postmortem analysis on.</p>
<p>Or more specifically, Microsoft did. So long ago that their docs don&#8217;t even discuss platform support. MiniDumpWriteDump&#8217;s supported versions are simply &#8220;Windows&#8221;. Microsoft Research has presumably developed a time machine to guarantee this.</p>
<p>Then Google came along (circa 2006-2007) and said &#8220;wouldn&#8217;t it be nice if we could make minidumps on <em>any</em> platform&#8221;? Thankfully Microsoft had actually built the format pretty extensibly, so it wasn&#8217;t too bad to extend the format for Linux, MacOS, BSD, Solaris, and so on. Those extensions became <a href="https://chromium.googlesource.com/breakpad/breakpad/">google-breakpad</a> (or just Breakpad) which included a ton of different tools for generating, parsing, and analyzing their extended minidump format (and native Microsoft ones).</p>
<p>Mozilla helped out with this a lot because apparently, our crash reporting infrastructure (&#8220;Talkback&#8221;) was <em>miserable</em> circa 2007, and this seemed like a nice improvement. Needless to say, we&#8217;re pretty invested in breakpad&#8217;s minidumps at this point.</p>
<p>Fast forward to the present day and in a hilarious twist of fate, products like VSCode mean that Microsoft now supports applications that run on Linux and MacOS so it runs breakpad in production and has to handle non-Microsoft minidumps somewhere in its crash reporting infra, so someone else&#8217;s extension of their own format is somehow their problem now!</p>
<p>Meanwhile, Google has kind-of moved on to <a href="https://chromium.googlesource.com/crashpad/crashpad">Crashpad</a>. I say kind-of because there&#8217;s still a lot of Breakpad in there, but they&#8217;re more interested in building out tooling on top of it than improving Breakpad itself. Having made a few changes to Breakpad: <strong>honestly fair</strong>, I don&#8217;t want to work on it either. Still, this was a bit of a problem for us, because it meant the project became increasingly under-staffed.</p>
<p>By the time I started working on crash reporting, Mozilla had basically given up on upstreaming fixes/improvements to Breakpad, and was just using its own patched fork. But even <em>without</em> the need for upstreaming patches, every change to Breakpad filled us with dread: many proposed improvements to our crash reporting infrastructure stalled out at &#8220;time to implement this in Breakpad&#8221;.</p>
<p>Why is working on Breakpad so miserable, you ask?</p>
<p>Parsing and analyzing minidumps is basically an exercise in writing a fractal parser of platform-specific formats nested in formats nested in formats. For many operating systems. For many hardware architectures. And all the inputs you&#8217;re parsing and analyzing are terrible and buggy so you <em>have</em> to write a really permissive parser and crawl forward however you can.</p>
<p>Some specific MSVC toolchain that was part of Windows XP had a bug in its debuginfo format? <strong>Too bad, symbolicate that stack frame anyway!</strong></p>
<p>The program crashed because it horribly corrupted its own stack? <strong>Too bad, produce a backtrace anyway!</strong></p>
<p>The minidump writer itself completely freaked out and wrote a bunch of garbage to one stream? <strong>Too bad, produce whatever output you can anyway!</strong></p>
<p>Hey, you know who has a lot of experience dealing with really complicated permissive parsers written in C++? Mozilla! That&#8217;s like <em>the core functionality</em> of a web browser.</p>
<p>Do you know Mozilla&#8217;s secret solution to writing really complicated permissive parsers in C++?</p>
<p><strong>We stopped doing it.</strong></p>
<p>We developed Rust and ported our nastiest parsers to it.</p>
<p>We&#8217;ve done it a lot, and <a href="https://hacks.mozilla.org/2017/08/inside-a-super-fast-css-engine-quantum-css-aka-stylo/">when we do</a> we&#8217;re always like <a href="https://www.joshmatthews.net/rbr17/">&#8220;wow this is so much more reliable and easy to maintain and it&#8217;s even faster now&#8221;</a>. Rust is a really good language for writing parsers. C++ really isn&#8217;t.</p>
<p>So we Rewrote It In Rust (or as the kids call it, &#8220;Oxidized It&#8221;). Breakpad is big, so we haven&#8217;t actually covered all of its features. We&#8217;ve specifically written and deployed:</p>
<ul>
<li><a href="https://github.com/mozilla/dump_syms">dump_syms</a> which processes native build artifacts into symbol files.</li>
<li><a href="https://github.com/luser/rust-minidump/">rust-minidump</a> which is a collection of crates that parse and analyze minidumps. Or more specifically, we deployed <a href="https://github.com/luser/rust-minidump/tree/master/minidump-stackwalk">minidump-stackwalk</a>, which is the high-level cli interface to all of rust-minidump.</li>
</ul>
<p>Notably missing from this picture is <em>minidump writing</em>, or what google-breakpad calls a <em>client</em> (because it runs on the client&#8217;s machine). We <em>are </em>working <a href="https://github.com/rust-minidump/minidump-writer">on a rust-based minidump writer</a>, but it&#8217;s not something we can recommend using quite yet (although it has sped up a lot thanks to help from <a href="https://embark.dev/">Embark Studios</a>).</p>
<p>This is arguably the messiest and hardest work because it has a horrible job: use a bunch of native system APIs to gather up a bunch of OS-specific and Hardware-specific information about the crash AND do it for a program that just crashed, on a machine that <em>caused </em>the program to crash.</p>
<p>We have a long road ahead but every time we get to the other side of one of these projects it&#8217;s <em>wonderful</em>.</p>
<p>&nbsp;</p>
<h1><strong>Background: Stackwalking and Calling Conventions</strong></h1>
<p>One of rust-minidump&#8217;s (<a href="https://github.com/luser/rust-minidump/tree/master/minidump-stackwalk">minidump-stackwalk&#8217;s</a>) most important jobs is to take the state for a thread (general purpose registers and stack memory) and create a backtrace for that thread (unwind/stackwalk). This is a surprisingly complicated and messy job, made only more complicated by the fact that <em>we are trying to analyze the memory of a process that got messed up enough to crash</em>.</p>
<p>This means our stackwalkers are inherently working with dubious data, and all of our stackwalking techniques are based on heuristics that can go wrong and we can very easily find ourselves in situations where the stackwalk goes backwards or sideways or infinite and we just have to try to deal with it!</p>
<p>It&#8217;s also pretty common to see a stackwalker start <em>hallucinating</em>, which is my term for &#8220;the stackwalker found something that looked plausible enough and went on a wacky adventure through the stack and made up a whole pile of useless garbage frames&#8221;. Hallucination is most common near the bottom of the stack where it&#8217;s also least offensive. This is because each frame you walk is another chance for something to go wrong, but also increasingly uninteresting because you&#8217;re rarely interested in confirming that a thread started in The Same Function All Threads Start In.</p>
<p>All of these problems would basically go away if everyone agreed to properly preserve their cpu&#8217;s <a href="https://gankra.github.io/blah/compact-unwinding/#frame-pointer-unwinding-standard-prologues">PERFECTLY GOOD DEDICATED FRAME POINTER REGISTER</a>. Just kidding, turning on frame pointers doesn&#8217;t really work either because Microsoft <a href="https://github.com/rust-lang/rust/issues/82333">invented chaos frame pointers</a> that can&#8217;t be used for unwinding! I assume this happened because they accidentally stepped on the wrong butterfly while they were traveling back in time to invent minidumps. (I&#8217;m sure it was a decision that made more sense 20 years ago, but it has not aged well.)</p>
<p>If you would like to learn more about the different techniques for unwinding, <a href="https://gankra.github.io/blah/compact-unwinding/#background-unwinding-and-debug-info">I wrote about them over here</a> in my <a href="https://gankra.github.io/blah/compact-unwinding">article on Apple&#8217;s Compact Unwind Info</a>. I&#8217;ve also attempted to <a href="https://docs.rs/breakpad-symbols/latest/breakpad_symbols/walker/index.html">document breakpad&#8217;s STACK WIN and STACK CFI unwind info formats here</a>, which are more similar to the  DWARF and PE32 unwind tables (which are basically tiny programming languages).</p>
<p>If you would like to learn more about ABIs in general, <a href="https://gankra.github.io/blah/rust-layouts-and-abis/#calling-conventions">I wrote an entire article about them here</a>. The end of that article also includes an <a href="https://gankra.github.io/blah/rust-layouts-and-abis/#calling-conventions">introduction to how calling conventions work</a>. Understanding calling conventions is key to implementing unwinders.</p>
<p>&nbsp;</p>
<p><strong>How Hard Did You Really Test Things?</strong></p>
<p>Hopefully you now have a bit of a glimpse into why analyzing minidumps is an enormous headache. And of course you know how the story ends: that fuzzer kicks our butts! But of course to really savor our defeat, you have to see how hard we tried to do a good job! It&#8217;s time to build up our hubris and pat ourselves on the back.</p>
<p>So how much work <em>actually</em> went into making rust-minidump robust before the fuzzer went to work on it?</p>
<p>Quite a bit!</p>
<p>I&#8217;ll never argue all the work we did was <em>perfect</em> but we definitely did some good work here, both for synthetic inputs and real world ones. Probably the biggest &#8220;flaw&#8221; in our methodology was the fact that we were only focused on getting Firefox&#8217;s usecase to work. Firefox runs on a lot of platforms and sees a lot of messed up stuff, but it&#8217;s still a fairly coherent product that only uses so many features of minidumps.</p>
<p>This is one of the nice benefits of our recent work with <a href="https://sentry.io/">Sentry</a>, which is basically a Crash Reporting As A Service company. They are <em>way</em> more liable to stress test all kinds of weird corners of the format that Firefox doesn&#8217;t, and they have definitely found (and fixed!) some places where something is wrong or missing! (And they recently deployed it into production too! <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f389.png" alt="🎉" class="wp-smiley" style="height: 1em; max-height: 1em;" />)</p>
<p>But hey don&#8217;t take my word for it, check out all the different testing we did:</p>
<h2><strong>Synthetic Minidumps for Unit Tests</strong></h2>
<p>rust-minidump includes a <a href="https://github.com/rust-minidump/rust-minidump/tree/553735e2624dcc6af82167f502cf92ae9a9fdc87/minidump-synth">synthetic minidump generator</a> which lets you come up with a high-level description of the contents of a minidump, and then produces an actual minidump binary that we can feed it into the full parser:</p>
<p>// Let&#8217;s make a synth minidump with this particular Crashpad Info&#8230;</p>
<pre>let module = ModuleCrashpadInfo::new(42, Endian::Little)
    .add_list_annotation("annotation")
    .add_simple_annotation("simple", "module")
    .add_annotation_object("string", AnnotationValue::String("value".to_owned()))
    .add_annotation_object("invalid", AnnotationValue::Invalid)
    .add_annotation_object("custom", AnnotationValue::Custom(0x8001, vec![42]));

let crashpad_info = CrashpadInfo::new(Endian::Little)
    .add_module(module)
    .add_simple_annotation("simple", "info");

let dump = SynthMinidump::with_endian(Endian::Little).add_crashpad_info(crashpad_info);

// convert the synth minidump to binary and read it like a normal minidump
let dump = read_synth_dump(dump).unwrap();</pre>
<p>// Now check that the minidump reports the values we expect…</p>
<p>minidump-synth intentionally avoids sharing layout code with the actual implementation so that incorrect changes to layouts won&#8217;t &#8220;accidentally&#8221; pass tests.</p>
<p><em>A brief aside for some history</em>: this testing framework was started by the original lead on this project, <a href="https://twitter.com/TedMielczarek">Ted Mielczarek</a>. He started rust-minidump as a side project to learn Rust when 1.0 was released and just never had the time to finish it. Back then he was working at Mozilla and also a major contributor to Breakpad, which is why rust-minidump has a lot of similar design choices and terminology.</p>
<p>This case is no exception: our minidump-synth is a shameless copy of the <a href="https://chromium.googlesource.com/breakpad/breakpad/+/refs/heads/main/src/processor/synth_minidump.cc">synth-minidump utility in breakpad&#8217;s code</a>, which was originally written by our <em>other</em> coworker <a href="https://www.red-bean.com/~jimb/">Jim Blandy</a>. Jim is one of the only people in the world that I will actually admit writes really good tests and docs, so I am totally happy to blatantly copy his work here.</p>
<p>Since this was all a learning experiment, Ted was understandably less rigorous about testing than usual. This meant a lot of minidump-synth was unimplemented when I came along, which also meant lots of minidump features were completely untested. (He built an absolutely great skeleton, just hadn&#8217;t had the time to fill it all in!)</p>
<p>We spent <em>a lot</em> of time filling in more of minidump-synth&#8217;s implementation so we could write more tests and catch more issues, but this is <em>definitely</em> the weakest part of our tests. Some stuff was implemented before I got here, so I don&#8217;t even <em>know</em> what tests are missing!</p>
<p>This is a good argument for some code coverage checks, but it would probably come back with &#8220;wow you should write a lot more tests&#8221; and we would all look at it and go &#8220;wow we sure should&#8221; and then we would probably never get around to it, because there are <em>many</em> things we <em>should</em> do.</p>
<p>On the other hand, Sentry has been very useful in this regard because they already <em>have</em> a mature suite of tests full of weird corner cases they&#8217;ve built up over time, so they can easily identify things that really matter, know what the fix should roughly be, and can contribute pre-existing test cases!</p>
<h2><strong>Integration and Snapshot Tests</strong></h2>
<p>We tried our best to shore up coverage issues in our unit tests by adding more holistic tests. There&#8217;s a few checked in Real Minidumps that we have <a href="https://github.com/luser/rust-minidump/blob/40c3390f5705890f932f78b7db4fc02866e012b8/minidump-processor/tests/test_processor.rs">some integration tests for</a> to make sure we handle Real Inputs properly.</p>
<p>We even wrote a bunch of <a href="https://github.com/luser/rust-minidump/blob/40c3390f5705890f932f78b7db4fc02866e012b8/minidump-stackwalk/tests/test-minidump-stackwalk.rs">integration tests for the CLI application that snapshot its output</a> to confirm that we never <em>accidentally</em> change the results.</p>
<p>Part of the motivation for this is to ensure we don&#8217;t break the JSON output, which we also wrote a <a href="https://github.com/luser/rust-minidump/blob/40c3390f5705890f932f78b7db4fc02866e012b8/minidump-processor/json-schema.md">very detailed schema document for</a> and are trying to keep stable so people can actually rely on it while the actual implementation details are still in flux.</p>
<p>Yes, <a href="https://github.com/luser/rust-minidump/tree/master/minidump-stackwalk">minidump-stackwalk</a> is supposed to be stable and reasonable to use in production!</p>
<p>For our snapshot tests we use <a href="https://github.com/mitsuhiko/insta">insta</a>, which I think is fantastic and more people should use. All you need to do is assert_snapshot! any output you want to keep track of and it will magically take care of the storing, loading, and diffing.</p>
<p>Here&#8217;s one of the snapshot tests where we invoke the CLI interface and snapshot stdout:</p>
<pre>#[test]
fn test_evil_json() {
    // For a while this didn't parse right
    let bin = env!("CARGO_BIN_EXE_minidump-stackwalk");
    let output = Command::new(bin)
        .arg("--json")
        .arg("--pretty")
        .arg("--raw-json")
        .arg("../testdata/evil.json")
        .arg("../testdata/test.dmp")
        .arg("../testdata/symbols/")
        .stdout(Stdio::piped())
        .stderr(Stdio::piped())
        .output()
        .unwrap();

    let stdout = String::from_utf8(output.stdout).unwrap();
    let stderr = String::from_utf8(output.stderr).unwrap();

    assert!(output.status.success());
    insta::assert_snapshot!("json-pretty-evil-symbols", stdout);
    assert_eq!(stderr, "");
}

</pre>
<h2><b>Stackwalker Unit Testing</b></h2>
<p>The stackwalker is easily the most complicated and subtle part of the new implementation, because every platform can have <em>slight</em> quirks and you need to implement several different unwinding strategies and carefully tune everything to work well <em>in practice</em>.</p>
<p>The scariest part of this was the call frame information (CFI) unwinders, because they are basically little virtual machines we need to parse and execute at runtime. Thankfully breakpad had long ago smoothed over this issue by defining a simplified and unified CFI format, STACK CFI (well, nearly unified, x86 Windows was still a special case as STACK WIN). So even if DWARF CFI has a ton of complex features, we mostly need to implement a <a href="https://en.wikipedia.org/wiki/Reverse_Polish_notation">Reverse Polish Notation Calculator</a> except it can read registers and load memory from addresses it computes (and for STACK WIN it has access to named variables it can declare and mutate).</p>
<p>Unfortunately, <a href="https://chromium.googlesource.com/breakpad/breakpad/+/master/docs/symbol_files.md">Breakpad&#8217;s description for this format is pretty underspecified</a> so I had to basically pick some semantics I thought made sense and go with that. This made me <em>extremely</em> paranoid about the implementation. (And yes I will be more first-person for this part, because this part was genuinely where I personally spent most of my time and did a lot of stuff from scratch. All the blame belongs to me here!)</p>
<p>The<a href="https://docs.rs/breakpad-symbols/latest/breakpad_symbols/walker/index.html"> STACK WIN / STACK CFI parser+evaluator</a> is 1700 lines. 500 of those lines are a detailed documentation and discussion of the format, and 700 of those lines are an enormous pile of ~80 test cases where I tried to come up with every corner case I could think of.</p>
<p>I even checked in two tests I <em>knew</em> were failing just to be honest that there were a couple cases to fix! One of them is a corner case involving dividing by a negative number that almost certainly just doesn&#8217;t matter. The other is a buggy input that old x86 Microsoft toolchains actually produce and parsers need to deal with. The latter was fixed before the fuzzing started.</p>
<p>And 5225225 <em>still</em> found an integer overflow in the STACK WIN preprocessing step! (Not actually that surprising, it&#8217;s a hacky mess that tries to cover up for how messed up x86 Windows unwinding tables were.)</p>
<p>(The code isn&#8217;t terribly interesting here, it&#8217;s just a ton of assertions that a given input string produces a given output/error.)</p>
<p>Of course, I wasn&#8217;t satisfied with just coming up with my own semantics and testing them: I also <a href="https://github.com/luser/rust-minidump/blob/master/minidump-processor/src/stackwalker/x86_unittest.rs">ported most of breakpad&#8217;s own stackwalker tests to rust-minidump</a>! This definitely found a bunch of bugs I had, but also taught me some weird quirks in Breakpad&#8217;s stackwalkers that I&#8217;m not sure I <em>actually</em> agree with. But in this case I was flying so blind that even being bug-compatible with Breakpad was some kind of relief.</p>
<p>Those tests also included several tests for the non-CFI paths, which were similarly wobbly and quirky. I still really hate a lot of the weird platform-specific rules they have for stack scanning, but I&#8217;m forced to work on the assumption that they might be load-bearing. (I definitely had several cases where I disabled a breakpad test because it was &#8220;obviously nonsense&#8221; and then hit it in the wild while testing. I quickly learned to accept that <strong>Nonsense Happens And Cannot Be Ignored</strong>.)</p>
<p>One major thing I <em>didn&#8217;t</em> replicate was some of the really hairy hacks for STACK WIN. Like there are several places where they introduce extra stack-scanning to try to deal with the fact that stack frames can have mysterious extra alignment that the windows unwinding tables just don&#8217;t tell you about? I guess?</p>
<p>There&#8217;s almost certainly some exotic situations that rust-minidump does worse on because of this, but it probably also means we do better in some random other situations too. I never got the two to perfectly agree, but at some point the divergences were all in weird enough situations, and as far as I was concerned both stackwalkers were producing equally bad results in a bad situation. Absent any reason to prefer one over the other, divergence seemed acceptable to keep the implementation cleaner.</p>
<p>Here&#8217;s a simplified version of one of the ported breakpad tests, if you&#8217;re curious (thankfully minidump-synth is based off of the same binary data mocking framework these tests use):</p>
<pre>#[test]
fn test_x86_frame_pointer() {
    let mut f = TestFixture::new();
    let frame0_ebp = Label::new();
    let frame1_ebp = Label::new();
    let mut stack = Section::new();

    // Setup the stack and registers so frame pointers will work
    stack.start().set_const(0x80000000);
    stack = stack
        .append_repeated(12, 0) // frame 0: space
        .mark(&amp;frame0_ebp)      // frame 0 %ebp points here
        .D32(&amp;frame1_ebp)       // frame 0: saved %ebp
        .D32(0x40008679)        // frame 0: return address
        .append_repeated(8, 0)  // frame 1: space
        .mark(&amp;frame1_ebp)      // frame 1 %ebp points here
        .D32(0)                 // frame 1: saved %ebp (stack end)
        .D32(0);                // frame 1: return address (stack end)
    f.raw.eip = 0x4000c7a5;
    f.raw.esp = stack.start().value().unwrap() as u32;
    f.raw.ebp = frame0_ebp.value().unwrap() as u32;

    // Check the stackwalker's output:
    let s = f.walk_stack(stack).await;
    assert_eq!(s.frames.len(), 2);
    {
        let f0 = &amp;s.frames[0];
        assert_eq!(f0.trust, FrameTrust::Context);
        assert_eq!(f0.context.valid, MinidumpContextValidity::All);
        assert_eq!(f0.instruction, 0x4000c7a5);
    }
    {
        let f1 = &amp;s.frames[1];
        assert_eq!(f1.trust, FrameTrust::FramePointer);
        assert_eq!(f1.instruction, 0x40008678);
    }
}</pre>
<h2>A Dedicated Production Diffing, Simulating, and Debugging Tool</h2>
<p>Because minidumps are so horribly fractal and corner-casey, I spent <em>a lot</em> of time terrified of subtle issues that would become huge disasters if we ever actually tried to deploy to production. So I also spent a bunch of time building <a href="https://github.com/Gankra/socc-pair/">socc-pair</a>, which takes the id of a crash report from Mozilla&#8217;s <a href="https://crash-stats.mozilla.org/">crash reporting system</a> and pulls down the minidump, the old breakpad-based implementation&#8217;s output, and extra metadata.</p>
<p>It then runs a local rust-minidump (minidump-stackwalk) implementation on the minidump and does a domain-specific diff over the two inputs. The most substantial part of this is a fuzzy diff on the stackwalks that tries to better handle situations like when one implementation adds an extra frame but the two otherwise agree. It also uses the reported techniques each implementation used to try to identify whose output is more trustworthy when they totally diverge.</p>
<p>I also ended up adding a bunch of mocking and benchmarking functionality to it as well, as I found more and more places where I just wanted to simulate a production environment.</p>
<p>Oh also I added <a href="https://github.com/luser/rust-minidump/tree/master/minidump-stackwalk#debugging-stackwalking">really detailed trace-logging for the stackwalker</a> so that I could easily post-mortem debug why it made the decisions it made.</p>
<p>This tool found so many issues and more importantly has helped me quickly isolate their causes. I am so happy I made it. Because of it, we know we actually <em>fixed</em> several issues that happened with the old breakpad implementation, which is great!</p>
<p>Here&#8217;s a trimmed down version of the kind of report socc-pair would produce (yeah I abused diff syntax to get error highlighting. It&#8217;s a great hack, and I love it like a child):</p>
<pre>comparing json...

: {
    crash_info: {
        address: 0x7fff1760aca0
        crashing_thread: 8
        type: EXCEPTION_BREAKPOINT
    }
    crashing_thread: {
        frames: [
            0: {
                file: wrappers.cpp:1750da2d7f9db490b9d15b3ee696e89e6aa68cb7
                frame: 0
                function: RustMozCrash(char const*, int, char const*)
                function_offset: 0x00000010
-               did not match
+               line: 17
-               line: 20
                module: xul.dll

.....

    unloaded_modules: [
        0: {
            base_addr: 0x7fff48290000
-           local val was null instead of:
            code_id: 68798D2F9000
            end_addr: 0x7fff48299000
            filename: KBDUS.DLL
        }
        1: {
            base_addr: 0x7fff56020000
            code_id: DFD6E84B14000
            end_addr: 0x7fff56034000
            filename: resourcepolicyclient.dll
        }
    ]
~   ignoring field write_combine_size: "0"
}

- Total errors: 288, warnings: 39

benchmark results (ms):
    2388, 1986, 2268, 1989, 2353, 
    average runtime: 00m:02s:196ms (2196ms)
    median runtime: 00m:02s:268ms (2268ms)
    min runtime: 00m:01s:986ms (1986ms)
    max runtime: 00m:02s:388ms (2388ms)

max memory (rss) results (bytes):
    267755520, 261152768, 272441344, 276131840, 279134208, 
    average max-memory: 258MB (271323136 bytes)
    median max-memory: 259MB (272441344 bytes)
    min max-memory: 249MB (261152768 bytes)
    max max-memory: 266MB (279134208 bytes)

Output Files: 
    * (download) Minidump: b4f58e9f-49be-4ba5-a203-8ef160211027.dmp
    * (download) Socorro Processed Crash: b4f58e9f-49be-4ba5-a203-8ef160211027.json
    * (download) Raw JSON: b4f58e9f-49be-4ba5-a203-8ef160211027.raw.json
    * Local minidump-stackwalk Output: b4f58e9f-49be-4ba5-a203-8ef160211027.local.json
    * Local minidump-stackwalk Logs: b4f58e9f-49be-4ba5-a203-8ef160211027.log.txt</pre>
<h2><b>Staging and Deploying to Production</b></h2>
<p>Once we were confident enough in the implementation, a lot of the remaining testing was taken over by Will Kahn-Greene, who&#8217;s responsible for a lot of the server-side details of our crash-reporting infrastructure.</p>
<p>Will spent a bunch of time getting a bunch of machinery setup to manage the deployment and monitoring of rust-minidump. He also did a lot of the hard work of cleaning up all our server-side configuration scripts to handle any differences between the two implementations. (Although I spent a lot of time on compatibility, we both agreed this was a good opportunity to clean up old cruft and mistakes.)</p>
<p>Once all of this was set up, he turned it on in staging and we got our first look at how rust-minidump actually worked in ~production:</p>
<p><strong>Terribly!</strong></p>
<p>Our staging servers take in about 10% of the inputs that also go to our production servers, but even at that reduced scale we very quickly found several new corner cases and we were getting <em>tons</em> of crashes, which is mildly embarrassing for<em> the thing that handles other people&#8217;s crashes</em>.</p>
<p>Will did a great job here in monitoring and reporting the issues. Thankfully they were all fairly easy for us to fix. Eventually, everything smoothed out and things seemed to be working just as reliably as the old implementation on the production server. The only places where we were completely failing to produce any output were for horribly truncated minidumps that may as well have been empty files.</p>
<p>We originally <em>did</em> have some grand ambitions of running socc-pair on everything the staging servers processed or something to get <em>really</em> confident in the results. But by the time we got to that point, we were completely exhausted and feeling pretty confident in the new implementation.</p>
<p>Eventually Will just said &#8220;let&#8217;s turn it on in production&#8221; and I said &#8220;AAAAAAAAAAAAAAA&#8221;.</p>
<p>This moment was pure terror. There had always been <em>more</em> corner cases. There&#8217;s no way we could just be <em>done</em>. This will probably set all of Mozilla on fire and delete Firefox from the internet!</p>
<p>But Will convinced me. We wrote up some docs detailing all the subtle differences and sent them to everyone we could. Then the moment of truth finally came: Will turned it on in production, and I got to really see how well it worked in production:</p>
<p><em>*dramatic drum roll*</em></p>
<p>It worked fine.</p>
<p>After all that stress and anxiety, we turned it on and it was <em>fine</em>.</p>
<p>Heck, I&#8217;ll say it: it ran <em>well</em>.</p>
<p>It was faster, it crashed less, and we even knew it fixed some issues.</p>
<p>I was in a bit of a stupor for the rest of that week, because I kept waiting for the other shoe to drop. I kept waiting for someone to emerge from the mist and explain that I had somehow bricked <em>Thunderbird</em> or something. But no, it just worked.</p>
<p>So we left for the holidays, and I kept waiting for it to break, but it was <em>still fine</em>.</p>
<p>I am honestly still shocked about this!</p>
<p>But hey, as it turns out we really did put a <em>lot</em> of careful work into testing the implementation. At every step we found new problems but that was <em>good</em>, because once we got to the final step there were no more problems to surprise us.</p>
<p><strong>And the fuzzer still kicked our butts afterwards.</strong></p>
<p>But that&#8217;s part 2! Thanks for reading!</p>
<p>&nbsp;</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/everything-is-broken-shipping-rust-minidump-at-mozilla/">Everything Is Broken: Shipping rust-minidump at Mozilla &#8211; Part 1</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://hacks.mozilla.org/2022/06/everything-is-broken-shipping-rust-minidump-at-mozilla/feed/</wfw:commentRss>
			<slash:comments>1</slash:comments>
		
		
			</item>
		<item>
		<title>Training efficient neural network models for Firefox Translations</title>
		<link>https://hacks.mozilla.org/2022/06/training-efficient-neural-network-models-for-firefox-translations/</link>
		
		<dc:creator><![CDATA[Evgeny Pavlov]]></dc:creator>
		<pubDate>Tue, 07 Jun 2022 15:25:47 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[Machine Translation]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[nmt]]></category>
		<category><![CDATA[Translations]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47809</guid>

					<description><![CDATA[<p>The Bergamot project is a collaboration between Mozilla, University of Edinburgh, Charles University in Prague, the University of Sheffield, and University of Tartu with funding from the European Union’s Horizon 2020 research and innovation programme. It brings MT to the local environment, providing small, high-quality, CPU optimized NMT models. The Firefox Translations web extension utilizes proceedings of project Bergamot and brings local translations to Firefox. In this article, we will discuss the components used to train our efficient NMT models.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/training-efficient-neural-network-models-for-firefox-translations/">Training efficient neural network models for Firefox Translations</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<p>Machine Translation is an important tool for expanding the accessibility of web content. Usually, people use cloud providers to translate web pages. State-of-the-art Neural Machine Translation (NMT) models are large and often require specialized hardware like GPUs to run inference in real-time.</p>
<p>If people were able to run a compact Machine Translation (MT) model on their local machine CPU without sacrificing translation accuracy it would help to preserve privacy and reduce costs.</p>
<p>The Bergamot <a href="https://browser.mt/" target="_blank" rel="noopener">project</a> is a collaboration between Mozilla, the University of Edinburgh, Charles University in Prague, the University of Sheffield, and the University of Tartu with funding from the European Union’s Horizon 2020 research and innovation programme. It brings MT to the local environment, providing small, high-quality, CPU optimized NMT models. <a href="https://github.com/mozilla/firefox-translations" target="_blank" rel="noopener">The Firefox Translations web extension</a> utilizes proceedings of project Bergamot and brings local translations to Firefox.</p>
<p>In this article, we will discuss the components used to train our efficient NMT models. The project is open-source, so you can give it a try and train your model too!</p>
<h2><b>Architecture</b></h2>
<p>NMT models are trained as language pairs, translating from language A to language B. The <a href="https://github.com/mozilla/firefox-translations-training" target="_blank" rel="noopener">training pipeline</a> was designed to train translation models for a language pair end-to-end, from environment configuration to exporting the ready-to-use models. The pipeline run is completely reproducible given the same code, hardware and configuration files.</p>
<p>The complexity of the pipeline comes from the requirement to produce an efficient model. We use Teacher-Student distillation to compress a high-quality but resource-intensive teacher model into an efficient CPU-optimized student model that still has good translation quality. We explain this further in the Compression section.</p>
<p>The pipeline includes many steps: compiling of components, downloading and cleaning datasets, training teacher, student and backward models, decoding, quantization, evaluation etc (more details below). The pipeline can be represented as a Directly Acyclic Graph (DAG).</p>
<p>&nbsp;</p>
<p><img decoding="async" loading="lazy" class="aligncenter wp-image-47810" src="https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-5.20.04-PM-500x246.png" alt="Firfox Translation training pipeline DAG" width="591" height="291" srcset="https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-5.20.04-PM-500x246.png 500w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-5.20.04-PM-250x123.png 250w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-5.20.04-PM-768x379.png 768w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-5.20.04-PM-1536x757.png 1536w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-5.20.04-PM-2048x1009.png 2048w" sizes="(max-width: 591px) 100vw, 591px" /></p>
<p>The workflow is file-based and employs self-sufficient scripts that use data on disk as input, and write intermediate and output results back to disk.</p>
<p>We use the Marian Neural Machine Translation engine. It is written in C++ and designed to be fast. The engine is open-sourced and used by many universities and companies, including Microsoft.</p>
<h2><b>Training a quality model</b></h2>
<p>The first task of the pipeline is to train a high-quality model that will be compressed later. The main challenge at this stage is to find a good parallel corpus that contains translations of the same sentences in both source and target languages and then apply appropriate cleaning procedures.</p>
<h3><b>Datasets</b></h3>
<p>It turned out there are many open-source parallel datasets for machine translation available on the internet. The most interesting project that aggregates such datasets is <a href="https://opus.nlpl.eu/" target="_blank" rel="noopener">OPUS</a>. The Annual Conference on Machine Translation also collects and distributes some datasets for competitions, for example, <a href="https://www.statmt.org/wmt21/translation-task.html#download" target="_blank" rel="noopener">WMT21 Machine Translation of News</a>. Another great source of MT corpus is the <a href="https://paracrawl.eu/" target="_blank" rel="noopener">Paracrawl</a> project.</p>
<p>OPUS dataset search interface:</p>
<p><img decoding="async" loading="lazy" class="aligncenter wp-image-47814" src="https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-6.04.13-PM-500x403.png" alt="OPUS dataset search interface" width="591" height="476" srcset="https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-6.04.13-PM-500x403.png 500w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-6.04.13-PM-250x202.png 250w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-6.04.13-PM-768x619.png 768w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-6.04.13-PM-1536x1238.png 1536w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-20-at-6.04.13-PM.png 1992w" sizes="(max-width: 591px) 100vw, 591px" /></p>
<p>It is possible to use any dataset on disk, but automating dataset downloading from Open source resources makes adding new language pairs easy, and whenever the data set is expanded we can then easily retrain the model to take advantage of the additional data. Make sure to check the licenses of the open-source datasets before usage.</p>
<h3><b>Data cleaning</b></h3>
<p>Most open-source datasets are somewhat noisy. Good examples are crawled websites and translation of subtitles. Texts from websites can be poor-quality automatic translations or contain unexpected HTML, and subtitles are often free-form translations that change the meaning of the text.</p>
<p>It is well known in the world of Machine Learning (ML) that if we feed garbage into the model we get garbage as a result. Dataset cleaning is probably the most crucial step in the pipeline to achieving good quality.</p>
<p>We employ some basic cleaning techniques that work for most datasets like removing too short or too long sentences and filtering the ones with an unrealistic source to target length ratio. We also use <a href="https://github.com/bitextor/bicleaner" target="_blank" rel="noopener">bicleaner</a>, a pre-trained ML classifier that attempts to indicate whether the training example in a dataset is a reversible translation. We can then remove low-scoring translation pairs that may be incorrect or otherwise add unwanted noise.</p>
<p>Automation is necessary when your training set is large. However, it is always recommended to look at your data manually in order to tune the cleaning thresholds and add dataset-specific fixes to get the best quality.</p>
<h3><b>Data augmentation</b></h3>
<p>There are more than 7000 languages spoken in the world and most of them are classified as low-resource for our purposes, meaning there is little parallel corpus data available for training. In these cases, we use a popular data augmentation strategy called back-translation.</p>
<p>Back-translation is a technique to increase the amount of training data available by adding synthetic translations. We get these synthetic examples by training a translation model from the target language to the source language. Then we use it to translate monolingual data from the target language into the source language, creating synthetic examples that are added to the training data for the model we actually want, from the source language to the target language.</p>
<h3><b>The model</b></h3>
<p>Finally, when we have a clean parallel corpus we train a big transformer model to reach the best quality we can.</p>
<p>Once the model converges on the augmented dataset, we fine-tune it on the original parallel corpus that doesn’t include synthetic examples from back-translation to further improve quality.</p>
<h2><b>Compression</b></h2>
<p>The trained model can be 800Mb or more in size depending on configuration and requires significant computing power to perform translation (decoding). At this point, it’s generally executed on GPUs and not practical to run on most consumer laptops. In the next steps we will prepare a model that works efficiently on consumer CPUs.</p>
<h3><b>Knowledge distillation</b></h3>
<p>The main technique we use for compression is Teacher-Student Knowledge Distillation. The idea is to decode a lot of text from the source language into the target language using the heavy model we trained (Teacher) and then train a much smaller model with fewer parameters (Student) on these synthetic translations. The student is supposed to imitate the teacher’s behavior and demonstrate similar translation quality despite being significantly faster and more compact.</p>
<p>We also augment the parallel corpus data with monolingual data in the source language for decoding. This improves the student by providing additional training examples of the teacher&#8217;s behavior.</p>
<h3><b>Ensemble</b></h3>
<p>Another trick is to use not just one teacher but an ensemble of 2-4 teachers independently trained on the same parallel corpus. It can boost quality a little bit at the cost of having to train more teachers. The pipeline supports training and decoding with an ensemble of teachers.</p>
<h3><b>Quantization</b></h3>
<p>One more popular technique for model compression is quantization. We use 8-bit quantization which essentially means that we store weights of the neural net as int8 instead of float32. It saves space and speeds up matrix multiplication on inference.</p>
<h3><b>Other tricks</b></h3>
<p>Other features worth mentioning but beyond the scope of this already lengthy article are the specialized Neural Network architecture of the student model, half-precision decoding by the teacher model to speed it up, lexical shortlists, training of word alignments, and finetuning of the quantized student.</p>
<p>Yes, it’s a lot! Now you can see why we wanted to have an end-to-end pipeline.</p>
<h2><b>How to learn more</b></h2>
<p>This work is based on a lot of research. If you are interested in the science behind the training pipeline, check out reference publications listed <a href="https://github.com/mozilla/firefox-translations-training#references" target="_blank" rel="noopener">in the training pipeline repository README</a> and <a href="https://browser.mt/publications" target="_blank" rel="noopener">across the wider Bergamot project</a>. <a href="https://aclanthology.org/2020.ngt-1.26/" target="_blank" rel="noopener">Edinburgh&#8217;s Submissions to the 2020 Machine Translation Efficiency Task</a> is a good academic starting article. Check <a href="https://nbogoychev.com/efficient-machine-translation/" target="_blank" rel="noopener">this tutorial</a> by Nikolay Bogoychev for a more practical and operational explanation of the steps.</p>
<h2><b>Results</b></h2>
<p>The final student model is 47 times smaller and 37 times faster than the original teacher model and has only a small quality decrease!</p>
<p>Benchmarks for en-pt model and Flores dataset:</p>
<table style="table-layout: fixed; width: 100%;">
<tbody>
<tr>
<td><b>Model</b></td>
<td><b>Size</b></td>
<td><b>Total number of parameters</b></td>
<td><b>Dataset decoding time on 1 CPU core</b></td>
<td><b>Quality, BLEU</b></td>
</tr>
<tr>
<td>Teacher</td>
<td>798Mb</td>
<td>192.75M</td>
<td>631s</td>
<td>52.5</td>
</tr>
<tr>
<td>Student quantized</td>
<td>17Mb</td>
<td>15.7M</td>
<td>17.9s</td>
<td>50.7</td>
</tr>
</tbody>
</table>
<p>We evaluate results using MT standard <a href="https://en.wikipedia.org/wiki/BLEU" target="_blank" rel="noopener">BLEU scores</a> that essentially represent how similar translated and reference texts are. This method is not perfect but it has been shown that BLEU scores correlate well with human judgment of translation quality.</p>
<p>We have a <a href="https://github.com/mozilla/firefox-translations-models" target="_blank" rel="noopener">GitHub repository</a> with all the trained models and <a href="https://github.com/mozilla/firefox-translations-models/blob/main/evaluation/prod/results.md" target="_blank" rel="noopener">evaluation results</a> where we compare the accuracy of our models to popular APIs of cloud providers. We can see that some models perform similarly, or even outperform, the cloud providers which is a great result taking into account our model’s efficiency, reproducibility and open-source nature.</p>
<p>For example, here you can see evaluation results for the English to Portuguese model trained by Mozilla using open-source data only.</p>
<p><img decoding="async" loading="lazy" class="alignnone wp-image-47818" src="https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-22-at-1.28.56-PM.png" alt="Evaluation results en-pt" width="591" height="476" srcset="https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-22-at-1.28.56-PM.png 2066w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-22-at-1.28.56-PM-250x201.png 250w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-22-at-1.28.56-PM-500x403.png 500w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-22-at-1.28.56-PM-768x619.png 768w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-22-at-1.28.56-PM-1536x1237.png 1536w, https://hacks.mozilla.org/files/2022/04/Screen-Shot-2022-04-22-at-1.28.56-PM-2048x1650.png 2048w" sizes="(max-width: 591px) 100vw, 591px" /></p>
<p>Anyone can train models and contribute them to our repo. Those contributions can be used in the <a href="https://github.com/mozilla/firefox-translations" target="_blank" rel="noopener">Firefox Translations web extension</a> and other places (see below).</p>
<h2><b>Scaling</b></h2>
<p>It is of course possible to run the whole pipeline on one machine, though it may take a while. Some steps of the pipeline are CPU bound and difficult to parallelize, while other steps can be offloaded to multiple GPUs. Most of the official models in the repository were trained on machines with 8 GPUs. A few steps, like teacher decoding during knowledge distillation, can take days even on well-resourced single machines. So to speed things up, we added cluster support to be able to spread different steps of the pipeline over multiple nodes.</p>
<h3><b>Workflow manager</b></h3>
<p>To manage this complexity we chose <a href="https://snakemake.github.io/" target="_blank" rel="noopener">Snakemake</a> which is very popular in the bioinformatics community. It uses file-based workflows, allows specifying step dependencies in Python, supports containerization and integration with different cluster software. We considered alternative solutions that focus on job scheduling, but ultimately chose Snakemake because it was more ergonomic for one-run experimentation workflows.</p>
<p>Example of a Snakemake rule (dependencies between rules are inferred implicitly):</p>
<pre><code class="js">rule train_teacher:
    message: "Training teacher on all data"
    log: f"{log_dir}/train_teacher{{ens}}.log"
    conda: "envs/base.yml"
    threads: gpus_num*2
    resources: gpu=gpus_num
    input:
        rules.merge_devset.output, 
        train_src=f'{teacher_corpus}.{src}.gz',
        train_trg=f'{teacher_corpus}.{trg}.gz',
        bin=ancient(trainer), 
        vocab=vocab_path
    output: model=f'{teacher_base_dir}{{ens}}/{best_model}'
    params: 
        prefix_train=teacher_corpus, 
        prefix_test=f"{original}/devset", 
        dir=directory(f'{teacher_base_dir}{{ens}}'),
        args=get_args("training-teacher-base")
    shell: '''bash pipeline/train/train.sh \
                teacher train {src} {trg} "{params.prefix_train}" \
                "{params.prefix_test}" "{params.dir}" \
                "{input.vocab}" {params.args} &gt;&gt; {log} 2&gt;&amp;1'''</code></pre>
<h3><b>Cluster support</b></h3>
<p>To parallelize workflow steps across cluster nodes we use <a href="https://slurm.schedmd.com/">Slurm</a> resource manager. It is relatively simple to operate, fits well for high-performance experimentation workflows, and supports Singularity containers for easier reproducibility. Slurm is also the most popular cluster manager for High-Performance Computers (HPC) used for model training in academia, and most of the consortium partners were already using or familiar with it.</p>
<h2><b>How to start training</b></h2>
<p>The workflow is quite resource-intensive, so you’ll need a pretty good server machine or even a cluster. We recommend using 4-8 Nvidia 2080-equivalent or better GPUs per machine.</p>
<p>Clone <a href="https://github.com/mozilla/firefox-translations-training" target="_blank" rel="noopener">https://github.com/mozilla/firefox-translations-training</a> and follow the instructions in the <a href="https://github.com/mozilla/firefox-translations-training/blob/main/README.md" target="_blank" rel="noopener">readme</a> for configuration.</p>
<p>The most important part is to find parallel datasets and properly configure settings based on your available data and hardware. You can learn more about this in the readme.</p>
<h2><b>How to use the existing models</b></h2>
<p>The existing models are shipped with the <a href="https://github.com/mozilla/firefox-translations" target="_blank" rel="noopener">Firefox Translations web extension</a>, enabling users to translate web pages in Firefox. The models are downloaded to a local machine on demand. The web extension uses these models with the<a href="https://github.com/browsermt/bergamot-translator" target="_blank" rel="noopener"> bergamot-translator</a> Marian wrapper compiled to Web Assembly.</p>
<p>Also, there is a playground website at <a href="https://mozilla.github.io/translate" target="_blank" rel="noopener">https://mozilla.github.io/translate</a> where you can input text and translate it right away, also locally but served as a static website instead of a browser extension.</p>
<p>If you are interested in an efficient NMT inference on the server, you can try a prototype <a href="https://github.com/mozilla/translation-service" target="_blank" rel="noopener">HTTP service</a> that uses bergamot-translator natively compiled, instead of compiled to WASM.</p>
<p>Or follow the build instructions in the <a href="https://github.com/browsermt/bergamot-translator#build-instructions" target="_blank" rel="noopener">bergamot-translator readme</a> to directly use the C++, JavaScript WASM, or Python bindings.</p>
<h2><b>Conclusion</b></h2>
<p>It is fascinating how far Machine Translation research has come in recent years. Local high-quality translations are the future and it’s becoming more and more practical for companies and researchers to train such models even without access to proprietary data or large-scale computing power.</p>
<p>We hope that <a href="https://github.com/mozilla/firefox-translations" target="_blank" rel="noopener">Firefox Translations</a> will set a new standard of privacy-preserving, efficient, open-source machine translation accessible for all.</p>
<h2><b>Acknowledgements</b></h2>
<p>I would like to thank all the participants of <a href="https://browser.mt/" target="_blank" rel="noopener">the Bergamot Project</a> for making this technology possible, my teammates Andre Natal and Abhishek Aggarwal for the incredible work they have done bringing Firefox Translations to life, Lonnen for managing the project and editing this blog post and of course awesome Mozilla community for helping with localization of the web-extension and testing its early builds.</p>
<p><i>This project has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 825303 <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f1ea-1f1fa.png" alt="🇪🇺" class="wp-smiley" style="height: 1em; max-height: 1em;" /></i></p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/06/training-efficient-neural-network-models-for-firefox-translations/">Training efficient neural network models for Firefox Translations</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Improved Process Isolation in Firefox 100</title>
		<link>https://hacks.mozilla.org/2022/05/improved-process-isolation-in-firefox-100/</link>
					<comments>https://hacks.mozilla.org/2022/05/improved-process-isolation-in-firefox-100/#comments</comments>
		
		<dc:creator><![CDATA[Gian-Carlo Pascutto]]></dc:creator>
		<pubDate>Thu, 12 May 2022 15:09:10 +0000</pubDate>
				<category><![CDATA[Featured Article]]></category>
		<category><![CDATA[Firefox]]></category>
		<category><![CDATA[Firefox OS]]></category>
		<category><![CDATA[HTML]]></category>
		<category><![CDATA[JavaScript]]></category>
		<category><![CDATA[api]]></category>
		<category><![CDATA[css]]></category>
		<category><![CDATA[firefox]]></category>
		<category><![CDATA[site isolation]]></category>
		<guid isPermaLink="false">https://hacks.mozilla.org/?p=47829</guid>

					<description><![CDATA[<p>Firefox uses a multi-process model for additional security and stability while browsing: Web Content (such as HTML/CSS and Javascript) is rendered in separate processes that are isolated from the rest of the operating system and managed by a privileged parent process. This way, the amount of control gained by an attacker that exploits a bug in a content process is limited. In this article, we would like to dive a bit further into the latest major milestone we have reached: Win32k Lockdown, which greatly reduces the capabilities of the content process when running on Windows.</p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/05/improved-process-isolation-in-firefox-100/">Improved Process Isolation in Firefox 100</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></description>
										<content:encoded><![CDATA[<h2><strong>Introduction</strong></h2>
<p><span style="font-weight: 400;">Firefox uses a </span><a href="https://hacks.mozilla.org/2021/05/introducing-firefox-new-site-isolation-security-architecture/"><span style="font-weight: 400;">multi-process model</span></a><span style="font-weight: 400;"> for additional security and stability while browsing: Web Content (such as HTML/CSS and Javascript) is rendered in separate processes that are isolated from the rest of the operating system and managed by a privileged parent process. This way, the amount of control gained by an attacker that exploits a bug in a content process is limited. </span></p>
<p><span style="font-weight: 400;">Ever since we deployed this model, we have been working on improving the isolation of the content processes to further limit the attack surface. This is a challenging task since content processes need access to some operating system APIs to properly function: for example, they still need to be able to talk to the parent process. </span></p>
<p><span style="font-weight: 400;">In this article, we would like to dive a bit further into the latest major milestone we have reached: </span><i><span style="font-weight: 400;">Win32k Lockdown,</span></i><span style="font-weight: 400;"> which greatly reduces the capabilities of the content process when running on Windows. Together with two major earlier efforts (</span><a href="https://hacks.mozilla.org/2021/05/introducing-firefox-new-site-isolation-security-architecture/"><span style="font-weight: 400;">Fission</span></a><span style="font-weight: 400;"> and </span><a href="https://hacks.mozilla.org/2021/12/webassembly-and-back-again-fine-grained-sandboxing-in-firefox-95/"><span style="font-weight: 400;">RLBox</span></a><span style="font-weight: 400;">) that shipped before, this completes a sequence of large leaps forward that will significantly improve Firefox&#8217;s security.</span></p>
<p><span style="font-weight: 400;">Although </span><i><span style="font-weight: 400;">Win32k Lockdown</span></i><span style="font-weight: 400;"> is a Windows-specific technique, it became possible because of a significant re-architecting of the Firefox security boundaries that Mozilla has been working on for around four years, which allowed similar security advances to be made on other operating systems.</span></p>
<h2><strong>The Goal: Win32k Lockdown</strong></h2>
<p><span style="font-weight: 400;">Firefox runs the processes that render web content with quite a few restrictions on what they are allowed to do when running on Windows. Unfortunately, by default they still have access to the entire Windows API, which opens up a large attack surface: the Windows API consists of many parts, for example, a core part dealing with threads, processes, and memory management, but also networking and socket libraries, printing and multimedia APIs, and so on.</span></p>
<p><span style="font-weight: 400;">Of particular interest for us is the </span><i><span style="font-weight: 400;">win32k.sys API,</span></i><span style="font-weight: 400;"> which includes many graphical and widget related system calls that have a history of being exploitable. Going back further in Windows&#8217; origins, this situation is likely the result of Microsoft moving many operations that were originally running in user mode into the kernel in order to improve performance around the Windows 95 and NT4 timeframe. </span></p>
<p><span style="font-weight: 400;">Having likely never been originally designed to run in this sensitive context, these APIs have been a traditional target for hackers to break out of application sandboxes and into the kernel.</span></p>
<p><span style="font-weight: 400;">In Windows 8, Microsoft introduced a new mitigation named </span><a href="https://docs.microsoft.com/en-us/windows/win32/api/winnt/ns-winnt-process_mitigation_system_call_disable_policy"><span style="font-weight: 400;">PROCESS_MITIGATION_SYSTEM_CALL_DISABLE_POLICY</span></a><span style="font-weight: 400;"> that an application can use to disable access to win32k.sys system calls. That is a long name to keep repeating, so we&#8217;ll refer to it hereafter by our internal designation: &#8220;</span><i><span style="font-weight: 400;">Win32k Lockdown</span></i><span style="font-weight: 400;">&#8220;.</span></p>
<h2><strong>The Work Required</strong></h2>
<p><span style="font-weight: 400;">Flipping the Win32k Lockdown flag on the Web Content processes &#8211; the processes most vulnerable to potentially hostile web pages and JavaScript &#8211; means that those processes can no longer perform any graphical, window management, input processing, etc. operations themselves. </span></p>
<p><span style="font-weight: 400;">To accomplish these tasks, such operations must be remoted to a process that has the necessary permissions, typically the process that has access to the GPU and handles compositing and drawing (hereafter called the GPU Process), or the privileged parent process. </span></p>
<h3><span style="font-weight: 400;">Drawing web pages: WebRender</span></h3>
<p><span style="font-weight: 400;">For painting the web pages&#8217; contents, Firefox historically used various methods for interacting with the Windows APIs, ranging from using modern Direct3D based textures, to falling back to GDI surfaces, and eventually dropping into pure software mode. </span></p>
<p><span style="font-weight: 400;">These different options would have taken quite some work to remote, as most of the graphics API is off limits in Win32k Lockdown. The good news is that as of Firefox 92, our rendering stack has switched to </span><a href="https://hacks.mozilla.org/2017/10/the-whole-web-at-maximum-fps-how-webrender-gets-rid-of-jank/"><span style="font-weight: 400;">WebRender</span></a><span style="font-weight: 400;">, which moves all the actual drawing from the content processes to WebRender in the GPU Process.</span></p>
<p><span style="font-weight: 400;">Because with WebRender the content process no longer has a need to directly interact with the platform drawing APIs, this avoids any Win32k Lockdown related problems. WebRender itself has been designed partially to be </span><a href="https://github.com/servo/webrender/wiki/"><span style="font-weight: 400;">more similar to game engines, and thus, be less susceptible to driver bugs</span></a><span style="font-weight: 400;">. </span></p>
<p><span style="font-weight: 400;">For the remaining drivers that are just too broken to be of any use, it still has a </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1601053"><span style="font-weight: 400;">fully software-based mode</span></a><span style="font-weight: 400;">, which means we have no further fallbacks to consider.</span></p>
<h3><span style="font-weight: 400;">Webpages drawing: Canvas 2D and WebGL 3D</span></h3>
<p><span style="font-weight: 400;">The </span><a href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API"><span style="font-weight: 400;">Canvas API</span></a><span style="font-weight: 400;"> provides web pages with the ability to draw 2D graphics. In the original Firefox implementation, these JavaScript APIs were executed in the Web Content processes and the calls to the Windows drawing APIs were made directly from the same processes. </span></p>
<p><span style="font-weight: 400;">In a Win32k Lockdown scenario, this is no longer possible, so </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1464032"><span style="font-weight: 400;">all drawing commands are remoted</span></a><span style="font-weight: 400;"> by recording and playing them back in the GPU process over IPC.</span></p>
<p><span style="font-weight: 400;">Although the initial implementation had good performance, there were nevertheless reports from some sites that experienced performance regressions (the web sites that became faster generally didn&#8217;t complain!). A particular pain point are applications that call </span><a href="https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/getImageData"><span style="font-weight: 400;">getImageData()</span></a><span style="font-weight: 400;"> repeatedly: having the Canvas remoted means that GPU textures must now be obtained from another process and sent over IPC. </span></p>
<p><span style="font-weight: 400;">We compensated for this in the scenario where getImageData is called at the start of a frame, by detecting this and preparing the right surfaces proactively to make the copying from the GPU faster.</span></p>
<p><span style="font-weight: 400;">Besides the Canvas API to draw 2D graphics, the web platform also exposes an </span><a href="https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API"><span style="font-weight: 400;">API to do 3D drawing, called WebGL</span></a><span style="font-weight: 400;">. WebGL is a state-heavy API, so properly and efficiently synchronizing child and parent (as well as parent and driver) takes </span><a href="https://phabricator.services.mozilla.com/D54019"><span style="font-weight: 400;">great</span></a> <a href="https://phabricator.services.mozilla.com/D54019"><span style="font-weight: 400;">care</span></a><span style="font-weight: 400;">. </span></p>
<p><span style="font-weight: 400;">WebGL originally handled all validation in Content, but with access to the GPU and the associated attack surface removed from there, we needed to craft a robust validating API between child and parent as well to get the full security benefit.</span></p>
<h3><span style="font-weight: 400;">(Non-)Native Theming for Forms</span></h3>
<p><span style="font-weight: 400;">HTML web pages have the ability to display form controls. While the overwhelming majority of websites provide a </span><a href="https://developer.mozilla.org/en-US/docs/Learn/Forms/Advanced_form_styling"><span style="font-weight: 400;">custom look and styling for those form controls</span></a><span style="font-weight: 400;">, not all of them do, and if they do not you get an input GUI widget that is styled like (and originally was!) a </span><a href="http://stephenhorlander.com/form-controls.html"><span style="font-weight: 400;">native element of the operating system</span></a><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;"> Historically, these were drawn by calling the appropriate OS widget APIs from within the content process, but those are not available under Win32k Lockdown. </span></p>
<p><span style="font-weight: 400;">This cannot easily be fixed by remoting the calls, as the widgets themselves come in an infinite amount of sizes, shapes, and styles can be interacted with, and need to be responsive to user input and dispatch messages. We settled on having Firefox </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1381938"><span style="font-weight: 400;">draw the form controls itself</span></a><span style="font-weight: 400;">, in a cross-platform style. </span></p>
<p><span style="font-weight: 400;">While changing the look of form controls has web compatibility implications, and some people prefer the more native look &#8211; on the few pages that don&#8217;t apply their own styles to controls &#8211; Firefox’s approach is consistent with that taken by other browsers, probably because of very similar considerations.</span></p>
<p><span style="font-weight: 400;">Scrollbars were a particular pain point: we didn&#8217;t want to draw the main scrollbar of the content window in a different manner as the rest of the UX, since nested scrollbars would show up with different styles which would look awkward. But, unlike the rather rare non-styled form widgets, the main scrollbar is visible on most web pages, and because it conceptually belongs to the browser UX we really wanted it to look native. </span></p>
<p><span style="font-weight: 400;">We, therefore, decided to draw all scrollbars to match the system theme, although it&#8217;s a bit of an open question though how things should look if even </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1719427#c3"><span style="font-weight: 400;">the vendor of the operating system can&#8217;t seem to decide what the &#8220;native&#8221; look is</span></a><span style="font-weight: 400;">.</span></p>
<h2><strong>Final Hurdles</strong></h2>
<h3><span style="font-weight: 400;">Line Breaking</span></h3>
<p><span style="font-weight: 400;">With the above changes, we thought we had all the usual suspects that would access graphics and widget APIs in win32k.sys wrapped up, so we started running the full Firefox test suite with win32k syscalls disabled. This caused at least one unexpected failure: Firefox was </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1713973"><span style="font-weight: 400;">crashing when trying to find line breaks</span></a><span style="font-weight: 400;"> for some languages with complex scripts. </span></p>
<p><span style="font-weight: 400;">While Firefox is able to correctly determine word endings in multibyte character streams for most languages by itself, the support for Thai, Lao, Tibetan and Khmer is known to be imperfect, and </span><a href="https://searchfox.org/mozilla-central/rev/80f11ac5d938f6fce255c56279f46f13a49ea5c3/intl/lwbrk/LineBreaker.h#65"><span style="font-weight: 400;">in these cases, Firefox can ask the operating system to handle the line breaking</span></a><span style="font-weight: 400;"> for it. But at least on Windows, the functions to do so are covered by the Win32k Lockdown switch. Oops!</span></p>
<p><span style="font-weight: 400;">There are </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1684927"><span style="font-weight: 400;">efforts underway to incorporate ICU4X</span></a><span style="font-weight: 400;"> and base all i18n related functionality on that, meaning that Firefox will be able to handle all scripts perfectly without involving the OS, but this is a major effort and it was not clear if it would end up delaying the rollout of win32k lockdown. </span></p>
<p><span style="font-weight: 400;">We did some experimentation with trying to forward the line breaking over IPC. Initially, this had bad performance, but when we </span><a href="https://phabricator.services.mozilla.com/D129125"><span style="font-weight: 400;">added caching</span></a><span style="font-weight: 400;"> performance was satisfactory or sometimes even improved, since OS calls could be avoided in many cases now.</span></p>
<h3><span style="font-weight: 400;">DLL Loading &amp; Third Party Interactions</span></h3>
<p><span style="font-weight: 400;">Another complexity of disabling win32k.sys access is that so much Windows functionality assumes it is available by default, and specific effort must be taken to ensure the relevant DLLs do not get loaded on startup. Firefox itself for example won&#8217;t load the user32 DLL containing some win32k APIs, but </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1719212"><span style="font-weight: 400;">injected third party DLLs sometimes do</span></a><span style="font-weight: 400;">. This causes problems because </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1751367"><span style="font-weight: 400;">COM initialization in particular uses win32k calls to get the Window Station and Desktop</span></a><span style="font-weight: 400;"> if the DLL is present. Those calls will fail with Win32k Lockdown enabled, silently breaking COM and features that depend on it such as our accessibility support. </span></p>
<p><span style="font-weight: 400;">On Windows 10 Fall Creators Update and later we have a fix that blocks these calls and forces a fallback, which keeps everything working nicely. We measured that </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1750742#c9"><span style="font-weight: 400;">not loading the DLLs causes about a 15% performance gain</span></a><span style="font-weight: 400;"> when opening new tabs, adding a nice performance bonus on top of the security benefit.</span></p>
<h3><span style="font-weight: 400;">Remaining Work</span></h3>
<p><span style="font-weight: 400;">As hinted in the previous section, Win32k Lockdown will initially roll out on Windows 10 Fall Creators Update and later. On Windows 8, and unpatched Windows 10 (which unfortunately seems to be in use!), we are still testing a fix for the case where third party DLLs interfere, so support for those will come in a </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1759167#c7"><span style="font-weight: 400;">future release</span></a><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">For Canvas 2D support, we&#8217;re still </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1766402"><span style="font-weight: 400;">looking into improving the performance of applications</span></a><span style="font-weight: 400;"> that regressed when the processes were switched around. Simultaneously, there is experimentation underway to see if hardware acceleration for </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1739448"><span style="font-weight: 400;">Canvas 2D can be implemented through WebGL</span></a><span style="font-weight: 400;">, which would increase code sharing between the 2D and 3D implementations and take advantage of modern video drivers being better optimized for the 3D case.</span></p>
<h2><strong>Conclusion</strong></h2>
<p><span style="font-weight: 400;">Retrofitting a significant change in the separation of responsibilities in a large application like Firefox presents a large, multi-year engineering challenge, but it is absolutely required in order to advance browser security and to continue keeping our users safe. We&#8217;re pleased to have made it through and present you with the result in Firefox 100.</span></p>
<h3><span style="font-weight: 400;">Other Platforms</span></h3>
<p><span style="font-weight: 400;">If you&#8217;re a Mac user, you might wonder if there’s anything similar to Win32k Lockdown that can be done for macOS. You&#8217;d be right, and I have good news for you: we already quietly </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1467758"><span style="font-weight: 400;">shipped the changes that block access to the WindowServer</span></a><span style="font-weight: 400;"> in Firefox 95, improving security and speeding process startup by about 30-70%. This too became possible because of the Remote WebGL and Non-Native Theming work described above.</span></p>
<p><span style="font-weight: 400;">For Linux users, </span><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1129492"><span style="font-weight: 400;">we removed the connection from content processes to the X11 Server</span></a><span style="font-weight: 400;">, which stops attackers from exploiting the unsecured X11 protocol. Although Linux distributions have been moving towards the more secure Wayland protocol as the default, we still see a lot of users that are using X11 or XWayland configurations, so this is definitely a nice-to-have, which shipped in Firefox 99.</span></p>
<h2><strong>We&#8217;re Hiring</strong></h2>
<p><span style="font-weight: 400;">If you found the technical background story above fascinating, I&#8217;d like to point out that our OS Integration &amp; Hardening team is going to be hiring soon. We&#8217;re especially looking for experienced C++ programmers with some interest in Rust and in-depth knowledge of Windows programming. </span></p>
<p><span style="font-weight: 400;">If you fit this description and are interested in taking the next leap in Firefox security together with us, </span><a href="https://www.mozilla.org/en-US/careers/"><span style="font-weight: 400;">we&#8217;d encourage you to keep an eye on our careers page</span></a><span style="font-weight: 400;">.</span></p>
<p><i>Thanks to Bob Owen, Chris Martin, and Stephen Pohl for their technical input to this article, and for all the heavy lifting they did together with Kelsey Gilbert and Jed Davis to make these security improvements ship.<br />
</i></p>
<p>The post <a rel="nofollow" href="https://hacks.mozilla.org/2022/05/improved-process-isolation-in-firefox-100/">Improved Process Isolation in Firefox 100</a> appeared first on <a rel="nofollow" href="https://hacks.mozilla.org">Mozilla Hacks - the Web developer blog</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://hacks.mozilla.org/2022/05/improved-process-isolation-in-firefox-100/feed/</wfw:commentRss>
			<slash:comments>5</slash:comments>
		
		
			</item>
	</channel>
</rss>